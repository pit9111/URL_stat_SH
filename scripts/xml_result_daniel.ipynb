{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fdc125c-4153-4a5d-a416-5a9c56c50637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in ..\\result\\xml_result_daniel.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def extract_domains_from_csv(csv_path):\n",
    "    \"\"\"Extract domains from the second column of a CSV file.\"\"\"\n",
    "    domains = set()\n",
    "    try:\n",
    "        with open(csv_path, newline='', encoding='utf-8') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=';')\n",
    "            next(reader, None)  # Skip header\n",
    "            for row in reader:\n",
    "                if len(row) > 1:\n",
    "                    domains.add(row[1].strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file {csv_path}: {e}\")\n",
    "    return domains\n",
    "\n",
    "\n",
    "def search_domains_in_xml(xml_folder, domains, output_csv_path):\n",
    "    \"\"\"Search for specified domains in XML files and extract associated URLs.\"\"\"\n",
    "    url_pattern = re.compile(\n",
    "        r'https?://(?!www\\.tei-c\\.org/ns/1\\.0\\b)(?:www\\.)?[-\\w@:%._\\+~#=]{1,256}\\.[a-zA-Z]{2,6}\\b(?:[-\\w@:%_\\+.~#?&/=]*)'\n",
    "    )\n",
    "    domain_pattern = re.compile(r'\\b(' + '|'.join(re.escape(domain) for domain in domains) + r')\\b')\n",
    "    matches = []\n",
    "    \n",
    "    os.makedirs(os.path.dirname(output_csv_path), exist_ok=True)\n",
    "    \n",
    "    for filename in os.listdir(xml_folder):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            file_path = os.path.join(xml_folder, filename)\n",
    "            try:\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    text = file.read().replace('\\r', '').replace('\\n', '')\n",
    "                    found_urls = url_pattern.findall(text)\n",
    "                    \n",
    "                    for url in found_urls:\n",
    "                        if domain_pattern.search(url):\n",
    "                            matches.append([url, filename[:-4]])  # Remove .xml extension\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "    \n",
    "    # Save results to CSV\n",
    "    try:\n",
    "        with open(output_csv_path, \"w\", encoding=\"utf-8\", newline='') as output_file:\n",
    "            writer = csv.writer(output_file, delimiter=';')\n",
    "            writer.writerow([\"url\", \"filename\"])  # Header\n",
    "            writer.writerows(matches)\n",
    "        print(f\"Results saved in {output_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing CSV file {output_csv_path}: {e}\")\n",
    "\n",
    "\n",
    "# Paths\n",
    "csv_path = os.path.join(\"..\", \"data\", \"SH\", \"SH_forge.csv\")\n",
    "xml_folder = os.path.join(\"..\", \"data\", \"xml\")\n",
    "output_path = os.path.join(\"..\", \"result\", \"xml_result_daniel.csv\")\n",
    "\n",
    "# Execution\n",
    "domains = extract_domains_from_csv(csv_path)\n",
    "search_domains_in_xml(xml_folder, domains, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5a619-37fb-407b-9da3-5e0283ed3083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
