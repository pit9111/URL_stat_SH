Unawareness in multi-agent systems with partial
valuations
Line van den Berg, Manuel Atencia, JÃ©rÃ´me Euzenat

To cite this version:

Line van den Berg, Manuel Atencia, JÃ©rÃ´me Euzenat. Unawareness in multi-agent systems with partial
valuations. LAMAS 2020 - 10th AAMAS workshop on Logical Aspects of Multi-Agent Systems, May
2020, Auckland, New Zealand. ï¿¿hal-02984952ï¿¿

HAL Id: hal-02984952

https://hal.science/hal-02984952

Submitted on 1 Nov 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

Lâ€™archive ouverte pluridisciplinaire HAL, est
destinÃ©e au dÃ©pÃ´t et Ã  la diffusion de documents
scientifiques de niveau recherche, publiÃ©s ou non,
Ã©manant des Ã©tablissements dâ€™enseignement et de
recherche franÃ§ais ou Ã©trangers, des laboratoires
publics ou privÃ©s.

Unawareness in Multi-Agent Systems with Partial Valuations

Line van den Berg, Manuel Atencia, JÃ©rÃ´me Euzenat
{line.van-den-berg,manuel.atencia,jerome.euzenat}@inria.fr
Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LIG, F-38000 Grenoble France

ABSTRACT
Public signature awareness is satisfied if agents are aware of the
vocabulary, propositions, used by other agents to think and talk
about the world. However, assuming that agents are fully aware of
each otherâ€™s signatures prevents them to adapt their vocabularies
to newly gained information, from the environment or learned
through agent communication. Therefore this is not realistic for
open multi-agent systems. We propose a novel way to model aware-
ness with partial valuations that drops public signature awareness
and can model agent signature unawareness, and we give a first
view on definining the dynamics of raising and forgetting aware-
ness on this framework.

KEYWORDS
Awareness; dynamic epistemic logic; partial valuations; multi-agent
systems

1 INTRODUCTION
Agents use propositions to represent the information they have
about the world. They may use different propositions and may
not be aware of the propositions used by other agents, i.e. their
signature, yet they may still need to communicate. In multi-agent
modal logics and in particular Dynamic Epistemic Logic (DEL), all
agents share the same signature. However, this is not desirable nor
practical for open multi-agent systems because it prevents agents
from acquiring new vocabulary or adapting their current signatures
when learning new information from the environment or through
agent communication.

This problem lies at the core of DEL: dynamic upgrades shrink
or re-arrange the models so that the carried information becomes
knowledge or belief in the resulting model. But this requires agents
to already be aware of the possible future evolutions of their knowl-
edge and beliefs and are not able to adapt their signatures.

We propose a novel way to model agent awareness with par-
tial valuations that (i) allows agents to be unaware of other agentsâ€™
signature and that (ii) enables knowledge representations to dynam-
ically evolve. This enables us to drop public signature awareness
and raise awareness of agents when they acquire new vocabulary.

2 RELATED WORK
Partial valuations have already been introduced for (Dynamic) Epis-
temic Logic [3â€“5, 7], but not connected to (dynamic) agent aware-
ness. However, we are not the first to capture unawareness and
awareness of agents. In [1], epistemic logic is extended with an
operator ğ´ğœ™ to denote â€œawareness of ğœ™â€ and a complete dynamic
logic with upgrades for increasing and decreasing agent awareness
was developed in [6, 8â€“10]. In this approach, each proposition is
evaluated at each world and only awareness is defined as a par-
tial function. That is, all the propositions that agents may become

aware of in the future are already specified in the initial setting.
As a consequence, increasing agent awareness also uncovers the
underlying truth values. Awareness is then used to distinguish
between â€˜implicitâ€™ and â€˜explicitâ€™ knowledge [8].

In this paper, we propose a different viewpoint and consider
becoming aware of a proposition and becoming aware of its truth
value as two different acts. This enables models to evolve openly in
their entirety.

3 UNAWARENESS
With partial semantics, lack of truth and falsity are not the same.
This enables agents to be uncertain about a statement ğ‘, i.e. not
knowing whether it is true or false (in the figure below on the left),
like in the case with standard semantics, but also to be unaware
of it, i.e. not considering it (in the figure below on the right). An
agent is unaware of ğ‘ if ğ‘ is not evaluated at the worlds the agent
considers plausible, where plausibility from a world ğ‘¤ to a world
ğ‘£ for agent ğ‘ is defined as follows: 1) there is an arrow from ğ‘¤ to
ğ‘£ for ğ‘ (ğ‘¤ğ‘…ğ‘ğ‘£), and 2) there is a (reflexive) arrow from ğ‘£ to ğ‘£ for ğ‘
(ğ‘£ğ‘…ğ‘ğ‘£).

ğ‘

ğ‘

ğ‘

ğ‘

ğ‘¤

ğ‘

 ğ‘

ğ‘£

ğ‘¢

To allow agents to have different knowledge representations
about the world, and to be unaware of each others signatures, there
is only a â€˜weak reflexivityâ€™ requirement: ğ‘¤ğ‘…ğ‘ğ‘¤ and ğ‘¤ğ‘…ğ‘ğ‘£ implies
ğ‘£ğ‘…ğ‘ğ‘£. Reflexivity and the lack of reflexivity allow us to control what
agents are aware of and therefore can have knowledge (or beliefs)
about. For example, consider two agents ğ‘ and ğ‘ that represent
the world with the propositions ğ‘ and ğ‘, respectively, that they
each know but that the other agent is unaware of - and therefore
cannot know or believe anything about. The states of the agents
are described as follows, where from ğ‘¤ (cid:6)
ğ‘ ) agent ğ‘ (ğ‘) does not
have a (reflexive) arrow to ğ‘¤ (cid:6)
ğ‘ ) but instead only to another
world ğ‘£ğ‘ (ğ‘£ğ‘ ) where ğ‘ (ğ‘) is undefined:

ğ‘ (ğ‘¤ (cid:6)

ğ‘ (ğ‘¤ (cid:6)

ğ‘

ğ‘

ğ‘¤ (cid:6)
ğ‘

ğ‘

ğ‘, ğ‘

ğ‘£ğ‘

ğ‘

ğ‘

ğ‘¤ (cid:6)
ğ‘

ğ‘

ğ‘, ğ‘

ğ‘£ğ‘

We model the knowledge and beliefs of agents from an agent-
perspective, where each agent can use a different signature, or
vocabulary. Thus, instead of one actual world as with standard
semantics for DEL, agents have different ways to represent the
actual world: these are reflections of the actual world, representing
the actual world as the agent sees it.

We require that the reflections are consistent. More specifically,
that for each agent, there is a reflection that is consistent with a

reflection of each other agent. In the example above, the reflections
are ğ‘¤ (cid:6)
ğ‘ for agent ğ‘ and ğ‘, respectively, and they are indeed
consistent: ğ‘ and ğ‘ do not contradict each other.

ğ‘ and ğ‘¤ (cid:6)

This enables models to be truly open: even the reflections of the
actual world are not constrained to interpret the same propositions.

3.1 Properties of awareness
We require that awareness cannot be lost over the relations ğ‘…ğ‘,
but is preserved. Similar properties for awareness were already
motivated in [1, 2]. In [1], awareness is assumed to only increase
over time and in [2] awareness is considered constant for all the
worlds the agent has access to.

In our semantics, preserving agent awareness over the relations

ğ‘…ğ‘ comes two-fold:

(cid:13) whenever an agent ğ‘ has a (reflexive) relation from ğ‘¤ to ğ‘¤,
she also has a (reflexive) relation from ğ‘£ to ğ‘£ for any ğ‘£ such
that ğ‘¤ğ‘…ğ‘ğ‘£(weak reflexivity);

(cid:13) and the propositions that are evaluated (defined) at ğ‘¤, remain

evaluated at any ğ‘£ such that ğ‘¤ğ‘…ğ‘ğ‘£.
The latter property is specified as follows:

(cid:13) the evaluated propositions cannot increase over ğ‘…ğ‘ (specifi-

cation);

(cid:13) and any two worlds that can be reached from a world ğ‘¤ by
the same agent via ğ‘…ğ‘, share the same evaluated propositions
(consideration consistency).

Together, the requirements of awareness enforce that agents are
consistent in their considerations: if an agent ğ‘ considers a propo-
sition ğ‘ or its negation plausible at a world ğ‘¤, she considers ğ‘ or
its negation plausible at every world she can reach via ğ‘…ğ‘ from ğ‘¤.

Definition 3.1 (Properties of awareness). Let ğ‘Š be a set of states, ğ‘
be an agent with a relation ğ‘…ğ‘ (cid:132) ğ‘Š (cid:2)ğ‘Š , and ğ‘‰ a valuation function
ğ‘‰ğ‘¤ : P (cid:209) t0, 1u. Then
that assigns to each state a partial function (cid:4)
the properties of awareness are formalized as:

(cid:13) Weak reflexivity: @ğ‘¤, ğ‘£ P ğ‘Š : ğ‘¤ğ‘…ğ‘ğ‘¤ ^ ğ‘¤ğ‘…ğ‘ğ‘£ Ã¦ ğ‘£ğ‘…ğ‘ğ‘£
ğ‘‰ğ‘¤ q
(cid:13) Specification: @ğ‘¤, ğ‘£ P ğ‘Š : ğ‘¤ğ‘…ğ‘ğ‘£ Ã¦ ğ·ğ‘œğ‘šp(cid:4)
(cid:13) Consideration consistency: @ğ‘¤, ğ‘£, ğ‘¢ P ğ‘Š : ğ‘¤ğ‘…ğ‘ğ‘£ ^ ğ‘¤ğ‘…ğ‘ğ‘¢ Ã¦

ğ‘‰ğ‘£ q (cid:132) ğ·ğ‘œğ‘šp(cid:4)

ğ·ğ‘œğ‘šp(cid:4)

ğ‘‰ğ‘£ q (cid:16) ğ·ğ‘œğ‘šp(cid:4)

ğ‘‰ğ‘¢ q

where the set of evaluated propositions at world ğ‘¤, the domain
(ğ·ğ‘œğ‘šp(cid:4)

ğ‘‰ğ‘¤ q (cid:16) tğ‘ P P | ğ‘ğ‘‰ğ‘¤ P t0, 1uu.

ğ‘‰ğ‘¤ q), is defined as ğ·ğ‘œğ‘šp(cid:4)

3.2 Semantics
The semantics that we use are different from the semantics of Partial
(Dynamic) Epistemic Logic in [4] in two ways:

(cid:13) knowledge and belief are defined as truth in all accessible and
all most plausible worlds, respectively, in which reflexivity
is satisfied;

(cid:13) and formulas ğœ™ are only true (or false) whenever all proposi-

tions occurring in ğœ™ are defined.

The first condition shapes our epistemic ((cid:18)ğ‘) and doxastic ((cid:209)ğ‘)
relations via ğ‘…ğ‘: ğ‘¤ (cid:18)ğ‘ ğ‘£ iff ğ‘£ğ‘…ğ‘ğ‘£ and either ğ‘¤ğ‘…ğ‘ğ‘£ or ğ‘£ğ‘…ğ‘ğ‘¤, and
ğ‘¤ (cid:209)ğ‘ ğ‘£ iff ğ‘£ P ğ‘€ğ‘ğ‘¥ğ‘…ğ‘ tğ‘¢ | ğ‘¤ğ‘…ğ‘ğ‘¢ ^ ğ‘¢ğ‘…ğ‘ğ‘¢u. Requiring reflexivity
enables us to control that agents can only know or believe a propo-
sition if they are aware of it.

The second condition strenghtens this: it ensures that agents can
only know (or believe) a formula if they have full awareness of the

propositions that occur in it. For example, unlike the work in [4],
this means that an agent ğ‘ can only know (or believe) a disjunction,
i.e. ğ¾ğ‘pğ‘ _ ğ‘q, if she is aware of both disjuncts ğ‘ and ğ‘.

3.3 Raising awareness
Traditionally, dynamic upgrades for DEL reduce or re-organize the
possible worlds and, with this, increase the knowledge and beliefs
of agents. With a formal notion of awareness, we can additionally
extend (or decrease) the valuation function to raise (or forget) agent
awareness, both locally or globally. This allows agents to naturally
extend their vocabularies, and hence knowledge and beliefs, with
newly gained information.

Formally, to raise awareness of ğ‘ ((cid:0)ğ‘), all the worlds (globally), or
all accessible worlds for an agent (locally), in which ğ‘ was initially
not defined are duplicated, accessibility to and from duplicated
worlds being preserved, and ğ‘ is made true in one world and false in
the other, while preserving the relations. This means that unaware
agents (ğ‘ is not defined in their accessible worlds) are transformed
to uncertain agents (considering ğ‘ true or ğ‘ false) after raising
awareness.

3.4 Forgetting
A dual, inverse operator for forgetting awareness can similarly be
defined. Naturally, to forget awareness of a proposition ğ‘ ((cid:1)ğ‘) all
valuations of ğ‘ are deleted from the model (globally), or from all ac-
cessible worlds of an agent (locally), while preserving accessibility
relations. After awareness of ğ‘ is raised and subsequently forgotten,
i.e. M(cid:0)ğ‘;(cid:1)ğ‘ , this way of forgetting forces us back to the original
model M, up to bisimilarity. However, after a more complex up-
grade sequence like (cid:0)ğ‘; !ğ‘; !pğ‘ (cid:209) ğ‘q; (cid:1)ğ‘, where a proposition (ğ‘)
is used as evidence for another proposition (ğ‘) before it is forgotten,
we have a choice: to arrive back at the original state (and therefore
forgetting the truth value learned of ğ‘), or to keep the conclusions
and view forgetting as a generalization operator (abstracting from
the evidence ğ‘).

4 DISCUSSION AND CONCLUSION
We have provided a first view on a new semantics for modeling
agent unawareness using partial valuations. This semantics allows
communicating agents to be unaware of the signatures of other
agents and to raise their awareness when new information is ac-
quired.

Besides its theoretical interest, this can be used to show that
public signature awareness is reached in the limit of the raising
awareness upgrade. The intuition behind this is that as long as
agents share all the propositions in their signature, the other agents
will raise their awareness accordingly.

Future research is required to formally explore the necessary
conditions for successful communication without public signature
awareness and to explore the practical implications of this seman-
tics.

ACKNOWLEDGMENTS
The authors thank the anonymous reviewers for their valuable
comments and helpful suggestions. This work has been partially
supported by MIAI @ Grenoble Alpes (ANR-19-P3IA-0003).

REFERENCES
[1] Ronald Fagin and Joseph Y Halpern. 1987. Belief, awareness, and limited reason-

ing. Artificial intelligence 34, 1 (1987), 39â€“76.

[2] Joseph Y Halpern. 2001. Alternative semantics for unawareness. Games and

Economic Behavior 37, 2 (2001), 321â€“339.

[3] Jens Ulrik Hansen. 2014. Modeling truly dynamic epistemic scenarios in a partial

version of DEL. The Logica Yearbook 2013 (2014), 63â€“75.

[4] Jan Jaspars and Elias Thijsse. 1996. Fundamentals of partial modal logic. Studies

in Logic Language and Information (1996).

[5] Elias Thijsse. 1994. Partial logic and knowledge representation. (1994).
[6] Johan Van Benthem and Fernando R VelÃ¡zquez-Quesada. 2010. The dynamics of

awareness. Synthese 177, 1 (2010), 5â€“27.

[7] Wiebe Van der Hoek, Jan Jaspars, and Elias Thijsse. 1996. Honesty in partial

logic. Studia Logica 56, 3 (1996), 323â€“360.

[8] Hans Van Ditmarsch and Tim French. 2009. Awareness and forgetting of facts and
agents. In 2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence
and Intelligent Agent Technology, Vol. 3. IEEE, 478â€“483.

[9] Hans Van Ditmarsch and Tim French. 2011. Becoming aware of propositional
variables. In Indian Conference on Logic and Its Applications. Springer, 204â€“218.
[10] Hans Van Ditmarsch, Andreas Herzig, JÃ©rÃ´me Lang, and Pierre Marquis. 2009.

Introspective forgetting. Synthese 169, 2 (2009), 405â€“423.

