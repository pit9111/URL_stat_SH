ConfidentialitÃ© diffÃ©rentielle Ã  risque : Relier les sources
dâ€™alÃ©a et un budget de confidentialitÃ©
Ashish Dandekar, Debabrota Basu, Pierre Senellart, StÃ©phane Bressan

To cite this version:

Ashish Dandekar, Debabrota Basu, Pierre Senellart, StÃ©phane Bressan. ConfidentialitÃ© diffÃ©rentielle
Ã  risque : Relier les sources dâ€™alÃ©a et un budget de confidentialitÃ©. BDA 2020 - 36Ã¨me ConfÃ©rence sur
la Gestion de DonnÃ©es â€“ Principes, Technologies et Applications, Oct 2020, Paris / Virtuel, France.
ï¿¿hal-03103528ï¿¿

HAL Id: hal-03103528

https://inria.hal.science/hal-03103528

Submitted on 8 Jan 2021

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

Lâ€™archive ouverte pluridisciplinaire HAL, est
destinÃ©e au dÃ©pÃ´t et Ã  la diffusion de documents
scientifiques de niveau recherche, publiÃ©s ou non,
Ã©manant des Ã©tablissements dâ€™enseignement et de
recherche franÃ§ais ou Ã©trangers, des laboratoires
publics ou privÃ©s.

ConfidentialitÃ© diffÃ©rentielle Ã  risque : Relier les sources dâ€™alÃ©a
et un budget de confidentialitÃ©

Ashish Dandekar
DI ENS, ENS, CNRS, UniversitÃ© PSL
& Inria & National University of Singapore
Paris, France & Singapour, Singapour
ashishd@comp.nus.edu.sg

Pierre Senellart
DI ENS, ENS, CNRS, UniversitÃ© PSL
& Inria & Institut Universitaire de France
Paris, France
pierre@senellart.com

Debabrota Basu
Chalmers University of Technology
& Inria
GÃ¶teborg, SuÃ¨de & Lille, France
debabrota.basu@inria.fr

StÃ©phane Bressan
National University of Singapore

Singapour, Singapour
steph@nus.edu.sg

Dwork et al. [2] quantifient le niveau ğœ€ de confidentialitÃ© dans
la confidentialitÃ© ğœ€-diffÃ©rentielle comme une borne supÃ©rieure sur
la perte de confidentialitÃ©, dans le pire des cas, obtenue par un
mÃ©canisme prÃ©servant la confidentialitÃ©. De maniÃ¨re gÃ©nÃ©rale, un
mÃ©canisme prÃ©servant la confidentialitÃ© perturbe les rÃ©sultats en y
ajoutant une certaine quantitÃ© de bruit alÃ©atoire. La calibration du
bruit dÃ©pend de la sensitivitÃ© de la requÃªte et du niveau de confiden-
tialitÃ© spÃ©cifiÃ©. Dans un scÃ©nario du monde rÃ©el, un coordinateur
des donnÃ©es doit spÃ©cifier un niveau de confidentialitÃ© qui atteint
un compromis entre les besoins des utilisateurs et les contraintes
monÃ©taires de lâ€™entreprise. Par exemple, Garfinkel et al. [3] rap-
portent les difficultÃ©s rencontrÃ©es en dÃ©ployant la confidentialitÃ©
diffÃ©rentielle comme dÃ©finition de confidentialitÃ© par le bureau du
recensement des Ã‰tats-Unis. Ils insistent sur le manque de mÃ©thodes
analytiques pour choisir le niveau de confidentialitÃ©. Ils fournissent
Ã©galement des Ã©tudes empiriques qui montrent la perte dâ€™utilitÃ©
obtenue en utilisant des mÃ©canismes prÃ©servant la confidentialitÃ©.
Nous adressons le dilemme dâ€™un coordinateur de donnÃ©es de
deux maniÃ¨res. PremiÃ¨rement, nous proposons une quantification
probabiliste des niveaux de confidentialitÃ©. La quantification proba-
biliste des niveaux de confidentialitÃ© fournit au coordinateur des
donnÃ©es une faÃ§on de prendre des risques quantifiÃ©s, en respec-
tant un niveau dâ€™utilitÃ© des donnÃ©es. Nous nous rÃ©fÃ©rons Ã  cette
quantification probabiliste par le terme de confidentialitÃ© Ã  risque
(DÃ©finition 1). Nous dÃ©rivons Ã©galement un thÃ©orÃ¨me de composi-
tion qui met en Å“uvre la confidentialitÃ© Ã  risque. DeuxiÃ¨mement,
nous proposons un modÃ¨le de coÃ»t qui relie le niveau de confidentia-
litÃ© Ã  un budget monÃ©taire. Ce modÃ¨le de coÃ»t aide le coordinateur
des donnÃ©es Ã  choisir un niveau de confidentialitÃ© contraint par
un budget estimÃ©, et vice-versa. La convexitÃ© du modÃ¨le de coÃ»t
proposÃ© assure lâ€™existence dâ€™une confidentialitÃ© Ã  risque unique
qui minimise le budget. Nous montrons que la composition avec
une confidentialitÃ© Ã  risque optimale fournit des garanties de confi-
dentialitÃ© plus fortes que le thÃ©orÃ¨me classique de composition
avancÃ©e [2]. Finalement, nous illustrons notre travail par un scÃ©na-
rio rÃ©aliste qui dÃ©montre par lâ€™exemple comment le coordinateur

Â© 2020, Droits restant aux auteurs. PubliÃ© dans les actes de la confÃ©rence BDA 2020
(27-29 octobre 2020, En ligne, France). Redistribution de cet article autorisÃ©e selon les
termes de la licence Creative Commons CC-by-nc-nd 4.0.

des donnÃ©es peut Ã©viter de surestimer le budget en utilisant le mo-
dÃ¨le de coÃ»t proposÃ© pour la confidentialitÃ© Ã  risque. Pour plus de
dÃ©tails, se rÃ©fÃ©rer Ã  la version longue de cet article [1].

La quantification probabiliste des niveaux de confidentialitÃ© dÃ©-
pend de deux sources dâ€™alÃ©a : lâ€™alÃ©a explicite induit par la distribution
de bruit et lâ€™alÃ©a implicite de la distribution gÃ©nÃ©ratrice de donnÃ©es.
Souvent, ces deux sources sont couplÃ©es lâ€™une Ã  lâ€™autre. Nous impo-
sons des formes analytiques des deux sources dâ€™alÃ©a ainsi quâ€™une
reprÃ©sentation analytique de la requÃªte pour dÃ©river une garan-
tie de confidentialitÃ©. Le calcul de la quantification probabiliste
est, en gÃ©nÃ©ral, une tÃ¢che difficile. Bien quâ€™il existe des dÃ©finitions
multiples de confidentialitÃ© probabiliste dans la littÃ©rature [4, 5], il
manque une quantification analytique qui relie lâ€™alÃ©a et le niveau
de confidentialitÃ© dâ€™un mÃ©canisme prÃ©servant la confidentialitÃ©.

DÃ©finition 1 (ConfidentialitÃ© Ã  risqe). Pour une distribu-
tion gÃ©nÃ©ratrice de donnÃ©es G, un mÃ©canisme prÃ©servant la confi-
dentialitÃ© M, Ã©quipÃ© dâ€™une requÃªte ğ‘“ et de paramÃ¨tres Î˜, satisfait la
confidentialitÃ© ğœ€-diffÃ©rentielle avec une confidentialitÃ© diffÃ©rentielle
0 â©½ ğ›¾ â©½ 1 si, pour tous ğ‘ âŠ† Image(M) et ğ‘¥, ğ‘¦ Ã©chantillonÃ©s de G
tels que ğ‘¥ âˆ¼ ğ‘¦ :

Pr

(cid:20)(cid:12)
(cid:12)
(cid:12)
(cid:12)

ln

Pr(M (ğ‘“ , Î˜)(ğ‘¥) âˆˆ ğ‘ )
Pr(M (ğ‘“ , Î˜)(ğ‘¦) âˆˆ ğ‘ )

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:21)

> ğœ€

â©½ ğ›¾,

(1)

oÃ¹ la probabilitÃ© externe est calculÃ©e par rapport Ã  lâ€™espace de proba-
bilitÃ©s Image(M â—¦ G) obtenu en appliquant le mÃ©canisme prÃ©servant
la confidentialitÃ© M sur la distribution gÃ©nÃ©ratrice de donnÃ©es G.

Autant que nous en le sachions, nous sommes les premiers Ã  dÃ©-
river une confidentialitÃ© Ã  risque pour le mÃ©canisme de Laplace [2],
largement utilisÃ©. Nous dÃ©rivons Ã©galement un thÃ©orÃ¨me de com-
position pour la confidentialitÃ© Ã  risque. Câ€™est un cas particulier du
thÃ©orÃ¨me de composition avancÃ©e [2] qui traite dâ€™un usage sÃ©quen-
tiel et adaptatif de mÃ©canismes prÃ©servant la confidentialitÃ©. Ces
rÃ©sultats et leurs preuves sont disponibles dans [1].

Le niveau de confidentialitÃ© proposÃ© par le cadre de la confi-
dentialitÃ© diffÃ©rentielle est une quantitÃ© trop abstraite pour Ãªtre
intÃ©grÃ©e dans un contexte dâ€™affaires. Nous analysons et listons les
conditions dâ€™un modÃ¨le de coÃ»t qui transforme le niveau de confi-
dentialitÃ© en un budget monÃ©taire. Nous lâ€™illustrons (Ã©quation (2))

BDA, octobre 2020, En ligne, France

Dandekar and Basu, et al.

en choisissant une fonction qui satisfait ces conditions. Dans lâ€™Ã©qua-
tion (2), ğ¸ dÃ©note le budget de compensation quâ€™une entreprise
doit payer Ã  chaque partie prenante dans le cas dâ€™une violation des
donnÃ©es Ã  caractÃ¨re personnel quand les donnÃ©es sont traitÃ©es sans
garantie de confidentialitÃ© prouvÃ©e, et ğ¸cd
ğœ€ est le budget de com-
pensation quâ€™une entreprise doit payer Ã  chaque partie prenante
dans le cas dâ€™une violation des donnÃ©es Ã  caractÃ¨re personnel quand
les donnÃ©es sont traitÃ©es par un mÃ©canisme avec confidentialitÃ©
ğœ€-diffÃ©rentielle. ğ¸min et ğ‘ sont des hyper-paramÃ¨tres rÃ©glables. Le
lecteur pourra se rÃ©fÃ©rer Ã  [1] pour plus dâ€™explications.

(2)

ğœ€ â‰œ ğ¸min + ğ¸eâˆ’ ğ‘
ğ¸cd
ğœ€ .
La fonction choisie pour le modÃ¨le de coÃ»t pour la quantifica-
tion probabiliste du modÃ¨le de coÃ»t est convexe en le niveau de
confidentialitÃ©. Ainsi, elle conduit Ã  un niveau de confidentialitÃ©
probabiliste unique qui minimise le coÃ»t. Nous illustrons ceci par un
scÃ©nario rÃ©aliste dâ€™une entreprise respectant le RGPD qui a besoin
dâ€™une estimation du budget de compensation quâ€™elle devra payer
aux parties prenantes dans le cas malheureux dâ€™une violation de
donnÃ©es personnelles. Cette illustration montre que lâ€™usage des ni-
veaux de confidentialitÃ© probabilistes Ã©vite de surestimer le budget
de compensation sans sacrifier lâ€™utilitÃ©.

Nous Ã©valuons de plus les garanties de confidentialitÃ© en utilisant
un calcul de la confidentialitÃ© Ã  risque pour le mÃ©canisme de Laplace.
Nous comparons quantitativement la composition sous confiden-
tialitÃ© Ã  risque optimale, estimÃ©e avec les modÃ¨le de coÃ»t, avec les
mÃ©canismes traditionnels de composition â€“ de base et avancÃ© [2].
Nous observons de plus fortes garanties de confidentialitÃ© que celles
obtenues par la composition avancÃ©e, sans sacrifier lâ€™utilitÃ© du mÃ©-
canisme. Nous adaptons Ã©galement le systÃ¨me PATE [6], qui utilise
la technique de comptabilitÃ© des moments de lâ€™Ã©tat de lâ€™art, pour

utiliser la confidentialitÃ© Ã  risque. Nous montrons expÃ©rimentale-
ment que la confidentialitÃ© Ã  risque optimale fournit de meilleures
garanties que la comptabilitÃ© des moments.

En conclusion, les bÃ©nÃ©fices de la quantification probabiliste,
c.-Ã -d., de la confidentialitÃ© Ã  risque, sont doubles. Non seulement
elle quantifie le niveau de confidentialitÃ© pour un mÃ©canisme prÃ©-
servant la confidentialitÃ© donnÃ©, mais elle facilite Ã©galement la prise
de dÃ©cision dans des problÃ¨mes qui se focalisent sur le compromis
confidentialitÃ©â€“utilitÃ© et sur la minimisation du budget de compen-
sation.

REMERCIEMENTS

Ce travail a Ã©tÃ© soutenu par la National Research Foundation
(NRF) de Singapour, Corporate Laboratory@University Scheme,
National University of Singapore et Singapore Telecommunications
Ltd. Ces recherches ont Ã©galement Ã©tÃ© financÃ©es par le projet Bio-
QOP de lâ€™ANR franÃ§aise (ANR-17-CE39-0006).

RÃ‰FÃ‰RENCES
[1] Ashish Dandekar, Debabrota Basu, and StÃ©phane Bressan. 2021. Differential
Privacy at Risk : Bridging Randomness and Privacy Budget. Proceedings on Privacy
Enhancing Technologies 1 (2021). https://doi.org/10.2478/popets-2021-0005
[2] Cynthia Dwork, Aaron Roth, et al. 2014. The algorithmic foundations of differential
privacy. Foundations and TrendsÂ® in Theoretical Computer Science 9, 3â€“4 (2014),
211â€“407.

[3] Simson L Garfinkel, John M Abowd, and Sarah Powazek. 2018. Issues Encountered

Deploying Differential Privacy. arXiv preprint arXiv :1809.02201 (2018).

[4] Rob Hall, Alessandro Rinaldo, and Larry Wasserman. 2012. Random Differential

Privacy. Journal of Privacy and Confidentiality 4, 2 (2012), 43â€“59.

[5] Ashwin Machanavajjhala, Daniel Kifer, John Abowd, Johannes Gehrke, and Lars
Vilhuber. 2008. Privacy : Theory meets practice on the map. In Data Engineering,
2008. ICDE 2008. IEEE 24th International Conference on. IEEE, 277â€“286.

[6] Nicolas Papernot, MartÃ­n Abadi, Ãšlfar Erlingsson, Ian J. Goodfellow, and Kunal
Talwar. 2017. Semi-supervised Knowledge Transfer for Deep Learning from Private
Training Data. In 5th International Conference on Learning Representations, ICLR
2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings.

