Trustworthy Distributed Computations on Personal
Data Using Trusted Execution Environments
Riad Ladjel, Nicolas Anciaux, Philippe Pucheral, Guillaume Scerri

To cite this version:

Riad Ladjel, Nicolas Anciaux, Philippe Pucheral, Guillaume Scerri. Trustworthy Distributed Com-
putations on Personal Data Using Trusted Execution Environments. APVP 2019 - Atelier sur la
Protection de la Vie Priv√©e, Jul 2019, Cap Hornu, France. Ôøøhal-02269200Ôøø

HAL Id: hal-02269200

https://hal.science/hal-02269200

Submitted on 22 Aug 2019

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L‚Äôarchive ouverte pluridisciplinaire HAL, est
destin√©e au d√©p√¥t et √† la diffusion de documents
scientifiques de niveau recherche, publi√©s ou non,
√©manant des √©tablissements d‚Äôenseignement et de
recherche fran√ßais ou √©trangers, des laboratoires
publics ou priv√©s.

Trustworthy Distributed Computations on Personal Data  

Using Trusted Execution Environments 

Riad Ladjel 
Inria, UVSQ, France 
riad.ladjel@inria.fr 

Nicolas Anciaux 
Inria, UVSQ, France 
nicolas.anciaux@inria.fr 

Philippe Pucheral  
Inria, UVSQ, France 
philippe.pucheral@uvsq.fr  

Guillaume Scerri  
Inria, UVSQ, France 
guillaume.scerri@uvsq.fr 

Abstract‚Äî  Thanks  to  new  regulations  like  GDPR,  Personal  Data 

performed by a myriad of untrusted participants?‚Äù. These are 

Management  Systems  (PDMS)  have  become  a  reality.  This 

the two questions targeted by this paper. 

decentralized  way  of  managing  personal  data  provides  a  de  facto 

protection  against  massive  attacks  on  central  servers.  But,  when 

performing distributed computations, this raises the question of how 

to preserve individuals' trust on their PDMS? And how to guarantee 

the  integrity  of  the  final  result?  This  paper  proposes  a  secure 

computing framework capitalizing on the use of Trusted Execution 

Environments at the edge of the network to tackle these questions. 

Keywords‚Äî Data privacy; TEE; secure distributed computing 

Answering  these  questions  requires  establishing  mutual 

trust between all parties in a distributed computation. On the 

one hand, any (PDMS) participant must get the guarantee that 

only the data required by the computation are collected and 

that  only  the  final  result  of  the  computation  he  consents  to 

contribute to, is disclosed (i.e., none of the collected raw data 

can be  leaked).  On the other hand,  the querier  must  get  the 

guarantee  that  the  final  result  has  been  honestly  computed, 

I. 

 INTRODUCTION  

with the appropriate code, on top of genuine data. Besides this, 

Smart disclosure initiatives (e.g., Blue Button in the US, 

MiData  in  UK,  MesInfos  in  France)  and  new  privacy-

protection  regulations  (e.g.,  GDPR  in  Europe  [1])  allow 

individuals to get their personal data back and manage it under 

control, in a fully decentralized way, using so-called Personal 

Data Management Systems (PDMS) [3]. Decentralization is 

paramount  in  terms  of  privacy  protection  by  reducing  the 

Benefit/Cost ratio of an attack compared to a central server. 

However,  crossing  data  of  multiple  individuals  (e.g., 

computing statistics or clustering data for an epidemiological 

or  sociological  study,  training  a  neural  network  to  organize 

bank records into categories or predict diagnoses according to 

medical  symptoms,  etc.)  is  of  utmost  personal  and  societal 

interest. This raises the question ‚Äúhow to preserve the trust of 

individuals  on  their  PDMS  while  engaging  their  data  in  a 

distributed  process  that  they  cannot  control?‚Äù.  The  dual 

question  from  the  querier  side  (i.e.,  the  party  initiating  the 

processing) is ‚Äúhow to guarantee the honesty of a computation 

the computing scheme must be generic and scalable (e.g., tens 

of thousands of participants) to have a practical interest. 

No state of the art solution tackles all dimensions of this 

problem.  Multi-party  computation  (MPC)  works  guarantee 

that only the final result of a computation is disclosed but they 

are either not generic in terms of supported computation or not 

scalable in the number of participants [10]. Similarly, gossip-

based [2], homomorphic encryption-based [13] or differential 

privacy-based  solutions  are  restricted  to  a  limited  set  of 

operations  that  can  be  computed.  Moreover,  none  of  these 

solutions tackle  the  limited data collection  and computation 

honesty issues. Recent works like [21] address the problem of 

authenticated query results, but focus on a single-user context, 

where the user is the querier.  

In  this  paper,  we  argue  that  the  emergence  of  Trusted 

Execution  Environments  (TEE)  [15]  definitely  changes  the 

game. TEEs, like ARM's TrustZone or Intel's Software Guard 

eXtention (SGX), are becoming omnipresent, from high-end 

servers to PC and mobile devices. TEEs are able to compute 

 
 
arbitrary functions over sensitive data while guaranteeing data 

The only type of attacks successfully conducted so far over 

confidentiality  and  code 

integrity.  This  opens  new 

TEE  are  side  channel  attacks  [19].  The  TEE  in  this  case 

opportunities to think about secure distributed processing with 

behaves  in  a  ‚Äúsealed  glass  proof‚Äù  mode  [18],  i.e.,  the 

the hope to reconcile security with genericity and scalability.  

confidentiality property is compromised, but the isolation and 

But TEEs are far from providing a direct solution on their 

attestation  properties  still  holds  (these  properties  are  not 

own.  They  have  not  been  designed  with  edge  computing 

challenged today). These attacks are complex to perform and 

involving a large number of participants in mind. Moreover, 

require  physically  instrumenting  the  TEE,  which  prevents 

while TEE tamper-resistance makes attacks difficult, specific 

large scale attacks. However, TEEs corrupted by side-channel 

side-channel attacks have been shown feasible [19]. Without 

attacks cannot be detected by honest ones as their behavior is 

appropriate  counter-measures,  a  minority  of  corrupted 

still the correct one. 

participants may endanger the data from the majority. Based 

on this statement, the paper makes four contributions: 

ÔÇ∑ it  defines  a  generic  and  scalable  TEE-based  computing 

protocol  over  decentralized  PDMSs  which  provides  the 

expected mutual trust and computation honesty properties, 

assuming this protocol has been safely executed;  

ÔÇ∑ it provides, for each participant and the querier, a solution 

to locally check that the protocol has indeed been honestly 

executed, without resorting to any trusted third party;  

ÔÇ∑ it proposes accurate counter-measures against side-channel 

attacks conducted by corrupted TEE participants;  

ÔÇ∑ finally,  it  qualitatively  and  quantitatively  evaluates  the 

scalability  and  security  of  the  solution  on  practical  use-

cases (group-by queries, k-means clustering). 

B.  Trust model 

The trust model considered in this paper stems from the 

decentralized nature of the targeted infrastructure.  

Untrusted  user  devices  and  infrastructure.  No  credible 

security  assumptions  can  be  made  on 

the  execution 

environment  running  on  widely  open  personal  devices  (PC, 

laptop, home box, smartphone, etc.) managed by non-experts. 

We thus consider that the device OS and applications can be 

corrupted. We also consider the communication infrastructure 

as  untrusted.  We  however  assume  that  the  communication 

flow  incurred  by  the  computed  algorithm  is  (made)  data 

independent,  i.e.,  that  personal  data  cannot  be  inferred  by 

observing the communication pattern among participants1.  

Large  set of  trusted  TEEs,  small  set of corrupted  TEEs. 

II.  PROBLEM FORMULATION 

We assume that each individual owns a TEE-enabled device 

A.  Security properties and limits of TEEs 

Relying  on  secure  hardware, existing Trusted  Execution 

Environments (TEEs) provide three main security properties: 

(1)  code  isolation,  meaning  that  an  attacker  controlling  a 

corrupted user environment/OS cannot influence the behavior 

of  a  program  executing  within  a  TEE  enclave,  (2) 

confidentiality,  meaning  that  private  data  residing  in  an 

enclave may never be observed, and (3) attestation, allowing 

to prove the identity of the code running inside a TEE [20].  

hosting his personal data (i.e., his PDMS). This is definitely 

no  longer  fantasy  considering  the  omnipresence  of  ARM's 

TrustZone  or  Intel's  SGX  on  most  PC, 

tablets  and 

smartphones.  As  explained  above,  a  small  subset  of  TEEs 

could have been corrupted by malicious participants to break 

their confidentiality with side-channel attacks. 

Trusted  computation  code.  We  consider  that  the  code 

distributed to the participants has been carefully reviewed and 

approved  beforehand  by  a  regulatory  body  (e.g.,  an 

association  or  national  privacy  regulatory  agency).  But  the 

1 Scalable solutions exist to meet this requirement [11] but this problem is 

orthogonal to this paper. 

                                                           
fact that the code is trusted does not imply that its execution 

attackers  from  targeting  a  specific  intermediate  result  (e.g., 

behaves as expected. 

sensitive  data  or  data  of  targeted  participants)  and  (3) 

Trusted  citizen  identity.  We  consider  that  citizens  have 

maximize the Cost/Benefit ratio of an attack. Note that this is 

been  assigned  a  private/public  key  by  a  trusted  (e.g., 

the best we can do assuming that the code manipulates clear 

governmental)  entity  (e.g.,  as  used  today  for  paying  taxes 

data  and  that  side  channel  attacks  can  be  performed.  In 

online). This prohibits attackers generating multiple identities 

addition, the means to achieve resilience should maintain the 

with the objective to massively contribute to a computation to 

communication flow independent of the data being processed 

isolate a small set of participants and infer their data. 

(i.e., attack resiliency should not affect the data independence 

assumption made in our trust model). 

To have a practical interest, the solution must finally: (1) 

be  generic  enough  to  support  any  distributed  computations 

(e.g.,  from  simple  aggregate  queries  to  advanced  machine 

learning  computations)  and  (2)  scale  to  a  large  population 

(e.g., tens of thousands) of individuals.  

C.  Problem statement 

The  problem  can  be  formulated  as  follows:    how  to 

translate  the  trust  provided  to  the  computation  code  by  the 

regulatory  body  into  a  mutual  trust  between  all  parties 

participating  to  the  computation  under  the  presented  trust 

model? To solve this problem, the following properties need 

to be satisfied: 

Mutual trust. Assuming that the declared code is executed 

within TEEs, mutual trust guarantees that: (1) only the final 

result r of the computation can be disclosed, i.e., none of the 

raw  data  of  any  participant  is  leaked  and  r  is  honestly 

computed as declared, (2) only the data strictly specified for 

the computation is requested from the participant PDMSs, (3) 

the computation code is generic and makes it possible to verify 

Figure 1 Manifest-based distributed computation. 

that any collected data is genuine2. 

Local assurance of validity. The querier and each involved 

participant must be able to monitor  locally (i.e., on its own, 

without relying on a central trusted party) that the computation 

is being performed in compliance with the code declaration, 

by  all  other  participants.  If  any  honest  participant  detects  a 

validity violation, an error is produced and the computation 

stops without producing any other (partial) result. 

Resilience  to  side-channel  attacks.  Assuming  a  small 

fraction of malicious (colluding) participants involved in the 

computation  with  corrupted  TEEs,  our  framework  must  (1) 

guarantee that the leakage remains circumscribed to the data 

manipulated  by  the  sole  corrupted  TEEs,  (2)  prevent  the 

2 Assuming data genuineness can be actually verified by the running code 

in any way (e.g., thanks to a digital signature). 

III. MUTUAL TRUST 

To provide the mutual trust property, we propose adopting 

a  manifest-based  approach.  As  described  in  Fig.  1,  this 

approach is conducted in three steps: 

Step1:  logical  manifest  declaration.  We  call  Querier  an 

entity  (e.g., a  research lab, a statistic agency  or  a company, 

acting  as  a  data  controller  in  the  GDPR  sense)  wishing  to 

execute a treatment over personal data. The Querier specifies 

a  Logical  Manifest  describing  the  computation  to  be 

performed,  namely:  its  purpose,  the  source  code  of  the 

operator to be run at each participant, the distributed execution 

plan materializing the data flow between operators and a set 

Actor (with identity)Logical ManifestPhysical ManifestTEE MonitorTEE OperationUntrusted proxyPDMS (personal data)AttestationConfidentialityCorrupted TEE‚Ä¶.ParticipantParticipant(corrupted)ParticipantQuerierPublic storeRegul.Citizen identityLegend:result11Querierspecifies and publish manifest; Regulator certifies itParticipants consent to manifest; Participants & querierbuild phys. manifestParticipants execute physi. manifest; Querierretrieves results (encrypted)2323                                                           
 
of privacy rules to be fulfilled, including data collection rules 

participants  have  executed  their  task,  the  end-result  is 

and expected number of participants. The Querier submits this 

delivered to the querier.  

logical  manifest  to  a  Regulatory  body  which  certifies  its 

Let  us  introduce  the  following  definitions  in  order  to 

compliance with the expected privacy practices. The certified 

analyze how mutual trust is achieved. 

logical manifest is then published in a public manifest store 

Definition  1:  Distributed  Execution  Plan  (DEP).  A 

where  it  can  be  downloaded  by  individuals  wishing  to 

distributed execution plan DEP is defined as a directed graph 

participate. We provide below an example (deliberately na√Øve 

(V, E) where V vertices are couples (opi, aj)ÔÉéOPÔÇ¥A with OP 

for the sake of simplicity) of a logical manifest for a group-by 

the set of operators to be computed and A the set of computing 

query implemented using a MapReduce-like framework. 

agents,  and  E  edges  are  couples  (<opi,  aj>,<opk,  al>) 

Example 1: ‚ÄòGroup-by‚Äô manifest. 

materializing  the  dataflow  among  operators,  namely  the 

Purpose:  
  Compute the mean quantity of anxiolytic 
  prescribed to employees group by employer 
Operators:   
  mapper source code  
  reducer source code  
Distributed execution plan and dataflow: 
  Number of mappers: 10.000  
  Number of reducers: 100  
  Any mapper linked to all reducers  
Collection rules:  
  SELECT employer_name FROM Job; 
  SELECT sum(qty)FROM Presc   
  WHERE drugtype = ‚Äòanxiolytic‚Äô;  
Number of participants (data collectors): 10.000 
Querier Public key: Rex2%√É≈∫Hj6k7√¢ƒÇƒô 

transmission by aj to al of opi output. For any vi ÔÉé V, we denote 

by Ant(vi) (resp. Succ(vi)) the antecedents (resp. successors) of 

vi  in  the  DEP,  that  is  the  vertices  linked  to  vi  by  a  direct 

incoming (resp. outgoing) edge. 

This  representation  of  distributed  execution  plans  is 

generic  enough  to  capture  most  distributed  data-oriented 

computations. Based on this definition, we can introduce the 

notion of logical manifest. 

Step2: physical manifest construction. Once certified, the 

Definition 2:  Logical  Manifest  (LM).  A  logical  manifest 

manifest  can  be  viewed  as  a  logical  distributed  query  plan 

LM  is defined as  a  tuple  <PU,  DEP,  CR,  N>,  with  PU the 

(participants are not yet identified). When a sufficient number 

textual purpose declaration, DEP a distributed execution plan, 

of potential participants consent to contribute with their data, 

CR the collection rule applied at each participant and  N the 

a Physical Manifest is collectively established by the TEEs of 

expected number of participants.  

all participants (according to our trust model, each participant 

The  CR  declaration  translates  the  limited  collection 

is  equipped  with  a  TEE).  A  physical  manifest  assigns  an 

principle  enacted  in  all  legislations  protecting  data  privacy 

operator to each participant. As detailed in Section V, this step 

(i.e., no data other than the ones strictly necessary to reach the 

is critical for resilience to side-channel attacks, by prohibiting 

declared purpose PU will be collected). We assume that this 

corrupted participants from selecting specific operators in the 

declaration is done using a basic assertional language (e.g., a 

query plan for malicious purpose. 

subset  of  an  SQL-like  language)  easily  interpretable  by  the 

Step3:  physical  manifest  evaluation.  Each  participant 

Regulatory body on one side and easily translatable into the 

downloads the physical manifest (or the subpart allocated to 

specific  query  language  of  any  PDMSs  on  the  participant‚Äôs 

him). The participant‚Äôs TEE initializes an enclave to execute 

side.  For  the  sake  of  simplicity,  we  assume  that  the  data 

his assigned operator and establishes communication channels 

queried at each participant follow the same schema (if it is not 

with the TEEs of other participants supposed to exchange data 

the case, it is basically a matter of translating the collection 

with  him  (according  to  the  manifest  distributed  execution 

rules in different schemas). N plays a dual role: it represents 

plan).  The  participants  then  contributes  his  personal  data  to 

both a significance threshold for the Querier wrt. the declared 

the operator and allows the computation to proceed. Once all 

purpose and a privacy threshold for the Regulatory body wrt. 

condition  (2)  stems  from  the  fact  that  each  participant  pi  is 

the risk of reidentification of any individual in the final result. 

presented with qi which is a translation of LM.CR. The honest 

The notion of physical manifest can be defined as follows.  

execution of  qi over  pi‚Äôs PDMS remains  however  under  the 

Definition 3: Physical Manifest (PM). A physical manifest 

participant‚Äôs  responsibility  who  selected  it  to  protect  his 

PM  is  defined  as  a  tuple  <LM,  P,  F,  QCR>    such  that:  (1) 

personal  data.  Regarding  condition  (3),  H1  and  H2  again 

function F: LM.DEP.AÔÄ†ÔÇÆ P assigns agents to the participants 

guarantee  the  integrity  of  the  global  execution  of  PM.DEP. 

P contributing to the computation of LM; (2) F is bijective, so 

Note  that  this  guarantee  holds  even  in  the  presence  of 

that a given participant cannot play the role of different agents 

corrupted  TEEs  since  side-channel  attacks  on  TEEs  may 

and each agent is represented by a participant; (3) any query 

compromise the confidentiality of the processing but not the 

qiÔÉéQCR is the translation for participant pj of the collection rule 

isolation  property.  It  immediately  follows  that  any  check 

LM.CR into the query language of his PDMS.  

integrated in the operator code can be faithfully performed on 

Definition  4:  PM  valid  execution.  An  execution  of  a 

cleartext data, thus ensuring genericity.  

physical  manifest  PM  is  said  valid  if  the  execution  has  not 

Compared to state of the art solutions, our manifest-based 

deviated in any manner from what is specified in LM, i.e., (i) 

approach  holds  the  capacity  to  reconcile  security  with 

the operators in LM.DEP.OP are each executed by the TEE of 

genericity  and  scalability.  First,  the  TEE  confidentiality 

the participant designated by F while respecting the dataflow 

property can be leveraged to execute the computation code at 

imposed  by  LM.DEP.E,  (ii)  the  TEE  of  any  participant  pi 

each participant over cleartext genuine data. Second, the shape 

queries its host with qi, (iii) N different participants contribute 

of  the  DEP  and  then  the  resulting  number  of  messages 

to  the  computation and (iv) all data  exchanged  between  the 

exchanged  among  participants,  directly  results  from  the 

participants‚Äô TEEs are encrypted with session keys. 

distributed computation to be performed. Hence, conversely 

Lemma 1. Under the hypothesis H1 that the execution of a 

to  MPC,  homomorphic  encryption,  Gossip  or  Differential 

PM  is  valid  and  H2  that  no  TEE  have  been  corrupted,  the 

privacy 

approaches, 

no 

computational 

constraints 

mutual trust property is satisfied.  

compromising  genericity  nor  performance  constraints 

We postpone to Section IV how to achieve hypothesis H1 

compromising  scalability  need  to  be  introduced  in  the 

and to Section V the counter-measures suggested in the case 

processing for security reasons. 

hypothesis H2 does not hold.  

Proof of  Lemma 1. The  three  conditions in  mutual  trust 

definition  given  in  Section  II  hold  by  construction.  First, 

condition  (1)  is  satisfied  because  H1  guarantees  that  each 

operator in DEP.OP is executed within a TEE, and H2 and the 

TEE‚Äôs  confidentiality  property  ensure  that  no  data  can  leak 

other than the input and output of each DEP.OP. Encrypting 

the  data  exchanges  between  each  vertex  vi  and  Ant(vi)  and 

Succ(vi) in DEP with a session key ensures the confidentiality 

of the global execution of PM.DEP. The final result is itself 

sent encrypted to the Querier so that no raw data other than 

the  final  result  can  leak  all  along  the  execution.  Second, 

IV.  LOCAL ASSURANCE OF VALIDITY  

Once mutual trust is ensured, one needs to ensure that each 

participant  gets  the  assurance  that  the  computation  was 

performed  as  expected.  Ideally, 

this  means 

that 

the 

computation  should  behave  as  if  all  participants  could 

continuously  monitor  all  the  others,  i.e.,  check  all  operator 

computations,  ensuring  correction  of  sent/received  data  at 

each  step,  and  abort  the  whole  process  if  any  misbehavior 

happens. This is formalized in the following definition. At this 

stage, we assume that the execution plan has been produced 

by  an  arbitrary  function  build_phys_manifest,  assigning  a 

position i in the execution plan to each participant (the strategy 

for performing this assignment is discussed in Section V). We 

to interpret the manifest and drive the local execution, creates 

also assume that the local code executed by a participant either 

a  second  enclave  to  launch  the  TEE  computation  code 

terminates successfully or explicitly returns an error. 

corresponding to the operator assigned to the participant in the 

Definition 5: locally checkable execution. The execution 

execution plan. Note that all of the scheduling is performed by 

of a distributed execution plan DEP is said locally checkable 

the untrusted proxy, in particular waking up TEE monitors as 

if  for  any  participant  pjÔÉéPM.P,  either  (i)  pj‚Äôs  view  of  the 

they are needed for the computation.  

partial execution  up  to  pj‚Äôs role  is  valid  or (ii)  pj returns an 

The TEE monitor code is identical for each participant, so 

error and no data is ever transmitted to other participants. 

that its hash is known by everyone. This code is minimal, can 

An immediate consequence of Definition 5 is that, for any 

be  easily  formally  proved  and  is  assumed  trusted  by  all 

locally checkable execution, either a global result is produced 

participants.  This  lets  us  consider  the  manifest  LM  as  data, 

if  the  execution  is  valid  or  no  intermediate  values  is  ever 

including the code of the local operator to be computed, let 

leaked.  It  follows  that  a  protocol  guaranteeing  locally 

each local TEE monitor check the integrity of this data and 

checkable  executions  for  a  DEP  exactly  provides  local 

then attest the other participants (antecedents and successors 

assurance  of  validity  as  any  deviation  from  the  normal 

in  the  execution  plan)  to  the  genuineness  of  the  TEE 

execution  would  result  in  an  invalid  execution  and  would 

computation  code.  Antecedents  and  successors  can  easily 

therefore result in an error at the participant‚Äôs level. 

check in turn the validity of the received remote attestation by 

As  participants  execute  code  in  TEEs,  a  na√Øve  way  to 

checking  only  the  genuineness  of  the  remote  TEE  monitor. 

satisfy Definition 5 is to instrument the code of each operator 

This  double  attestation  by  the  antecedents  and  by  the 

in  order  to  make  sure  that  before  sending  out  any  (partial) 

successors is mandatory to guarantee, for each participant, the 

result the code gets approval from all other participants. While 

validity  of  the  inputs  it  receives  and  the  authenticity  of  the 

this solution trivially satisfies our goal of local assurance of 

recipients  for  its  own  outputs.  This  transitive  attestation 

validity, the communication overhead with a large number of 

principle is depicted in Fig. 2. 

participants is overwhelming. 

Following this strategy, local checkability is guaranteed. 

In  order  to  overcome  the  aforementioned  problem,  we 

Intuitively,  if  a  specific  participant  does  not  execute  the 

leverage  the  fact  that  using  the  TEE  mechanisms  and 

genuine  TEE  monitor,  it  will  be  unable  to  provide  a  valid 

attestation,  one  can  rely  on  checks  made  within  other 

attestation to its partners (antecedents/successors) which will 

participant‚Äôs TEEs. In our architecture, the foundation of local 

stop the execution and return an error. Then, if all participants 

checkability is the decomposition of the code running at each 

run the correct TEE monitor and execute the same manifest, 

participant  in  a  generic  TEE  monitor  and  a  specific  TEE 

the  execution  is  necessarily  correct,  since  the  TEE  monitor 

computation code. The objective of this distinction is to avoid 

only  executes  its  dedicated  code,  and  attestation  prevents 

the need for any participant to recompile the code running on 

attacks  from  the  OS  on  the  result  of  the  TEE  computation 

the  other  participants  and  compute  its  hash  to  evaluate  the 

code. If, however, one participant does not execute the correct 

validity of the requested remote attestations. The execution at 

manifest,  its  antecedents/successors  will  fail  during  the 

each  participant  then  works  as  follows:  (1)  untrusted  code 

manifest  verification.  Finally,  for  any  execution  plan 

executed on the local host, called untrusted proxy in Fig. 2, 

represented by a connected graph, the validity of the global 

creates  a  TEE  enclave  and  launches  the  TEE  monitor  code 

execution  is  obtained  by  propagating  errors  through  the 

inside this enclave, (2) the TEE monitor, the role of which is 

execution  graph,  if  an  error  occurs  at  any  point  during  the 

computation. In order to prevent an attacker from running a 

and  to  prevent  an  adversary  capable  of  observing  the 

large number of instances of a computation code in enclaves, 

communications from getting access to user data. A primitive 

each enclave must be tied to an identity, certified by a citizen 

reaching this goal is called attested key exchange [5]. It allows 

identity provider.  

to  exchange  a  key  with  an  enclave  executing  a  specific 

The  pseudo  code  of  the  TEE  monitor  is  provided  in 

program, and hence ensures (using the attestation mechanism) 

Algorithm  1.  For  the  sake  of  conciseness,  we  restrict  this 

that the endpoint of the channel lies within an enclave and that 

algorithm to the management of tree-based execution plans, 

the  enclave  is  executing  the  expected  program,  even  if  the 

however extending it to any graph is just a matter of allowing 

administrator of the machine running the enclave is corrupted. 

multiple successors. Note that the scheduling of the execution 

We  abstract  this  creation  of  a  secure  channel  as  channel( 

and  errors  propagation  can  be  handled  by  untrusted  code. 

remote, expected_code) where  remote is the remote enclave 

Indeed, if a participant encounters an error, it would typically 

and expected_code is the code expected to be running in the 

propagate  it  upstream  so  as  not  to  let  successor‚Äôs  enclaves 

remote  enclave.  The  cost  is  essentially  1  remote  attestation 

hanging.  However,  it  is  by  no  means  security  critical  as 

and 2 communications. Once established, all communications 

successor‚Äôs enclave would simply never execute if they fail to 

are assumed to be done on this channel. For simplicity‚Äôs sake 

receive their antecedents‚Äô inputs. 

Algorithm 1.  TEE monitor 

Input: 

LM the logical manifest, id = (ski, pki, certi) the participants‚Äô 
cryptographic identity and the corresponding certificate  

// build physical manifest 

// verify manifest  

Output:  boolean indicating success  
1. 
if verify(LM) = false then 
2. 
  return error 
3.  PM ÔÇ¨ build_phys_manifest(LM, id)  
4. 
i ÔÇ¨ get_my_position(PM, ski)  
5.  PMi ÔÇ¨ extract(PM, i)  
6.  Qi, Pi, Ci, opi ÔÇ¨ Parse(PMi) 
7.  for each antecedent ÔÉé Ci do 
8. 
9. 
10.  
11.  
12. input_tuples +ÔÇ¨ out_call(Qi)  
13. EOPi ÔÇ¨ create_enclave(opi)  
14. if not(channel(EOPi, opi) then return error 
15. send_tuples(input_tuples, EOPi)  

if not(channel(antecedent, self.code)) then return error 
if not(id_check(antecedent)) then return error 
if antecedent.PM ÔÇπ PM then return error 
input_tuples +ÔÇ¨ accept_input(antecedent)  

// query PDMS 
// create opi enclave  

// produce output 

// get antecedents‚Äô outputs 

/* NB: integrity of input_tuple is checked in OPi enclave code */ 

// execute opi 

16. res_opi ÔÇ¨ accept_input(EOPi)  
17. successor ÔÇ¨ get_ successor(PM,res_opi) 
18. if successor = querier then  
19.   a ÔÇ¨ attest(res_opi, PM) 
20.   send(a, res_opi) 
21.   return success 
22. if not(channel(successor), self.code) then return error  
23. if not(id_check(successor)) then return error 
24. if successor.PM ÔÇπ PM then return error  
25. send_tuples(res_opi, successor)  
26. return success 

we abstract away who is the initiator of the secure channel and 

view this process as symmetric. 

Algorithm description. In lines 1 to 6, the integrity of the 

logical  manifest  is  verified  by  checking  its  signature,  the 

physical  manifest  is  built  in  collaboration  with  the  other 

participating TEE monitors (cf. Section V, which also covers 

the explanation of line 4, not required in this section) and the 

part of the manifest related to this participant is extracted (i.e., 

the set of its antecedents/successors, the data collection query 

used to retrieve data from the local PDMS and the code of the 

operator to be evaluated locally).  

Then, in lines 7 to 12, the attestation of each antecedent is 

verified, by comparing the hash value of the code it is running 

to the hash value of the TEE monitor code (common to each 

participant). Once the antecedent TEE monitor is known to be 

correct,  we  check  that  it runs  the correct  manifest. We  also 

check  its  identity  by  requiring  its  enclave  to  send  it.  This 

provides enough assurance because once we know the code of 

its  enclave  we  know  that  it  will  honestly  send  its  identity. 

While  hidden  in  the  pseudo  code,  we  assume  that  all 

Finally,  the  input  tuples  of  the  local  operator  are  retrieved 

communications  between  participants  and  the  different 

from its antecedents and/or the local PDMS of this participant.  

enclaves are performed on secure channels. This is crucial to 

In lines 13 to 16, the TEE monitor creates an additional 

ensure that the endpoints of channels lie in real TEE enclaves 

enclave  for  the  operator  to  be  run  (its  code  is  part  of  the 

  
 
 
manifest)  and  requests an  attestation from  this  enclave  (the 

A.  Randomness and Sampling 

hash  of  the  operator  is  compared  to  the  hash  of  the  code 

In  a  physical  manifest,  we  distinguish  participants 

computed by the TEE monitor) to make sure that the host did 

assigned to  a collection  task (which  contribute  to  the  query 

not compromise or impersonate the operator code. Then the 

with their own personal raw data) from participants assigned 

monitor  establishes  a  secure  channel  with  the  operator 

to a computation task (which process personal data produced 

enclave,  using  an  attested  key  exchange  as  in  [5]  and  TEE 

by other participants). Attacking any TEE running a collection 

monitor calls the operator using the appropriate inputs.  

task has no interest since the attacker only gains access to his 

Finally, in lines 17 to 26, the TEE monitor, either sends 

own personal data. Hence, the primary objective of an attacker 

the result to the querier if its result is the final result, together 

is  to  tamper  with  the  building  phase  of  a  physical  manifest 

with  an  attestation  guaranteeing  the  result  was  indeed 

such that his TEE is assigned a computation task to leak the 

produced by the correct computation of the specified data; or 

data it manipulates. The randomness counter-measure assigns 

sends its result to the next participants as planned by the DEP.  

a  random  position  in  the  DEP  to  each  participant.  More 

Proposition 1. Algorithm 1 satisfies the locally checkable 

precisely, it ensures that for a given physical manifest PM, any 

execution property for the physical manifest PM derived from 

the logical manifest LM by the build_phys_manifest function. 

The sketch of proof of Proposition 1 is given in [23]. 

V.  RESILIENCE TO SIDE-CHANNEL ATTACKS  

According to our trust model, a small fraction of TEEs can 

be instrumented by malicious (colluding) participants owning 

them to conduct side-channel attacks compromising the TEE 

confidentiality  property.  This  issue  is  paramount  in  our 

Manifest-based  approach  which  draws  its  genericity  and 

scalability  from  the  fact  that  computing  nodes  manipulate 

cleartext genuine data, putting them at risk.  

The resilience to side-channel attacks property introduced 

in Section II, states first that the leakage generated by an attack 

must be circumscribed to the data manipulated solely by the 

corrupted TEEs. This is intrinsically achieved in our proposal 

participant pj ‚àà PM.P is able to locally verify that its position 

and the position of any other participant in PM.P have been 

obtained  randomly.  A  protocol  achieving  this  goal,  adapted 

from [22], can be found in [23]. The idea is to ensure that the 

randomness is generated by an enclave once the querier has 

committed  to  the  list  of  participants.  As  we  consider  that 

enclave integrity may not be compromised, this ensures that 

this  number  is  chosen  uniformly  at  random  even  in  the 

presence of an active adversary. 

Figure 2. Attestation flow for position i. 

by  never  sharing  any  cryptographic  information  among 

The second counter-measure to prevent an attacker from 

different  nodes.  A  second  requirement  is  to  prevent  any 

selecting its position in the DEP is to add a sampling phase in 

attacker  from  targeting  specific  personal  data.  Randomness 

Step2  (physical  manifest  construction,  Section  III)  by 

and Sampling are introduced next to achieve this goal. Finally, 

DEP  reshaping  is  proposed  to  tackle  the  third  requirement, 

i.e., maximizing the average Cost/Benefit ratio of an attack. 

selecting a given rate ÔÅ≥ of individuals accepting to contribute 

to the computation. The lower this rate ÔÅ≥, the more TEEs need 

be corrupted to keep the same probability of selecting a given 

position in the built DEP for an attacker. For conciseness, we 

3ParticipantPhysical ManifestTEE MonitorTEE OperationUntrusted proxyPDMS (personal data)Attestation flowAntecedentSuccessorLegend:Participant(at position i)3Antecedent... 
refer to a technical report [23] for details on randomness and 

nodes sharing mi‚Äôs initial computing load, with rf denoting the 

sampling algorithms and security proofs. 

reshaping  factor.  More  precisely,  this  curve  plots  the 

B.  DEP Reshaping  

In our context, the Cost factor of the Cost/Benefit ratio is 

expressed in terms of the number of TEEs to corrupt and the 

Benefit is measured by the amount of personal data leaked by 

the  attack.  While  randomness  and  sampling  contribute  to 

exacerbate the Cost factor, our third countermeasure aims at 

reducing the amount of raw data exposed at a single TEE. To 

introduce the idea, let us consider a DEP with n participants, 

among  which  m  computation  nodes  computing  a  function  f 

and  n-m  collection  nodes  contributing  with  their  own  data. 

With  the  randomness  countermeasure,  the  probability  to 

corrupt exactly t computation nodes among m with c corrupted 

participants (side-channel attacks), follows an hypergeometric 
distribution ùëùùëõ,ùëö,ùëê(ùë• = ùë°) = (ùëö

. The probability 

ùë• )(ùëõ‚àíùëö

ùëê‚àíùë• ) (ùëõ
ùëê)‚ÅÑ

of corrupting t or more computation tasks over m is then: 

ùëùùëõ,ùëö,ùëê(ùë°ÔÄ†ÔÇ£ ùë•ÔÄ†ÔÇ£ ùëö) = ‚àë (ùëö

ùë• )(ùëõ‚àíùëö
ùëê‚àíùë• )

(ùëõ
ùëê)‚ÅÑ
. 

ùëö

ùë•=ùë°

With n=10000, m=10 and c=100 (which is a high number 

of corrupted participants), the probability of corrupting at least 

one computation node is p10000,10,100 (1 ÔÇ£ xÔÄ†ÔÇ£ 10)=0.095, while 

with  m=100,  this  probability  drops  to p10000,100,100 (10  ÔÇ£  xÔÄ†ÔÇ£ 

100)=5.10-8. For simplicity, we assume that each participant 

contributes  with  exactly  one  tuple  mapped  to  a  single 

computation  node,  hence  each  computation  node  processes 

(and may endanger) on average N/m tuples (1000 tuples here).  

Figure 3. Probability and expected values in tuples of successful attacks. 

probability  to  leak  the  same  amount  of  data  as  with  the 

original  settings  in  function  of  the  number  c  of  corrupted 

nodes with different reshaping factor rf (e.g., rf=1 is the initial 

settings  with  m=10  computation  nodes,  rf=2  means  m=20, 

etc.). Unsurprisingly, increasing rf dramatically decreases the 

probability  of  an  attack  leaking  the  same  amount  of  tuples 

since rf different computation nodes (among rfÔÇ¥m) must now 

be corrupted with the same number c of corrupted participants.  

Fig.  3  (right)  shows  the  expected  value  in  number  of 

leaked tuples (i.e., sum of the probability of a successful attack 

on  some  computation  nodes  times  the  number  of  tuples 

leaked)  in  the  case  of  successful  side-channel  attacks  with 

c=100  corrupted  nodes.  The  expected  gain  is  always  small, 

although the number c of corrupted TEE is relatively high, and 

reduces  linearly  with  rf,  which  is  deterrent  for  attackers. 

Indeed, the probability to successfully break two computation 

nodes is close to zero, hence the expected gain is nearly given 

by the probability of breaking a single computation node times 

the  number  of  leaked  tuples  processed  in  that  node,  which 

linearly decreases with rf. These results are true if m and c are 

small compared to n, which is typically the case in our context. 

The conclusion is that, while maximizing the distribution 

of  a  computation  has  recognized  virtues  in  terms  of 

performance  and  scalability  (explaining  the  success  of 

MapReduce or Spark models), this strategy leads as well to a 

better resilience against side-channel attacks. Maximizing the 

distribution can be done by exploiting some properties of the 

functions to be evaluated by DEP computation nodes: 

Definition 6: Distributive function. Let f be a function to 

be  computed  over  a  dataset  D,  f  is  said  distributive  if  there 

exists a function g such that f(D) = g(f(D1), f(D2), ‚Ä¶, f(DN)) 

where Di forms a partition of D (e.g., D = ÔÉài (ÔÅ≥ (i, Di)) with ÔÅ≥ 

Fig.  3  (left)  plots  the  privacy  benefit  of  increasing  the 

a selection function).   

number of computation nodes by reshaping the DEP such that 

each initial computation node mi is split in rf new computation 

1E-101E-81E-61E-41E-21E+0050100150200pn,m,c( xÔÇ≥rf )  Currupted participants (c)rf = 1rf = 4rf = 8024681012rf=1rf=4rf=8Expected gain (in tuples) 
 
Definition  7:  Algebraic  function.  A  function  f  is  said 

data independent for privacy concern (e.g., sending fake data 

algebraic if f can be computed by a combination of distributive 

among  participants  to  normalize  the  communications).  It  is 

functions (e.g., mean(D) = sum(D)/count(D)).  

thus mandatory to preserve this independence. 

For any DEP node computing a distributive or algebraic 

Lemma  2.  If  the  communication  flow  E  of  a  distributed 

function, the number of D input tuples exposed to that node 

execution  plan  DEP(V,E) 

is  data 

independent, 

the 

can  be  linearly  reduced  by  augmenting  the  number  of  Di 

communication flow  E‚Äô of any  DEP‚Äô(V‚Äô,E‚Äô) obtained by  rf-

partitions  in  the  same  proportion.  This  general  principle, 

reshaping of DEP(V,E) is also data independent. 

called  DEP  reshaping,  splits  distributive/algebraic  tasks 

The result is ensured by the fact that the communication 

allocated to a single participant into several tasks allocated to 

flow in the DEP‚Äô only depends on the communication pattern 

different nodes, each working on a partition of the initial input.  

in DEP and the at( ) function in Definition 8, which in turn 

Definition  8:  rf-reshaping.  Given  an  attribution  function 

only depends on vertices identifiers and not on data. Hence, 

ùëéùë°: ùëâ ‚Üí {1, ‚Ä¶ , ùëüùëì} associating vertices to integers uniformly, 

the  communication  flow  E‚Äô  reveals  nothing  more  about  the 

a  distributed  execution  plan  DEP‚Äô(V‚Äô,E‚Äô)  is  obtained  by  rf-

transmitted data compared to E. 

reshaping 

from  DEP(V,E) 

such 

that:  V‚ÄôÔÉäV 

and 

The  rf-reshaping  principle  can  be  applied  in  many 

ÔÄ¢vi=(ai,opi)ÔÉéV/  distrib_algebra(opi)=true  ÔÉû  vi,j‚Äô=(ai,j,opi) 

practical examples of computations over distributed PDMSs, 

ÔÉéV‚Äô with j:1..rf, and vi,j‚ÄôÔÉéAnt(vi) in E‚Äô and ÔÄ¢vÔÉéAnt(vi) in E, 

vÔÉéAnt(vi,j‚Äô) with ùëó = ùëéùë°(ùë£) in E‚Äô. 

This definition is illustrated on Fig. 4, showing a DEP with 

6 additional computation nodes obtained by 3-reshaping from 

an initial DEP with only 2 computation nodes. Note that the 

communication overhead is very small, as only one additional 

message from each added reshaped node to the original node 

is  produced  compared  to  the  original  execution.  In  the 

remainder of the paper, we call a cluster all vertices attributed 

to the same reshaped node (i.e. ùëéùë°‚àí1(ùëó)). 

All  other  things  being  equal,  rf-reshaping  drastically 

reduce the data exposure at each computing node. Indeed, for 

any  distributive/algebraic  vertex  vi  in  DEP,  rf-reshaping 

divides the probability of gaining access to the entire input D 

of vi by a factor (ùëõ‚àíùëüùëì

ùëê‚àíùëüùëì) ‚àè

ùëñ=1..ùëüùëì

. 
‚ÅÑ
(ùëõ ‚àí ùëñ) (ùëê ‚àí ùëñ)

The final issue is showing that rf-reshaping may hurt the 

independence between the processed data and the dataflow as 

specified in the initial DEP. Recall that a communication flow 

E  is  said data  independent  if the  DEP is  such  that personal 

ranging from simple statistical queries to big data analysis, as 

illustrated in the validation section. The rf-reshaping process 

can  be  automatically  performed  by  a  precompiler  taking  as 

input  a  logical  manifest  LM  and  producing  a  transformed 

logical  manifest  LMminExp  minimizing  data  exposure  for  the 

participants for each node computing distributive or algebraic 

functions. The degree of distribution impacts the performance 

and  the  protection  of  raw  data  in  case  of  successful  attacks 

(see  Section  VI),  but  selecting  the  optimal  strategy  and 

integrating it into a precompiler is left for future work. 

Figure 4. 3-reshaping of DEP with m=2 distributive computation nodes. 

VI.  VALIDATION 

data  cannot  be  inferred  from  observing  the  communication 

The effectiveness of the solution in terms of security and 

pattern  among  participants.  E  can  be  data  independent  by 

scalability  is  assessed  on  a  platform  composed  of  8  SGX 

construction  (e.g.,  broadcast-based  algorithm)  or  be  made 

capable  machines  with  Intel  I5-7200U  and  16GB  RAM, 

Clustered antecedentsa1a2Rootresulta11a12a13Agents added by reshapinga21a22a23a1a2Root‚Ä¶‚Ä¶.‚Ä¶‚Ä¶‚Ä¶resultInitial DEPDEP‚Äô obtained by 3-reshaping of DEP 
equipped with  Intel SGX  SDK  2.3.101 over  Ubuntu  16.04. 

K-means clustering. It is similarly computed: (1) k initial 

We  consider  two  use-cases  of  distributed  processing  over 

means  representing  the  centroid  of  k  clusters  are  randomly 

personal data, to validate the genericity of our framework. 

generated by the querier and sent to all participants to initialize 

the  processing,  (2)  each  participant  acting  as  a  mapper 

computes its distance with these k means and sends back its 

data to the reducer node managing the closest cluster, (3) each 

reducer recomputes the new centroid of the cluster it manages 

based on the data received from the mappers and sends it back 

to  all  participants.  Steps  2  and  3  are  repeated  a  number  of 

times. The function computed by step 3 is algebraic since the 

centroid of a cluster ci can be computed thanks to sums and 

counts computed over all sub-clusters of ci. Hence, the number 

of reducers in step 3 can also be arbitrarily augmented by rf-

reshaping, such that each of the k initial reducers is preceded 

in DEP by a set of sub-reducers computing a partial centroid. 

The SGX platform is used to perform real measurements 

at  small  scale  (up  to  100  participants)  and  to  calibrate  an 

analytical model required to conduct large scale experiments. 

We  used  synthetic  datasets  since  the  primary  goal  is  not 

studying the peak performance for specific data distributions 

and save seconds or minutes (manual surveys over thousands 

of  participants  usually  take  weeks).  We  present  in  Fig.  5  a 

summary of our results and give the main outcome. We refer 

(a)  Combining counter-measures  

(b) Impact of rf-reshaping on Cost 

(c) Impact of rf-reshaping on Benefit 

(d) Performance without reshaping 

(e) Performance with rf-reshaping 

(f) Time ratio with rf-reshaping 

Figure 5. Security and performance evaluation. 

to [23] for extensive experiments and details.  

Group-by  aggregation.  We  consider  a  MapReduce-like 

implementation  of  an  aggregate  with  a  group  by  query  run 

over  distributed  PDMSs.  The  processing  is  as  follows:  (1) 

each mapper sends a couple (h(group_key), value) to a reducer 

where h is a hash function which projects the group key on a 

given  reducer,  (2)  each  reducer  computes  the  aggregate 

function  over  the  values  received  for  the  group  keys  it 

manages. If the aggregate function is distributive (e.g., count, 

Several conclusions can be drawn. First, even if the overall 

time can be considered rather high (tens of minutes for large 

numbers of participants), it is not a critical issue in our context 

from  a  querier  perspective.  Second,  rf-reshaping  drastically 

reduces the elapsed time by augmenting the parallelism while 

decreasing  the  number of  attestations between  mappers and 

reducers.  Third  rf-reshaping  is  deterrent  for  attackers  by 

acting on the Benefit/Cost ratio, even for low values of rf. 

min, max, sum, rank, etc.) or algebraic (e.g., avg, var, etc.), rf-

VII. RELATED WORKS 

reshaping is applied to all reducer nodes. Sub-reducer nodes 

Several works focus on protecting outsourced databases 

contribute to the computation of the function for a subset of a 

with encryption, but most of the existing encryption schemes 

grouping value and the initial reducers combine their work.  

applied to databases have been shown vulnerable to inference 

attacks  [7].  Going  further  induces  fully  homomorphic 

1E-311E-231E-151E-071E+010100200300Probability of successNumber of corrupted TEEsRnd.+Smpl.Rnd.+Reshp.Rnd.+Reshp.+Smpl.1100100001816Nb of corrupted TEEsReshaping factor (rf)Fixed targetAny target0100020001816Nb of leaked tuplesReshaping factor (rf)Zipfian distributionUniform distribution110010000202003000700010000Elapsed time (s)Number of mappersK-meansGroup-by0200400rf=8rf=16rf=8rf=16Elapsed time (s)100 mappers5000 mappers10000 mappersGroup-byK-means020406080100rf=1rf=16rf=1rf=16Time ratio (%)ValidityRnd.Algo.Group-byK-means  
 
 
 
 
 
 
encryption  [8]  with  intractable  performance  issues.  Some 

between enclaves in these works is quite similar to ours, but 

works  [4]  deploy  secure  hardware  at  database  server  side. 

the assumption of a unique controller completely removes the 

These solutions are centralized by nature and do not match our 

need  for  establishing  trust  at  a  local  level,  which  is  exactly 

assumption that no hardware module is perfectly secure. 

what our notion of local checkability aims at solving. 

In terms of decentralized computing, Secure Multi-Party 

Computations  (MPC)  have  been  adapted  to  databases  (e.g. 

SMCQL  [6]),  but  only  support  a  few  tens  of  participants. 

Using secure hardware, TrustedPals [9,12] makes MPC more 

scalable, but their goal and security assumptions differ from 

ours.  TrustedPals  ensures  that  results  are  distributed  to  all 

honest  parties,  and  that  all  received  results  are  consistent. 

Hence, TrustedPals is highly fault tolerant as opposed to our 

solution. Our solution is simpler, as it only aims at delivering 

the result to a querier, and thus does away with the consensus 

protocols.  However,  at  the  end  of  the  computation,  all 

involved parties in TrustedPals hold the entirety of the data 

within their security module, which would be unacceptable in 

our case as some TEEs might be compromised. 

Several  works  suggest  distributed  computation  schemes 

providing  anonymous  data  exchanges  and  confidential 

processing  using  gossip-style  protocols  [2].  They  typically 

scale  well  but  are  not  generic  in  terms  of  computations. 

Similarly, decentralized processing solutions based on secure 

hardware have also been proposed for aggregate queries [17] 

but do not match our genericity objective. 

To  the  best  of  our  knowledge,  all  works  regarding 

executing data oriented task using SGX (e.g. Ryoan [14]) have 

a unique controller, as opposed to our setting where no unique 

individual  is  supposed  to  be  in  control  of  the  computation. 

VIII. CONCLUSION 

Smart disclosure initiatives and new regulations push for 

the adoption of Personal Data Management Systems managed 

under  individual's  control  while  keeping  the  capability  to 

cross  personal  data  of  multiple  individuals  (e.g.,  economic, 

epidemiological  or  sociological  studies).  However,  without 

appropriate  security  measures,  the  risk  is  high  to  see 

individuals  refuse 

their  contribution.  Only  fragmented 

solutions have emerged so far. The generalization of Trusted 

Execution  Environment  at  the  edge  of  the  network  changes 

the game. This paper capitalizes on this trend and proposes a 

generic  secure  decentralized  computing  framework  where 

each participant gains the assurance that his data is used for 

the  purpose  he  consents  to  and  that  only  the  final  result  is 

disclosed. Conversely, the querier is assured that the result has 

been honestly computed. We have shown the practicality of 

the  solution  in  terms  of privacy  and performance.  We  hope 

that this work will lay the groundwork for thinking differently 

about decentralized computing on personal data. 

ACKNOWLEDGEMENTS 

This research is supported by the ANR PerSoCloud grant no 

ANR-16-CE39-0014. 

REFERENCES 

Additionally, most of the time this controller also provides the 

[1]  European  Parliament.  General  Data  Protection  Regulation.  Law.  (27 

data to be computed on. This greatly simplifies the problem as 

April 2016). https://gdpr-info.eu/ 

a  same  controller  verifies  all  enclaves  and  organizes  the 

computation. Other works [14], following VC3 [16], provide 

[2]  T. Allard, G. H√©brail, E. Pacitti, et al. Chiaroscuro: Transparency and 

privacy for massive personal time-series clustering. SIGMOD, 2015. 

[3]  N.  Anciaux,  P.  Bonnet,  L.  Bouganim,  B.  Nguyen,  P.  Pucheral,  I.  S. 

SGX-based  Map-Reduce 

frameworks 

for 

executing 

Popa, and G. Scerri. Personal data management systems: The security 

computations in the cloud to ensure data confidentiality and 

and functionality standpoint. Information Systems, 80, 2019. 

hide communication patterns between mappers and reducers, 

but again, they consider a unique controller. Communication 

[4]  A. Arasu and R. Kaushik. Oblivious query processing. In ICDT, 2014. 

[5]  M. Barbosa, B. Portela, G. Scerri, et al. Foundations of hardware based 

attested computation and application to SGX. In EuroS&P, 2016. 

[6] 

J.  Bater,  G.  Elliott,  C.  Eggen,  et  al,  and  J.  Rogers.  SMCQL:  secure 

query processing for private data networks. PVLDB, 10(6), 2017. 

[7]  V.  Bindschaedler,  P.  Grubbs,  D.  Cash,  et al.  The  tao  of inference  in 

privacy-protected databases. PVLDB, 11(11), 2018. 

[8]  D. Boneh, C. Gentry, S. Halevi, F.Wang, and D. J.Wu. Private database 

queries using somewhat homomorphic encryption. ACNS, 2013. 

[9]  R.  Corti√±as  et  al.  Secure  Failure  Detection  and  Consensus  in 

TrustedPals. IEEE Trans. Dependable Sec. Comput. 9(4), 2012. 

[10]  I. Damg√•rd, M. Keller, E. Larraia, et al. Practical covertly secure MPC 

for dishonest majority - or: Breaking the SPDZ limits. ESORICS, 2013. 

[11]  A. Dinh, P. Saxena, C. Chang, et al. M2R: enabling strong-er privacy 

in mapreduce computation. USENIX Security Symposium, 2015. 

[12]  M. Fort, F.C. Freiling, L.D. Penso et al. TrustedPals: Secure Multiparty 

Computation Implemented with Smart Cards. ESORICS, 2006. 

[13]  T.  Ge  and  S.  B.  Zdonik.  Answering  aggregation  queries  in  a  secure 

system model. VLDB, 2007. 

[14]  T. Hunt, Z. Zhu, Y. Xu, S. Peter, and E. Witchel. Ryoan: A distributed 

sandbox for untrusted computation on secret data. OSDI, 2016. 

[15]  M. Sabt, M. Achemlal, et al. Trusted execution environment: What it 

is, and what it is not. TrustCom/BigDataSE/ISPA (1), 2015.  

[16]  F.  Schuster,  M.  Costa,  C.  Fournet,  et  al.  VC3:  trustworthy  data 

analytics in the cloud using SGX. S&P, 2015.  

[17]  Q. To, B. Nguyen, P. Pucheral. Private and scalable execution of SQL 

aggregates on a secure decentralized architecture. TODS, 41(3), 2016.  

[18]  F.  Tram√®r,  F.  Zhang,  H.  Lin,  et  al.  Sealed-glass  proofs:  Using 

transparent enclaves to prove and sell knowledge. EuroS&P, 2017. 

[19]  W.  Wang,  G.  Chen,  X.  Pan,  et  al.  Leaky  cauldron  on  the dark  land: 

Understanding memory side-channel hazards in SGX. CCS, 2017.  

[20]  I. Anati, S. Gueron, S. Johnson, et al. Innovative technology for CPU 

based attestation and sealing. HASP, 2013.  

[21]  Zhang, Y., Genkin, D., Katz, J., et al. vSQL: Verifying arbitrary SQL 

queries over dynamic outsourced databases. S&P, 2017. 

[22]  M. Backes, et al. CSAR. A Practical and Provable Technique to Make 

Randomized Systems Accountable. In NDSS, vol. 9. 2009. 

[23]  R.  Ladjel,  et  al.  Trustworthy  Distributed  Computations  on  Personal 

Data. Inria report. http://petrus.inria.fr/~anciaux/papers/TR.pdf,  2019. 

