Rewriting the Infinite Chase
Michael Benedikt, Maxime Buron, Stefano Germano, Kevin Kappelmann,

Boris Motik

To cite this version:

Michael Benedikt, Maxime Buron, Stefano Germano, Kevin Kappelmann, Boris Motik. Rewriting
the Infinite Chase. VLDB 2022 - 48th International Conference on Very Large Databases, Sep 2022,
Sydney, Australia. pp.3045-3057, ï¿¿10.14778/3551793.3551851ï¿¿. ï¿¿lirmm-03714595ï¿¿

HAL Id: lirmm-03714595

https://hal-lirmm.ccsd.cnrs.fr/lirmm-03714595

Submitted on 5 Jul 2022

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

Lâ€™archive ouverte pluridisciplinaire HAL, est
destinÃ©e au dÃ©pÃ´t et Ã  la diffusion de documents
scientifiques de niveau recherche, publiÃ©s ou non,
Ã©manant des Ã©tablissements dâ€™enseignement et de
recherche franÃ§ais ou Ã©trangers, des laboratoires
publics ou privÃ©s.

Distributed under a Creative Commons Attribution - NonCommercial - NoDerivatives 4.0
International License

Rewriting the Infinite Chase

Michael Benedikt
Oxford University
Oxford, United Kingdom
michael.benedikt@cs.ox.ac.uk

Maxime Buron
LIRMM, Inria, Univ. of Montpellier
Montpellier, France
maxime.buron@inria.fr

Stefano Germano
Oxford University
Oxford, United Kingdom
stefano.germano@cs.ox.ac.uk

Kevin Kappelmann
Technical University of Munich
Munich, Germany
kevin.kappelmann@tum.de

Boris Motik
Oxford University
Oxford, United Kingdom
boris.motik@cs.ox.ac.uk

ABSTRACT
Guarded tuple-generating dependencies (GTGDs) are a natural ex-
tension of description logics and referential constraints. It has long
been known that queries over GTGDs can be answered by a variant
of the chaseâ€”a quintessential technique for reasoning with depen-
dencies. However, there has been little work on concrete algorithms
and even less on implementation. To address this gap, we revisit
Datalog rewriting approaches to query answering, where GTGDs
are transformed to a Datalog program that entails the same base
facts on each base instance. We show that the rewriting can be
seen as containing â€œshortcutâ€ rules that circumvent certain chase
steps, we present several algorithms that compute the rewriting by
simulating specific types of chase steps, and we discuss important
implementation issues. Finally, we show empirically that our tech-
niques can process complex GTGDs derived from synthetic and
real benchmarks and are thus suitable for practical use.

PVLDB Reference Format:
Michael Benedikt, Maxime Buron, Stefano Germano, Kevin Kappelmann,
and Boris Motik. Rewriting the Infinite Chase. PVLDB, 15(11): XXX-XXX,
2022.
doi:XX.XX/XXX.XX

PVLDB Artifact Availability:
The source code, data, and/or other artifacts have been made available at
https://github.com/KRR-Oxford/Guarded-saturation.

1 INTRODUCTION
Tuple-generating dependencies (TGDs) are a natural extension of
description logics and referential constraints, and they are exten-
sively used in databases. For example, they are used in data integra-
tion to capture semantic restrictions on data sources, mapping rules
between data sources and the mediated schema, and constraints
on the mediated schema. A fundamental computational problem in
such applications is query answering under TGDs: given a query ğ‘„,
a collection of facts ğ¼ , and a set of TGDs Î£, find all the answers to
ğ‘„ that logically follow from ğ¼ and Î£. This problem has long been
seen as a key component of a declarative data integration systems

This work is licensed under the Creative Commons BY-NC-ND 4.0 International
License. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to view a copy of
this license. For any use beyond those covered by this license, obtain permission by
emailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights
licensed to the VLDB Endowment.
Proceedings of the VLDB Endowment, Vol. 15, No. 11 ISSN 2150-8097.
doi:XX.XX/XXX.XX

[25, 33], and it also arises in answering querying using views and
accessing data sources with restrictions [20, 26, 37].

The chase is a quintessential technique for reasoning with TGDs.
It essentially performs â€œforward reasoningâ€ by extending a set of
given facts ğ¼ to a set ğ¼ â€² of all facts implied by ğ¼ and a set of TGDs Î£.
To answer a query, one can compute ğ¼ â€² using the chase and then
evaluate the query in ğ¼ â€². Unfortunately, the chase does not neces-
sarily terminate, and in fact query answering for general TGDs is
undecidable. Considerable effort was devoted to identifying classes
of TGDs for which query answering is decidable. One line of work
has focused on TGDs where the chase terminates; weakly-acyclic
TGDs [21] are perhaps the best-known such class. Another line of
work focused on guarded TGDs (GTGDs). GTGDs are interesting
since they can capture common constraints used in data integration,
and ontologies expressed in variants of description logic (DL) [6]
can be translated directly into GTGDs. Example 1.1 illustrates the
use of GTGDs used in a practical data integration scenario.

Example 1.1. The IEC Common Information Model (CIM) is
an open model for describing power generation and distribution
networks. It is frequently used as a semantic layer in applications
that integrate data about power systems [22]. CIM is defined in UML,
but its formal semantics has been provided by a translation into
an OWL ontology. The domain of CIM is described using classes
and properties, which correspond to unary and binary relations,
respectively. Moreover, semantic relationships between classes and
properties are represented as OWL axioms, many of which can
be translated into GTGDs. A significant portion of CIM describes
power distribution equipment using GTGDs such as (1)â€“(4).
ACEquipment(ğ‘¥) â†’ âˆƒğ‘¦ hasTerminal(ğ‘¥, ğ‘¦) âˆ§ ACTerminal(ğ‘¦) (1)
ACTerminal(ğ‘¥) â†’ Terminal(ğ‘¥) (2)
hasTerminal(ğ‘¥, ğ‘§) âˆ§ Terminal(ğ‘§) â†’ Equipment(ğ‘¥) (3)
ACTerminal(ğ‘¥) â†’ âˆƒğ‘¦ partOf(ğ‘¥, ğ‘¦) âˆ§ ACEquipment(ğ‘¦) (4)

Data integration is then achieved by populating the vocabulary
using mappings, which can be seen queries over the data sources
that produce a set of facts called a base instance. A key issue in
data integration is dealing with incompleteness of data sources.
For example, it is not uncommon that one data source mentions
two switches sw1 and sw2, while another data source provides
information about connected terminals only for switch sw1.

ACEquipment(sw1) ACEquipment(sw2)
hasTerminal(sw1, trm1) ACTerminal(trm1)

(5)

(6)

GTGDs can be used to complete the data. For example, if a user
asks to list all pieces of equipment known to the system, both sw1
and sw2 will be returned, even though the base instance does not
âŠ³
explicitly classify either switch as a piece of equipment.

Even though the chase for GTGDs does not necessarily terminate,
query answering for GTGDs is decidable [34]. To prove decidability,
one can argue that the result of a chase is tree-likeâ€”that is, the
facts derived by the chase can be arranged into a particular kind
of tree. Next, one can develop a finite representation of potentially
infinite trees. One possibility is to describe the trees using a finite
tree automaton, so query answering can be reduced to checking
automaton emptiness. While theoretically elegant, this method
is not amenable to practical use: building the automaton and the
emptiness test are both complex and expensive, and such algorithms
always exhibit worst-case complexity. Alternatively, one can use
blocking to identify a tree prefix sufficient for query evaluation.
Blocking is commonly used in description logic reasoning [6], and
it was later lifted to guarded logic [27]. However, blocking was
shown to be impractical for query answering: the required tree
prefix can be much larger than the base instance ğ¼ so, as ğ¼ grows in
size, the size of the tree prefix becomes unmanageable.

More promising query answering techniques for GTGDs are
based on Datalog rewriting [35]. The idea was initially proposed by
Marnette [35], and it was later extended to broader classes of TGDs
[10, 24] and settings [11]. The main idea is to transform an input
set of GTGDs Î£ into a set rew(Î£) of Datalog rules such that Î£ and
rew(Î£) entail the same base facts on each base instance. Thus, given
a base instance ğ¼ , instead of computing the chase of ğ¼ and Î£ (which
may not terminate), we compute the chase ğ¼ â€² of ğ¼ and rew(Î£). Since
Datalog rules essentially correspond to existential-free TGDs, ğ¼ â€²
is always finite and it can be computed using optimized Datalog
engines. Moreover, Î£ and rew(Î£) entail the same base facts on ğ¼ , so
we can answer any existential-free conjunctive query (i.e., queries
where all variables are answer variables) by evaluating in ğ¼ â€². The
restriction to existential-free queries is technical: existentially quan-
tified variables in a query can be matched to objects introduced by
existential quantification, and these are not preserved in a Datalog
rewriting. However, practical queries are typically existential-free
since all query variables are usually answer variables.

Example 1.2. A Datalog program consisting of rules (2)â€“(3) and

(7) is a rewriting of GTGDs (1)â€“(4).

ACEquipment(ğ‘¥) â†’ Equipment(ğ‘¥)

(7)

Rule (7) is a logical consequence of GTGDs (1)â€“(3), and it provides
âŠ³
a â€œshortcutâ€ for the inferences of the other GTGDs.

The advantage of rewriting-based approaches is scalability in the
size of the base instance ğ¼ . Such techniques have been implemented
and practically validated in the context of description logics [28, 29],
but practical algorithms have not yet been proposed for GTGDs.
This raises several theoretical and practical questions.

How to compute the Datalog rules needed for completeness?
Existing Datalog rewriting algorithms often prove their correctness
indirectly. For example, completeness of a rewriting algorithm for
description logics [29] uses a proof-theoretic argument, which does
not provide an intuition about why the algorithm actually works.

Our first contribution is to relate Datalog rewriting approaches to the
chase. Towards this goal, we introduce the one-pass variant of the
chase, which we use to develop a general completeness criterion
for Datalog rewriting algorithms. This, in turn, provides us with
a better understanding of how rewriting algorithms work, and it
allows us to discover new algorithms in a systematic way.

What does the space of rewriting algorithms look like? Com-
puting the rewriting rew(Î£) usually requires extending Î£ with
certain logical consequences of Î£. We show that we can select the
relevant consequences using different criteria. Some methods re-
quire deriving TGDs with existential quantifiers in the head, others
generate Datalog rules directly, and yet other methods derive logical
implications with function symbols. We relate all of these methods
to the one-pass chase mentioned earlier, and we provide theoretical
worst-case guarantees about their performance.

How do we ensure scalability of rewriting algorithms? Im-
plementations of Datalog rewriting algorithms have thus far been
mainly considered in the setting of description logics [29, 38]. To
the best of our knowledge, we provide the first look at optimization
and implementation of Datalog rewriting algorithms for GTGDs. We
achieve scalability by developing and combining various indexing
and redundancy elimination techniques.

How do we evaluate rewriting algorithms? We provide a bench-
mark for GTGD query answering algorithms, and we use it to eval-
uate our methods. To the best of our knowledge, this is the first
attempt to evaluate query answering techniques for GTGDs.

Summary of contributions. We give an extensive account of Dat-
alog rewriting for GTGDs. In particular, we develop a theoretical
framework that allows us to understand, motivate, and show com-
pleteness of rewriting algorithms. Moreover, we present several
concrete algorithms, establish worst-case complexity bounds, and
discuss their relationships. We complement this theoretical analy-
sis with a discussion of how to adapt techniques from first-order
theorem proving to the setting of GTGDs. Finally, we empirically
evaluate our techniques using an extensive benchmark. All proofs
and the details of one algorithm are given in the appendix of this
paper. Our implementation and a more detailed account of our
experimental results can be found online [13].

2 RELATED WORK
Answering queries via rewriting has been extensively considered
in description logics. For example, queries over ontologies in the
DL-Lite family of languages can be rewritten into first-order queries
[18], and fact entailment for SH IQ ontologies can be rewritten to
disjunctive Datalog [29]. These techniques provide the foundation
for the Ontop [17] and KAON2 [38] systems, respectively.

In the context of TGDs, first-order rewritings were considered in
data integration systems with inclusion and key dependencies [16].
Datalog rewritings have been considered for GTGDs [35] and their
extensions such as frontier-guarded TGDs [11], and nearly frontier-
guarded and nearly guarded TGDs [24]. The focus in these studies
was to identify complexity bounds and characterize expressivity of
TGD classes rather than provide practical algorithms. Existing im-
plements of query answering for TGDs use first-order rewriting for
linear TGDs [48], chase variants for TGDs with terminating chase

[14], chase with blocking for warded TGDs [12], chase with the
magic sets transformation for shy TGDs [3], and Datalog rewriting
for separable and weakly separable TGDs [49]. These TGD classes
are all different from GTGDs, and we are unaware of any attempts
to implement and evaluate GTGD rewriting algorithms.

Our algorithms are related to resolution-based decision proce-
dures for variants of guarded logics [19, 23, 50]. Moreover, our
characterization of Datalog rewritings is related to a chase vari-
ant used to answer queries over data sources with access patterns
[4]. Finally, a variant of the one-pass chase from Section 4 was
generalized to the broader context of disjunctive GTGDs [31].

3 PRELIMINARIES
In this section, we recapitulate the well-known definitions and
notation that we use to formalize our technical results.

TGDs. Let consts, vars, and nulls be pairwise disjoint, infinite sets
of constants, variables, and labeled nulls, respectively. A term is a
constant, a variable, or a labeled null; moreover, a term is ground
if it does not contain a variable. For ğ›¼ a formula or a set thereof,
consts(ğ›¼), vars(ğ›¼), nulls(ğ›¼), and terms(ğ›¼) are the sets of constants,
free variables, labeled nulls, and terms, respectively, in ğ›¼.

A schema is a set of relations, each of which is associated with a
nonnegative integer arity. A fact is an expression of the form ğ‘…((cid:174)ğ‘¡),
where ğ‘… is an ğ‘›-ary relation and (cid:174)ğ‘¡ is a vector of ğ‘› ground terms;
moreover, ğ‘…((cid:174)ğ‘¡) is a base fact if (cid:174)ğ‘¡ contains only constants. An instance
ğ¼ is a finite set of facts, and ğ¼ is a base instance if it contains only
base facts. An atom is an expression of the form ğ‘…((cid:174)ğ‘¡), where ğ‘… is
an ğ‘›-ary relation and (cid:174)ğ‘¡ is a vector of ğ‘› terms not containing labeled
nulls. Thus, each base fact is an atom. We often treat conjunctions
as sets of conjuncts; for example, for ğ›¾ a conjunction of facts and ğ¼
an instance, ğ›¾ âŠ† ğ¼ means that each conjunct of ğ›¾ is contained ğ¼ .

A tuple generating dependency (TGD) is a first-order formula of
the form âˆ€(cid:174)ğ‘¥ [ğ›½ â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚], where ğ›½ and ğœ‚ are conjunctions of atoms,
ğœ‚ is not empty, the free variables of ğ›½ are (cid:174)ğ‘¥, and the free variables
of ğœ‚ are contained in (cid:174)ğ‘¥ âˆª (cid:174)ğ‘¦. Conjunction ğ›½ is the body and formula
âˆƒ(cid:174)ğ‘¦ ğœ‚ is the head of the TGD. We often omit âˆ€(cid:174)ğ‘¥ when writing a
TGD. A TGD is full if (cid:174)ğ‘¦ is empty; otherwise, the TGD is non-full.
A TGD is in head-normal form if it is full and its head contains
exactly one atom, or it is non-full and each head atom contains at
least one existentially quantified variable. Each TGD can be easily
transformed to an equivalent set of TGDs in head-normal form.
A full TGD in head-normal form is a Datalog rule, and a Datalog
program is a finite set of Datalog rules. The head-width (hwidth) and
the body-width (bwidth) of a TGD are the numbers of variables in
the head and body, respectively; these are extended to sets of TGDs
by taking the maxima over all TGDs. The notion of an instance
satisfying a TGD is inherited from first-order logic. A base fact ğ¹ is
entailed by an instance ğ¼ and a finite set of TGDs Î£, written ğ¼, Î£ |= ğ¹ ,
if ğ¹ âˆˆ ğ¼ â€² holds for each instance ğ¼ â€² âŠ‡ ğ¼ that satisfies Î£.

A substitution ğœ is a function that maps finitely many variables
to terms. The domain and the range of ğœ are dom(ğœ) and rng(ğœ),
respectively. For ğ›¾ a term, a vector of terms, or a formula, ğœ (ğ›¾) is
obtained by replacing each free occurrence of a variable ğ‘¥ in ğ›¾ such
that ğ‘¥ âˆˆ dom(ğœ) with ğœ (ğ‘¥).

Fact Entailment for Guarded TGDs. Fact entailment for general
TGDs is semidecidable, and many variants of the chase can be used

to define a (possibly infinite) set of facts that is homomorphically
contained in each modef of a base instance and a set of TGDs.

Fact entailment is decidable for guarded TGDs (GTGDs): a TGD
âˆ€(cid:174)ğ‘¥ [ğ›½ â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚] is guarded if ğ›½ contains an atom (called a guard) that
contains all variables of (cid:174)ğ‘¥. Note that a guard need not be unique in
ğ›½. Let Î£ be a finite set of GTGDs. We say that a set of ground terms
ğº is Î£-guarded by a fact ğ‘…((cid:174)ğ‘¡) if ğº âŠ† (cid:174)ğ‘¡ âˆª consts(Î£). Moreover, ğº is
Î£-guarded by a set of facts ğ¼ if ğº is Î£-guarded by some fact in ğ¼ .
Finally, a fact ğ‘† ( (cid:174)ğ‘¢) is Î£-guarded by a fact ğ‘…((cid:174)ğ‘¡) (respectively a set of
facts ğ¼ ) if (cid:174)ğ‘¢ is Î£-guarded by ğ‘…((cid:174)ğ‘¡) (respectively ğ¼ ).

By adapting the reasoning techniques for guarded logics [5, 47]
and referential database constraints [30], fact entailment for GTGDs
can be decided by a chase variant that works on tree-like structures.
A chase tree ğ‘‡ consists of a directed tree, one tree vertex that is said
to be recently updated, and a function mapping each vertex ğ‘£ in the
tree to a finite set of facts ğ‘‡ (ğ‘£). A chase tree ğ‘‡ can be transformed
to another chase tree ğ‘‡ â€² in the following two ways.
â€¢ One can apply a chase step with a GTGD ğœ = âˆ€(cid:174)ğ‘¥ [ğ›½ â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚] in
head-normal form. The precondition is that there exist a vertex
ğ‘£ in ğ‘‡ and a substitution ğœ with domain (cid:174)ğ‘¥ such that ğœ (ğ›½) âŠ† ğ‘‡ (ğ‘£).
The result of the chase step is obtained as follows.
â€“ If ğœ is full (and thus ğœ‚ is a single atom), then chase tree ğ‘‡ â€²
is obtained from ğ‘‡ by making ğ‘£ recently updated in ğ‘‡ â€² and
setting ğ‘‡ â€² (ğ‘£) = ğ‘‡ (ğ‘£) âˆª {ğœ (ğœ‚)}.

â€“ If ğœ is not full, then ğœ is extended to a substitution ğœ â€² that
maps each variable in (cid:174)ğ‘¦ to a labeled null not occurring in ğ‘‡ ,
and chase tree ğ‘‡ â€² is obtained from ğ‘‡ by introducing a fresh
child ğ‘£ â€² of ğ‘£, making ğ‘£ â€² recently updated in ğ‘‡ â€², and setting
ğ‘‡ (ğ‘£ â€²) = ğœ â€² (ğœ‚) âˆª {ğ¹ âˆˆ ğ‘‡ (ğ‘£) | ğ¹ is Î£-guarded by ğœ â€² (ğœ‚)}.
â€¢ One can apply a propagation step from a vertex ğ‘£ to a vertex ğ‘£ â€²
in ğ‘‡ . Chase tree ğ‘‡ â€² is obtained from ğ‘‡ by making ğ‘£ â€² recently
updated in ğ‘‡ â€² and setting ğ‘‡ â€² (ğ‘£ â€²) = ğ‘‡ (ğ‘£ â€²) âˆª ğ‘† for some nonempty
set ğ‘† satisfying ğ‘† âŠ† {ğ¹ âˆˆ ğ‘‡ (ğ‘£) | ğ¹ is Î£-guarded by ğ‘‡ (ğ‘£ â€²)}.
A tree-like chase sequence for a base instance ğ¼ and a finite set of
GTGDs Î£ in head-normal form is a finite sequence of chase trees
ğ‘‡0, . . . ,ğ‘‡ğ‘› such that ğ‘‡0 contains exactly one root vertex ğ‘Ÿ that is
recently updated in ğ‘‡0 and ğ‘‡0 (ğ‘Ÿ ) = ğ¼ , and each ğ‘‡ğ‘– with 0 < ğ‘– â‰¤ ğ‘›
is obtained from ğ‘‡ğ‘– âˆ’1 by a chase step with some ğœ âˆˆ Î£ or a prop-
agation step. For each vertex ğ‘£ in ğ‘‡ğ‘› and each fact ğ¹ âˆˆ ğ‘‡ğ‘› (ğ‘£), this
sequence is a tree-like chase proof of ğ¹ from ğ¼ and Î£. It is well known
that ğ¼, Î£ |= ğ¹ if and only if there exists a tree-like chase proof of ğ¹
from ğ¼ and Î£ (e.g., [34]). Example 4.3 in Section 4 illustrates these
definitions. One can decide ğ¼, Î£ |= ğ¹ by imposing an upper bound
on the size of chase trees that need to be considered [34].
Rewriting. A Datalog rewriting of a finite set of TGDs Î£ is a Datalog
program rew(Î£) such that ğ¼, Î£ |= ğ¹ if and only if ğ¼, rew(Î£) |= ğ¹ for
each base instance ğ¼ and each base fact ğ¹ . If Î£ contains GTGDs only,
then a Datalog rewriting rew(Î£) is guaranteed to exist (which is
not the case for general TGDs). Thus, we can reduce fact entailment
for GTGDs to Datalog reasoning, which can be solved using highly
optimized Datalog techniques [1, 38]. For example, given a base
instance ğ¼ , we can compute the materialization of rew(Î£) on ğ¼ by
applying the rules of rew(Î£) to ğ¼ up to a fixpoint. This will compute
precisely all base facts entailed by rew(Î£) (and thus also by Î£) on ğ¼ ,
and it can be done in time polynomial in the size of ğ¼ .

Encoding Existentials by Function Symbols. It is sometimes
convenient to represent existentially quantified values using func-
tional terms. In such cases, we use a slightly modified notions of
terms, atoms, and rules. It will be clear from the context which
definitions we use in different parts of the paper.

We adjust the notion of a term as either a constant, a variable,
or an expression of the form ğ‘“ ((cid:174)ğ‘¡) where ğ‘“ is an ğ‘›-ary function
symbol and (cid:174)ğ‘¡ is a vector of ğ‘› terms. The notions of ground terms,
(base) facts, and (base) instances, and atoms are the same as before,
but they use the modified notion of terms. A rule is a first-order
implication of the form âˆ€(cid:174)ğ‘¥ [ğ›½ â†’ ğ» ] where ğ›½ is a conjunction of
atoms whose free variables are (cid:174)ğ‘¥, and ğ» is an atom whose free
variables are contained in (cid:174)ğ‘¥; as for TGDs, we often omit âˆ€(cid:174)ğ‘¥. A
rule thus contains no existential quantifiers, but its head contains
exactly one atom that can contain function symbols. Also, a Datalog
rule, a function-free rule, and a full TGD in head-normal form are
all synonyms. Finally, a base fact still contains only constants.

Skolemization allow us to replace existential quantifiers in TGDs
by functional terms. Specifically, let ğœ = âˆ€(cid:174)ğ‘¥ [ğ›½ â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚], and let ğœ
be a substitution defined on each ğ‘¦ âˆˆ (cid:174)ğ‘¦ as ğœ (ğ‘¦) = ğ‘“ğœ,ğ‘¦ ( (cid:174)ğ‘¥) where
ğ‘“ğœ,ğ‘¦ is a fresh | (cid:174)ğ‘¥ |-ary Skolem symbol uniquely associated with ğœ
and ğ‘¦. Then, the Skolemization of ğœ produces rules âˆ€(cid:174)ğ‘¥ [ğ›½ â†’ ğœ (ğ» )]
for each atom ğ» âˆˆ ğœ‚. Moreover, the Skolemization Î£â€² of a finite set
of TGDs Î£ is the union of the rules obtained by Skolemizing each
ğœ âˆˆ Î£. It is well known that ğ¼, Î£ |= ğ¹ if and only if ğ¼, Î£â€² |= ğ¹ for each
base instance ğ¼ and each base fact ğ¹ .
Unification. A unifier of atoms ğ´1, . . . , ğ´ğ‘› and ğµ1, . . . , ğµğ‘› is a
substitution ğœƒ such that ğœƒ (ğ´ğ‘– ) = ğœƒ (ğµğ‘– ) for 1 â‰¤ ğ‘– â‰¤ ğ‘›. Such ğœƒ is a
most general unifier (MGU) if, for each unifier ğœ of ğ´1, . . . , ğ´ğ‘› and
ğµ1, . . . , ğµğ‘›, there exists a substitution ğœŒ such that ğœ = ğœŒ â—¦ ğœƒ (where
â—¦ is function composition). An MGU is unique up to variable renam-
ing if it exists, and it can be computed in time ğ‘‚ ((cid:205)ğ‘›
ğ‘–=1 |ğ´ğ‘– | + |ğµğ‘– |)
where |ğ´ğ‘– | and |ğµğ‘– | are the encoding sizes of ğ´ğ‘– and ğµğ‘– [41, 42].

4 CHASE-BASED DATALOG REWRITING
Our objective is to develop rewriting algorithms that can handle
complex GTGDs. Each algorithm will derive Datalog rules that
provide â€œshortcutsâ€ in tree-like chase proofs: instead of introduc-
ing a child vertex ğ‘£ â€² using a chase step with a non-full GTGD at
vertex ğ‘£, performing some inferences in ğ‘£ â€², and then propagating a
derived fact ğ¹ back from ğ‘£ â€² to ğ‘£, these â€œshortcutsâ€ will derive ğ¹ in
one step without having to introduce ğ‘£ â€². The main question is how
to derive all â€œshortcutsâ€ necessary for completeness while keeping
the number of derivations low. In this section we lay the technical
foundations that will allow us to study different strategies for deriv-
ing â€œshortcutsâ€ in Section 5. We show that, instead of considering
arbitrary chase proofs, we can restrict our attention to chase proofs
that are one-pass according to Definition 4.1. Then, we identify the
parts of such proofs that we need to be able to circumvent using
â€œshortcutsâ€. Finally, we present sufficient conditions that guaran-
tee completeness of rewriting algorithms. We start by describing
formally the structure of tree-like chase proofs.
Definition 4.1. A tree-like chase sequence ğ‘‡0, . . . ,ğ‘‡ğ‘› for a base
instance ğ¼ and a finite set of GTGDs Î£ in head-normal form is one-
pass if, for each 0 < ğ‘– â‰¤ ğ‘›, chase tree ğ‘‡ğ‘– is obtained by applying one
of the following two steps to the recently updated vertex ğ‘£ of ğ‘‡ğ‘– âˆ’1:

ğ‘‡0

ğ´(ğ‘, ğ‘)

ğ‘‡1

ğ´(ğ‘, ğ‘)

ğµ(ğ‘, ğ‘›1)
ğ¶ (ğ‘, ğ‘›1)

ğ‘‡2

ğ´(ğ‘, ğ‘)

ğµ(ğ‘, ğ‘›1)
ğ¶ (ğ‘, ğ‘›1)
ğ· (ğ‘, ğ‘›1)

ğ‘‡3

ğ´(ğ‘, ğ‘)

ğµ(ğ‘, ğ‘›1)
ğ¶ (ğ‘, ğ‘›1)
ğ· (ğ‘, ğ‘›1)
ğ¸ (ğ‘)

ğ‘‡4

ğ´(ğ‘, ğ‘)
ğ¸ (ğ‘)

ğµ(ğ‘, ğ‘›1)
ğ¶ (ğ‘, ğ‘›1)
ğ· (ğ‘, ğ‘›1)
ğ¸ (ğ‘)

ğ‘‡5

ğ´(ğ‘, ğ‘)
ğ¸ (ğ‘)

ğµ(ğ‘, ğ‘›1)
ğ¶ (ğ‘, ğ‘›1)
ğ· (ğ‘, ğ‘›1)
ğ¸ (ğ‘)

ğ¸ (ğ‘)
ğ¹ (ğ‘, ğ‘›2)
ğ¹ (ğ‘›2, ğ‘›3)

ğ‘‡6

ğ´(ğ‘, ğ‘)
ğ¸ (ğ‘)

ğµ(ğ‘, ğ‘›1)
ğ¶ (ğ‘, ğ‘›1)
ğ· (ğ‘, ğ‘›1)
ğ¸ (ğ‘)

ğ¸ (ğ‘)
ğ¹ (ğ‘, ğ‘›2)
ğ¹ (ğ‘›2, ğ‘›3)
ğº (ğ‘)

ğ‘‡7

ğ´(ğ‘, ğ‘)
ğ¸ (ğ‘)

ğµ(ğ‘, ğ‘›1)
ğ¶ (ğ‘, ğ‘›1)
ğ· (ğ‘, ğ‘›1)
ğ¸ (ğ‘)
ğº (ğ‘)

ğ¸ (ğ‘)
ğ¹ (ğ‘, ğ‘›2)
ğ¹ (ğ‘›2, ğ‘›3)
ğº (ğ‘)

ğ‘‡8

ğ´(ğ‘, ğ‘)
ğ¸ (ğ‘)

ğ¸ (ğ‘)
ğ¹ (ğ‘, ğ‘›2)
ğ¹ (ğ‘›2, ğ‘›3)
ğº (ğ‘)

ğµ(ğ‘, ğ‘›1)
ğ¶ (ğ‘, ğ‘›1)
ğ· (ğ‘, ğ‘›1)
ğ¸ (ğ‘)
ğº (ğ‘)
ğ» (ğ‘)

Figure 1: Tree-Like Chase Sequence for Example 4.3

â€¢ a propagation step copying exactly one fact from ğ‘£ to its parent, or
â€¢ a chase step with a GTGD from Î£ provided that no propagation

step from ğ‘£ to the parent of ğ‘£ is applicable.

Thus, each step in a tree-like chase sequence is applied to a â€œfo-
cusedâ€ vertex; steps with non-full TGDs move the â€œfocusâ€ from a
parent to a child, and propagation steps move the â€œfocusâ€ in the op-
posite direction. Moreover, once a child-to-parent propagation takes
place, the child cannot be revisited in further steps. Theorem 4.2
states a key property about chase proofs for GTGDs: whenever a
proof exists, there exists a one-pass proof too. Example 4.3 illus-
trates important aspects of Definition 4.1 and Theorem 4.2.

Theorem 4.2. For each base instance ğ¼ , each finite set of GTGDs Î£
in head-normal form, and each base fact ğ¹ such that ğ¼, Î£ |= ğ¹ , there
exists a one-pass tree-like chase proof of ğ¹ from ğ¼ and Î£.

Example 4.3. Let ğ¼ = {ğ´(ğ‘, ğ‘)} and let Î£ contain GTGDs (8)â€“(13).
ğ´(ğ‘¥1, ğ‘¥2) â†’ âˆƒğ‘¦ ğµ(ğ‘¥1, ğ‘¦) âˆ§ ğ¶ (ğ‘¥1, ğ‘¦)
ğ¶ (ğ‘¥1, ğ‘¥2) â†’ ğ· (ğ‘¥1, ğ‘¥2)

(9)

(8)

(10)

(11)

(12)

ğµ(ğ‘¥1, ğ‘¥2) âˆ§ ğ· (ğ‘¥1, ğ‘¥2) â†’ ğ¸ (ğ‘¥1)

ğ´(ğ‘¥1, ğ‘¥2) âˆ§ ğ¸ (ğ‘¥1) â†’ âˆƒğ‘¦1, ğ‘¦2 ğ¹ (ğ‘¥1, ğ‘¦1) âˆ§ ğ¹ (ğ‘¦1, ğ‘¦2)
ğ¸ (ğ‘¥1) âˆ§ ğ¹ (ğ‘¥1, ğ‘¥2) â†’ ğº (ğ‘¥1)
ğµ(ğ‘¥1, ğ‘¥2) âˆ§ ğº (ğ‘¥1) â†’ ğ» (ğ‘¥1)

(13)
A tree-like chase sequence for ğ¼ and Î£ is shown in Figure 1,
and it provides a proof of the base fact ğ» (ğ‘) from ğ¼ and Î£. The
recently updated vertex of each chase tree is shown in red. We
denote the root vertex by ğ‘Ÿ , and its left and right children by ğ‘£1 and
ğ‘£2, respectively. The step producing ğ‘‡7 from ğ‘‡6 does not satisfy the
requirements of one-pass chase: it propagates the fact ğº (ğ‘) from
ğ‘£2 to ğ‘£1, where the latter is a â€œsiblingâ€ of the former.

To obtain a one-pass chase sequence, we could try to â€œslow downâ€
the propagation of ğº (ğ‘): we first propagate ğº (ğ‘) from ğ‘£2 to ğ‘Ÿ , and
then from ğ‘Ÿ to ğ‘£1. The former step is allowed in one-pass chase,
but the latter step is not: once we leave the subtree rooted at ğ‘£1,
we are not allowed to revisit it later. Note, however, that ğµ(ğ‘, ğ‘›1)
and ğº (ğ‘) must occur jointly in a vertex of a chase tree in order to
derive ğ» (ğ‘). Moreover, note that no reordering of chase steps will

ğ‘‡ 1
7

ğ´(ğ‘, ğ‘)
ğ¸ (ğ‘)
ğº (ğ‘)

ğ‘‡ 2
7

ğ´(ğ‘, ğ‘)
ğ¸ (ğ‘)
ğº (ğ‘)

ğµ(ğ‘, ğ‘›1)
ğ¶ (ğ‘, ğ‘›1)
ğ· (ğ‘, ğ‘›1)
ğ¸ (ğ‘)

ğ¸ (ğ‘)
ğ¹ (ğ‘, ğ‘›2)
ğ¹ (ğ‘›2, ğ‘›3)
ğº (ğ‘)

ğµ(ğ‘, ğ‘›1)
ğ¶ (ğ‘, ğ‘›1)
ğ· (ğ‘, ğ‘›1)
ğ¸ (ğ‘)

ğ¸ (ğ‘)
ğ¹ (ğ‘, ğ‘›2)
ğ¹ (ğ‘›2, ğ‘›3)
ğº (ğ‘)

ğµ(ğ‘, ğ‘›3)
ğ¶ (ğ‘, ğ‘›3)
ğ¸ (ğ‘)
ğº (ğ‘)

ğ‘‡ 1
8

ğ´(ğ‘, ğ‘)
ğ¸ (ğ‘)
ğº (ğ‘)

ğ‘‡9

ğ´(ğ‘, ğ‘)
ğ¸ (ğ‘)
ğº (ğ‘)
ğ» (ğ‘)

ğµ(ğ‘, ğ‘›1)
ğ¶ (ğ‘, ğ‘›1)
ğ· (ğ‘, ğ‘›1)
ğ¸ (ğ‘)

ğ¸ (ğ‘)
ğ¹ (ğ‘, ğ‘›2)
ğ¹ (ğ‘›2, ğ‘›3)
ğº (ğ‘)

ğµ(ğ‘, ğ‘›3)
ğ¶ (ğ‘, ğ‘›3)
ğ¸ (ğ‘)
ğº (ğ‘)
ğ» (ğ‘)

ğµ(ğ‘, ğ‘›1)
ğ¶ (ğ‘, ğ‘›1)
ğ· (ğ‘, ğ‘›1)
ğ¸ (ğ‘)

ğ¸ (ğ‘)
ğ¹ (ğ‘, ğ‘›2)
ğ¹ (ğ‘›2, ğ‘›3)
ğº (ğ‘)

ğµ(ğ‘, ğ‘›3)
ğ¶ (ğ‘, ğ‘›3)
ğ¸ (ğ‘)
ğº (ğ‘)
ğ» (ğ‘)

Figure 2: One-Pass Chase Sequence Obtained from Figure 1

derive ğ» (ğ‘): we must first produce ğ‘£1 to be able to derive ğ‘£2, and
we must combine ğº (ğ‘) from ğ‘£2 and ğµ(ğ‘, ğ‘›1) from ğ‘£1.

The solution, which is used in the proof of Theorem 4.2, is to
replace propagation to the child by â€œregrowingâ€ the entire subtree.
In our example, we replace the steps producing ğ‘‡7 and ğ‘‡8 with
the steps shown in Figure 2. Chase tree ğ‘‡ 1
7 is obtained from ğ‘‡6 by
propagating ğº (ğ‘) from ğ‘£2 to ğ‘Ÿ . Then, instead of propagating ğº (ğ‘)
from ğ‘Ÿ to ğ‘£1, a new vertex ğ‘£3 is created in ğ‘‡ 2
7 by reapplying (8) and
fact ğº (ğ‘) is pushed to ğ‘£3 as part of the chase step with a non-full
GTGD. This allows ğ» (ğ‘) to be derived in vertex ğ‘£3 of ğ‘‡ 1
8 .

Fact ğ· (ğ‘›3) can be derived in vertex ğ‘£3, but this is not needed to
prove ğ» (ğ‘). Moreover, our chase is oblivious [34]: a non-full TGD
can be applied to the same facts several times, each time introducing
a fresh vertex and fresh labeled nulls. The number of children of
a vertex is thus not naturally bounded, and our objective is not to
apply all chase steps exhaustively to obtain a universal model of
Î£. Instead, we are interested only in chase proofs, which must only
contain steps needed to demonstrate entailment of a specific fact. âŠ³

One-pass chase proofs are interesting because they can be de-

composed into loops as described in Definition 4.4.

Definition 4.4. For ğ‘‡0, . . . ,ğ‘‡ğ‘› a one-pass tree-like chase sequence for
some ğ¼ and Î£, a loop at vertex ğ‘£ with output fact ğ¹ is a subsequence
ğ‘‡ğ‘–, . . . ,ğ‘‡ğ‘— with 0 â‰¤ ğ‘– < ğ‘— â‰¤ ğ‘› such that
â€¢ ğ‘‡ğ‘–+1 is obtained by a chase step with a non-full GTGD,
â€¢ ğ‘‡ğ‘— is obtained by a propagation step that copies ğ¹ , and
â€¢ ğ‘£ is the recently updated vertex of both ğ‘‡ğ‘– and ğ‘‡ğ‘— .
The length of the loop is defined as ğ‘— âˆ’ ğ‘–.

Example 4.5. Subsequence ğ‘‡0,ğ‘‡1,ğ‘‡2,ğ‘‡3,ğ‘‡4 of the chase trees from
Example 4.3 is a loop at the root vertex ğ‘Ÿ with output fact ğ¸ (ğ‘): chase
tree ğ‘‡1 is obtained by applying a non-full GTGD to ğ‘Ÿ , and chase
tree ğ‘‡4 is obtained by propagating ğ¸ (ğ‘) back to ğ‘Ÿ . Analogously,
7 is another loop at ğ‘Ÿ with output fact ğº (ğ‘). Finally,
ğ‘‡4,ğ‘‡5,ğ‘‡6,ğ‘‡ 1
âŠ³
,ğ‘‡ 2
ğ‘‡ 1
,ğ‘‡9 is a loop at ğ‘Ÿ with output fact ğ» (ğ‘).
7
7

,ğ‘‡ 1
8

Thus, a loop is a subsequence of chase steps that move the â€œfocusâ€
from a parent to a child vertex, perform a series of inferences in the
child and its descendants, and finally propagate one fact back to

the parent. If non-full TGDs are applied to the child, then the loop
can be recursively decomposed into further loops at the child. The
properties of the one-pass chase ensure that each loop is finished as
soon as a fact is derived in the child that can be propagated to the
parent, and that the vertices introduced in the loop are not revisited
at any later point in the proof. In this way, each loop at vertex ğ‘£ can
be seen as taking the set ğ‘‡ğ‘– (ğ‘£) as input and producing the output
fact ğ¹ that is added to ğ‘‡ğ‘— (ğ‘£). This leads us to the following idea:
for each loop with the input set of facts ğ‘‡ğ‘– (ğ‘£), a rewriting should
contain a â€œshortcutâ€ Datalog rule that derives the loopâ€™s output.

Example 4.6. One can readily check that rules (14)â€“(16) provide

â€œshortcutsâ€ for the three loops identified in Example 4.5.

ğ´(ğ‘¥1, ğ‘¥2) â†’ ğ¸ (ğ‘¥1)
ğ´(ğ‘¥1, ğ‘¥2) âˆ§ ğ¸ (ğ‘¥1) â†’ ğº (ğ‘¥1)
ğ´(ğ‘¥1, ğ‘¥2) âˆ§ ğº (ğ‘¥1) â†’ ğ» (ğ‘¥1)

(14)

(15)

(16)

Moreover, these are all relevant â€œshortcutsâ€: the union of rules (14)â€“
(16) and the Datalog rules from Example 4.3â€”that is, rules (9), (10),
(12), and (13)â€”is a rewriting of the set Î£ from Example 4.1.
âŠ³

These ideas are formalized in Proposition 4.7, which will provide

us with a correctness criterion for our algorithms.

Proposition 4.7. A Datalog program Î£â€² is a rewriting of a finite

set of GTGDs Î£ in head-normal form if
â€¢ Î£â€² is a logical consequence of Î£,
â€¢ each Datalog rule of Î£ is a logical consequence of Î£â€², and
â€¢ for each base instance ğ¼ , each one-pass tree-like chase sequence
ğ‘‡0, . . . ,ğ‘‡ğ‘› for ğ¼ and Î£, and each loop ğ‘‡ğ‘–, . . . ,ğ‘‡ğ‘— at the root vertex ğ‘Ÿ
with output fact ğ¹ , there exist a Datalog rule ğ›½ â†’ ğ» âˆˆ Î£â€² and a
substitution ğœ such that ğœ (ğ›½) âŠ† ğ‘‡ğ‘– (ğ‘Ÿ ) and ğœ (ğ» ) = ğ¹ .

Intuitively, the first condition ensures soundness: rewriting Î£â€²
should not derive more facts than Î£. The second condition ensures
that Î£â€² can mimic direct applications of Datalog rules from Î£ at the
root vertex ğ‘Ÿ . The third condition ensures that Î£â€² can reproduce
the output of each loop at vertex ğ‘Ÿ using a â€œshortcutâ€ Datalog rule.

5 REWRITING ALGORITHMS
We now consider ways to produce â€œshortcutâ€ Datalog rules sat-
isfying Proposition 4.7. In Subsection 5.1 we present the ExbDR
algorithm that manipulates GTGDs directly, and in Subsections 5.2
and 5.3 we present the SkDR and HypDR algorithms, respectively,
that manipulate rules obtained by Skolemizing the input GTGDs.
All of these algorithms can produce intermediate GTGDs/rules that
are not necessarily Datalog rules. In Appendix E we present the
FullDR algorithm that manipulates GTGDs, but derives only Dat-
alog rules. However, the performance of FullDR proved to not be
competitive, so we do not discuss it any further here.

Each algorithm is defined by an inference rule Inf that can be
applied to several TGDs/rules to derive additional TGDs/rules. For
simplicity, we use the same name for the rule and the resulting
algorithm. Given a set of GTGDs Î£, the algorithm applies Inf to
(the Skolemization of) Î£ as long as possible and then returns all
produced Datalog rules. This process, however, can derive a large

number of TGDs/rules, so it is vital to eliminate TGDs/rules when-
ever possible. We next define notions of redundancy that can be
used to discard certain TGDs/rules produced by Inf.
Definition 5.1. A TGD ğœ1 = âˆ€(cid:174)ğ‘¥1 [ğ›½1 â†’ âˆƒ(cid:174)ğ‘¦1 ğœ‚1] is a syntactic tau-
tology if it is in head-normal form and ğ›½1 âˆ© ğœ‚1 â‰  âˆ…. TGD ğœ1 subsumes
a TGD ğœ2 = âˆ€(cid:174)ğ‘¥2 [ğ›½2 â†’ âˆƒ(cid:174)ğ‘¦2 ğœ‚2] if there exists a substitution ğœ‡ such
that dom(ğœ‡) = (cid:174)ğ‘¥1 âˆª (cid:174)ğ‘¦1, ğœ‡ ( (cid:174)ğ‘¥1) âŠ† (cid:174)ğ‘¥2, ğœ‡ ( (cid:174)ğ‘¦1) âŠ† (cid:174)ğ‘¦1 âˆª (cid:174)ğ‘¦2, ğœ‡ (ğ‘¦) â‰  ğœ‡ (ğ‘¦â€²)
for distinct ğ‘¦ and ğ‘¦â€² in (cid:174)ğ‘¦1, ğœ‡ (ğ›½1) âŠ† ğ›½2, and ğœ‡ (ğœ‚1) âŠ‡ ğœ‚2.

A rule ğœ1 = âˆ€(cid:174)ğ‘¥1 [ğ›½1 â†’ ğ»1] is a syntactic tautology if ğ»1 âˆˆ ğ›½1.
Rule ğœ1 subsumes a rule ğœ2 = âˆ€(cid:174)ğ‘¥2 [ğ›½2 â†’ ğ»2] if there exists a substi-
tution ğœ‡ such that ğœ‡ (ğ›½1) âŠ† ğ›½2 and ğœ‡ (ğ»1) = ğ»2.

A TGD/rule ğœ is contained in a set of TGDs/rules ğ‘† up to redun-

dancy if ğœ is a syntactic tautology or some ğœ â€² âˆˆ ğ‘† subsumes ğœ.

The following example illustrates Definition 5.1.
Example 5.2. Rule ğ´(ğ‘¥) âˆ§ ğµ(ğ‘¥) â†’ ğ´(ğ‘¥) is a syntactic tautology:
applying a chase step with it cannot produce a new fact. A non-full
TGD in head-normal form cannot be a syntactic tautology since
each head atom of such a TGD contains an existentially quantified
variable that does not occur in the TGD body.

Rule ğœ1 = ğ´(ğ‘“ (ğ‘¥1), ğ‘“ (ğ‘¥1)) âˆ§ ğµ(ğ‘¥1) â†’ ğµ(ğ‘“ (ğ‘¥1)) is subsumed by
rule ğœ2 = ğ´(ğ‘¥2, ğ‘¥3) â†’ ğµ(ğ‘¥2) using substitution ğœ‡1 that maps both
ğ‘¥2 and ğ‘¥3 to ğ‘“ (ğ‘¥1). If ğœ1 derives ğµ(ğ‘“ (ğ‘¡)) in one step from a set of
facts ğ¼ by a substitution ğœ where ğœ (ğ‘¥1) = ğ‘¡, then ğœ2 also derives
ğµ(ğ‘“ (ğ‘¡)) from ğ¼ in one step by substitution ğœ â—¦ ğœ‡1. Thus, rule ğœ1 is
not needed when rule ğœ2 is present, so ğœ1 can be discarded.

While syntactic tautologies and rule subsumption are standard
in first-order theorem proving [8], subsumption of TGDs is more in-
volved. TGD ğœ3 = ğ´(ğ‘¥1, ğ‘¥1) âˆ§ ğµ(ğ‘¥1) â†’ âˆƒğ‘¦1 ğ¶ (ğ‘¥1, ğ‘¦1) is subsumed
by TGD ğœ4 = ğ´(ğ‘¥2, ğ‘¥3) â†’ âˆƒğ‘¦2, ğ‘¦3 ğ¶ (ğ‘¥2, ğ‘¦2) âˆ§ ğ· (ğ‘¥3, ğ‘¦3) by substitu-
tion ğœ‡2 where ğœ‡2 (ğ‘¥2) = ğœ‡2 (ğ‘¥3) = ğ‘¥1, ğœ‡2 (ğ‘¦2) = ğ‘¦1, and ğœ‡2 (ğ‘¦3) = ğ‘¦3.
The conditions on substitution ğœ‡2 in Definition 5.1 ensure that
ğ‘¦2 and ğ‘¦3 are not mapped to each other or to ğ‘¥1. Thus, as in the
previous paragraph, the result of each chase step with ğœ3 and sub-
stitutions ğœ and ğœ â€² can always be obtained (up to isomorphism) by
a chase step with ğœ4 and substitutions ğœ â—¦ ğœ‡2 and ğœ â€² â—¦ ğœ‡2.
âŠ³

In Definition 5.3 we formalize the notion of applying Inf exhaus-
tively up to redundancy. The definition, however, does not say how
to actually do it: we discuss this and other issues in Section 6.

Definition 5.3. For Inf an inference rule and Î£ a finite set of GTGDs,
Inf(Î£) is the subset of all Skolem-free Datalog rules of Î£â€², where Î£â€²
is the smallest set that contains up to redundancy each TGD/rule
obtained by
â€¢ transforming Î£ into head-normal form if Inf manipulates TGDs

or Skolemizing Î£ if Inf manipulates rules, and

â€¢ selecting an adequate number of premises in Î£â€², renaming any
variables shared by distinct premises, applying Inf to the renamed
premises, and transforming the result into head-normal form.

5.1 The Existential-Based Rewriting
As we discussed in Section 4, each loop ğ‘‡ğ‘–, . . . ,ğ‘‡ğ‘— at vertex ğ‘£ in a
one-pass chase sequence can be seen as taking ğ‘‡ğ‘– (ğ‘£) as input and
producing one fact included in ğ‘‡ğ‘— (ğ‘£) as output. Let ğ‘£ â€² be child of ğ‘£
introduced inğ‘‡ğ‘–+1. The idea behind the ExbDR algorithm is to derive
all GTGDs such that, for each ğ‘˜ with ğ‘– < ğ‘˜ â‰¤ ğ‘—, all facts of ğ‘‡ğ‘˜ (ğ‘£ â€²)

ğ´(ğ‘, ğ‘)

(8)

(9)

(10)

ğµ(ğ‘, ğ‘›1), ğ¶ (ğ‘, ğ‘›1)

ğ· (ğ‘, ğ‘›1)

ğ¸ (ğ‘)

(17) = (8) + (9)

(18) = (17) + (10)

Figure 3: Deriving â€œshortcutsâ€ for the loop ğ‘‡0â€“ğ‘‡4 in ExbDR

can be derived from the input ğ‘‡ğ‘– (ğ‘£) in one step. The output of the
loop can then also be derived from ğ‘‡ğ‘– (ğ‘£) in one step by full GTGD,
so this GTGD provides us with the desired loop â€œshortcutâ€. Before
formalizing this idea, we slightly adapt the notion of unification.

Definition 5.4. For ğ‘‹ a set of variables, an ğ‘‹ -unifier and an ğ‘‹ -
MGU ğœƒ of atoms ğ´1, . . . , ğ´ğ‘› and ğµ1, . . . , ğµğ‘› are defined as in Section 3,
but with the additional requirement that ğœƒ (ğ‘¥) = ğ‘¥ for each ğ‘¥ âˆˆ ğ‘‹ .

It is straightforward to see that an ğ‘‹ -MGU is unique up to the re-
naming of variables not contained in ğ‘‹ , and that it can be computed
as usual while treating variables in ğ‘‹ as if they were constants. We
are now ready to formalize the ExbDR algorithm.

Definition 5.5. The Existential-Based Datalog Rewriting inference
rule ExbDR takes two guarded TGDs

ğœ = âˆ€(cid:174)ğ‘¥ [ğ›½ â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚ âˆ§ ğ´1 âˆ§ Â· Â· Â· âˆ§ ğ´ğ‘›] with ğ‘› â‰¥ 1 and
ğœ â€² = âˆ€(cid:174)ğ‘§ [ğ´â€²
1 âˆ§ Â· Â· Â· âˆ§ ğ´â€²
ğ‘› âˆ§ ğ›½â€² â†’ ğ» â€²]
and, for ğœƒ a (cid:174)ğ‘¦-MGU of ğ´1, . . . , ğ´ğ‘› and ğ´â€²
1
and vars(ğœƒ (ğ›½â€²)) âˆ© (cid:174)ğ‘¦ = âˆ…, it derives

, . . . , ğ´â€²

ğ‘›, , if ğœƒ ( (cid:174)ğ‘¥) âˆ© (cid:174)ğ‘¦ = âˆ…

ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½â€²) â†’ âˆƒ(cid:174)ğ‘¦ ğœƒ (ğœ‚) âˆ§ ğœƒ (ğ´1) âˆ§ Â· Â· Â· âˆ§ ğœƒ (ğ´ğ‘›) âˆ§ ğœƒ (ğ» â€²).

Example 5.6. Consider again the set Î£ from Example 4.3. The
idea behind the ExbDR algorithm is illustrated in Figure 3, which
summarizes the steps of the loop ğ‘‡0,ğ‘‡1,ğ‘‡2,ğ‘‡3,ğ‘‡4 from Figure 1. We
denote the vertices by ğ‘Ÿ and ğ‘£1 as in Example 4.3.

Fact ğ´(ğ‘, ğ‘) is the input to the loop, and the first step of the
loop derives ğµ(ğ‘, ğ‘›1) and ğ¶ (ğ‘, ğ‘›1) using GTGD (8). Next, GTGD (9)
evolves vertex ğ‘£1 by deriving ğ· (ğ‘, ğ‘›1). To capture this, the ExbDR
inference rule combines (8), the GTGD that creates ğ‘£1, with (9), the
GTGD that evolves ğ‘£1. This produces GTGD (17), which derives
all facts of ğ‘£1 from the input fact in one step. Vertex ğ‘£1 is evolved
further using GTGD (10) to derive ğ¸ (ğ‘). To reflect this, the ExbDR
inference rule combines (17) and (10) to produce (18), which again
derives all facts of ğ‘£1 from the loopâ€™s input in one step.
ğ´(ğ‘¥1, ğ‘¥2) â†’ âˆƒğ‘¦ ğµ(ğ‘¥1, ğ‘¦) âˆ§ ğ¶ (ğ‘¥1, ğ‘¦) âˆ§ ğ· (ğ‘¥1, ğ‘¦)
ğ´(ğ‘¥1, ğ‘¥2) â†’ âˆƒğ‘¦ ğµ(ğ‘¥1, ğ‘¦) âˆ§ ğ¶ (ğ‘¥1, ğ‘¦) âˆ§ ğ· (ğ‘¥1, ğ‘¦) âˆ§ ğ¸ (ğ‘¥1)

(18)
Fact ğ¸ (ğ‘) does not contain the labeled null ğ‘›1 that is introduced
when creating ğ‘£1, so it can be propagated to the root vertex ğ‘Ÿ as
the output of the loop. This is reflected in (18): atom ğ¸ (ğ‘¥1) does
not contain any existential variables. Definition 5.3 requires each
derived GTGD to be brought into head-normal, so (18) is broken up
into (17) and (14). The latter GTGD is full, and it provides us with
the desired shortcut for the loop.

(17)

Next, (12) and atom ğ¹ (ğ‘¥1, ğ‘¦1) of (11) produce (19), and transfor-
mation into head-normal form produces (11) and (15). Moreover,
(8) and (13) produce (20), and transformation (20) into head-normal
form produces (16) and (21).

ğ´(ğ‘¥1, ğ‘¥2) âˆ§ ğ¸ (ğ‘¥1) â†’ âˆƒğ‘¦1, ğ‘¦2 ğ¹ (ğ‘¥1, ğ‘¦1) âˆ§ ğ¹ (ğ‘¦1, ğ‘¦2) âˆ§ ğº (ğ‘¥1)
ğ´(ğ‘¥1, ğ‘¥2) âˆ§ ğº (ğ‘¥1) â†’ âˆƒğ‘¦ ğµ(ğ‘¥1, ğ‘¦) âˆ§ ğ¶ (ğ‘¥1, ğ‘¦) âˆ§ ğ» (ğ‘¥1)
ğ´(ğ‘¥1, ğ‘¥2) âˆ§ ğº (ğ‘¥1) â†’ âˆƒğ‘¦ ğµ(ğ‘¥1, ğ‘¦) âˆ§ ğ¶ (ğ‘¥1, ğ‘¦)

(19)

(20)

(21)

GTGD (21) is subsumed by (8) so it can be dropped. No further
inferences are possible after this, so all derived full GTGDs are
returned as the rewriting of Î£.
âŠ³

Before proceeding, we present an auxiliary result showing cer-

tain key properties of the ExbDR inference rule.

Proposition 5.7. Each application of the ExbDR inference rule
to ğœ, ğœ â€², and ğœƒ as in Definition 5.5 satisfies the following properties.
1. Some atom ğ´â€²
ğ‘– with 1 â‰¤ ğ‘– â‰¤ ğ‘› is a guard in ğœ â€².
2. For each 1 â‰¤ ğ‘– â‰¤ ğ‘› such that ğ´â€²

ğ‘– is a guard of ğœ â€², and for ğœ the (cid:174)ğ‘¦-
ğ‘– and the corresponding atom ğ´ğ‘– such that ğœ ( (cid:174)ğ‘¥) âˆ© (cid:174)ğ‘¦ = âˆ…,

MGU of ğ´â€²
it is the case that vars(cid:0)ğœ (ğ´â€²

ğ‘— )(cid:1) âˆ© (cid:174)ğ‘¦ â‰  âˆ… for each 1 â‰¤ ğ‘— â‰¤ ğ‘›.

3. The result is a GTGD whose body and head width are at most

bwidth(Î£) and hwidth(Î£), respectively.

In the second claim of Proposition 5.7, ğœ unifies only ğ´ğ‘– and
ğ´â€²
ğ‘– , whereas ğœƒ unifies all ğ´1, . . . , ğ´ğ‘› and ğ´â€²
ğ‘›; thus, ğœ and ğœƒ
1
are not necessarily the same. The third claim is needed to prove
termination of ExbDR.

, . . . , ğ´â€²

Proposition 5.7 can be used to guide the application of the ExbDR
inference rule. Consider an attempt to apply the ExbDR inference
rule to two candidate GTGDs ğœ = ğ›½ â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚ and ğœ â€² = ğ›½â€² â†’ ğ» â€². The
first claim of Proposition 5.7 tells us that a guard of ğœ â€² will defi-
nitely participate in the inference. Thus, we can choose one such
guard ğº â€² âˆˆ ğ›½â€² of ğœ â€² and try to find a (cid:174)ğ‘¦-MGU ğœ of ğº â€² and a coun-
terpart atom ğº âˆˆ ğœ‚ from the head of ğœ. Next, we need to check
whether ğœ ( (cid:174)ğ‘¥) âˆ© (cid:174)ğ‘¦ = âˆ…; if not, there is no way for ğœƒ ( (cid:174)ğ‘¥) âˆ© (cid:174)ğ‘¦ = âˆ… to
hold so the inference is not possible. By the second claim of Propo-
sition 5.7, all candidates for the atoms participating in the inference
will contain a variable that is mapped by ğœ to a member of (cid:174)ğ‘¦; thus,
ğ‘† â€² = (cid:8)ğœ (ğ´â€²) | ğ´â€² âˆˆ ğ›½â€² âˆ§ vars(ğœ (ğ´â€²)) âˆ© (cid:174)ğ‘¦ â‰  âˆ…(cid:9) is the set of all rele-
vant side atoms. Note that we apply ğœ to the atoms in ğ‘† â€² to simplify
further matching. The next step is to identify the corresponding
head atoms of ğœ. To achieve this, for each atom ğ´â€² âˆˆ ğ‘† â€² of the form
ğ‘…(ğ‘¡1, . . . , ğ‘¡ğ‘›), we identify the set ğ¶ [ğ´â€²] of candidate counterpart
atoms as the set of atoms of the form ğ‘…(ğ‘ 1, . . . , ğ‘ ğ‘›) âˆˆ ğœ (ğœ‚) such
that, for each argument position ğ‘– with 1 â‰¤ ğ‘– â‰¤ ğ‘›, if either ğ‘¡ğ‘– âˆˆ (cid:174)ğ‘¦ or
ğ‘ ğ‘– âˆˆ (cid:174)ğ‘¦, then ğ‘¡ğ‘– = ğ‘ ğ‘– . Finally, we consider each possible combination
ğ‘† of such candidates, and we try to find an MGU ğœƒ of sets ğ‘† and ğ‘† â€².
If unification succeeds, we derive the corresponding GTGD.

Theorem 5.8. Program ExbDR(Î£) is a Datalog rewriting of a
finite set of GTGDs Î£. Moreover, the rewriting can be computed in
time ğ‘‚ (ğ‘ğ‘Ÿ ğ‘‘ Â· (ğ‘¤ğ‘ +ğ‘ )ğ‘‘ğ‘ Â·ğ‘Ÿ ğ‘‘ Â· (ğ‘¤â„+ğ‘ )ğ‘‘ğ‘
) for ğ‘Ÿ the number of relations in Î£, ğ‘
the maximum relation arity in Î£, ğ‘¤ğ‘ = bwidth(Î£), ğ‘¤â„ = hwidth(Î£),
ğ‘ = |consts(Î£)|, and some ğ‘ and ğ‘‘.

use. From a theoretical point of view, checking fact entailment via
ExbDR(Î£) is worst-case optimal. To see why, let ğ‘Ÿ , ğ‘, and ğ‘ be as in
Theorem 5.8, and consider a base instance ğ¼ with ğ‘â€² constants. The
fixpoint of ExbDR(Î£) on ğ¼ contains at most ğ‘Ÿ (ğ‘ + ğ‘â€²)ğ‘ facts, and
it can be computed in time ğ‘‚ (ğ‘Ÿ (ğ‘ + ğ‘â€²)ğ‘ Â· |ExbDR(Î£)|): each rule
ğœ âˆˆ ExbDR(Î£) is guarded so we can apply a chase step with ğœ by
matching a guard and then checking the remaining body atoms.
Hence, we can compute ExbDR(Î£) and find its fixpoint in 2Exp-
Time, in ExpTime if the relation arity is fixed, and in PTime if Î£ is
fixed (i.e., if we consider data complexity). These results match the
lower bounds for checking fact entailment for GTGDs [34].

5.2 Using Skolemization
The ExbDR algorithm exhibits two drawbacks. First, each applica-
tion of the ExbDR inference rule potentially introduces a head atom,
so the rule heads can get very long. Second, each inference requires
matching a subset of body atoms of ğœ â€² to a subset of the head atoms
of ğœ; despite the optimizations outlined after Proposition 5.7, this
can be costly, particularly when rule heads are long.

We would ideally derive GTGDs with a single head atom and
unify just one body atom of ğœ â€² with the head atom of ğœ, but this does
not seem possible if we stick to manipulating GTGDs. For example,
atoms ğ¶ (ğ‘¦) and ğ· (ğ‘¦) of GTGD (17) refer to the same labeled null
(represented by variable ğ‘¦), and this information would be lost if we
split (17) into two GTGDs. We thus need a way to refer to the same
existentially quantified object in different logical formulas. This
can be achieved by replacing existentially quantified variables by
Skolem terms, which in turns gives rise to the SkDR algorithm from
Definition 5.10. Before presenting the algorithm, in Definition 5.9
we generalize the notion of guardedness to rules.

Definition 5.9. Rule âˆ€(cid:174)ğ‘¥ [ğ›½ â†’ ğ» ] is guarded if each function symbol
in the rule is a Skolem symbol, the body ğ›½ contains a Skolem-free
atom ğ´ âˆˆ ğ›½ such that vars(ğ´) = (cid:174)ğ‘¥, and each Skolem term in the rule
is of the form ğ‘“ ((cid:174)ğ‘¡) where vars(cid:0)ğ‘“ ((cid:174)ğ‘¡)(cid:1) = (cid:174)ğ‘¥ and (cid:174)ğ‘¡ is function-free.

Definition 5.10. The Skolem Datalog Rewriting inference rule
SkDR takes two guarded rules

ğœ = ğ›½ â†’ ğ»

and

ğœ â€² = ğ´â€² âˆ§ ğ›½â€² â†’ ğ» â€²

such that
â€¢ ğ›½ is Skolem-free and ğ» contains a Skolem symbol, and
â€¢ ğ´â€² contains a Skolem symbol, or ğœ â€² is Skolem-free and ğ´â€² contains

all variables of ğœ â€²,

and, for ğœƒ an MGU of ğ» and ğ´â€², it derives

ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½â€²) â†’ ğœƒ (ğ» â€²).

Example 5.11. Skolemizing GTGDs (8) and (11) produces rules

(22)â€“(23), and (24)â€“(25), respectively.

ğ´(ğ‘¥1, ğ‘¥2) â†’ ğµ(ğ‘¥1, ğ‘“ (ğ‘¥1, ğ‘¥2))
ğ´(ğ‘¥1, ğ‘¥2) â†’ ğ¶ (ğ‘¥1, ğ‘“ (ğ‘¥1, ğ‘¥2))
ğ´(ğ‘¥1, ğ‘¥2) âˆ§ ğ¸ (ğ‘¥1) â†’ ğ¹ (ğ‘¥1, ğ‘”(ğ‘¥1, ğ‘¥2))
ğ´(ğ‘¥1, ğ‘¥2) âˆ§ ğ¸ (ğ‘¥1) â†’ ğ¹ (ğ‘”(ğ‘¥1, ğ‘¥2), â„(ğ‘¥1, ğ‘¥2))

(22)

(23)

(24)

(25)

Program ExbDR(Î£) can thus be large in the worst case. In Sec-
tion 7 we show empirically that rewritings are suitable for practical

Intuitively, rules (22) and (23) jointly represent the facts introduced
by the non-full GTGD (8): functional term ğ‘“ (ğ‘¥1, ğ‘¥2) allows both

rules to â€œtalkâ€ about the same labeled nulls. This allows the SkDR
inference rule to simulate the ExbDR inference rule while unifying
just pairs of atoms. In particular, SkDR combines (22) and (10) to
obtain (26); it combines (23) and (9) to obtain (27); and it combines
(26) and (27) to obtain the â€œshortcutâ€ rule (14).
ğ´(ğ‘¥1, ğ‘¥2) âˆ§ ğ· (ğ‘¥1, ğ‘“ (ğ‘¥1, ğ‘¥2)) â†’ ğ¸ (ğ‘¥1)

(26)

ğ´(ğ‘¥1, ğ‘¥2) â†’ ğ· (ğ‘¥1, ğ‘“ (ğ‘¥1, ğ‘¥2))

(27)

The rules with Skolem-free bodies derived in this way allow us to
reconstruct derivations in one step analogously to Example 5.6, and
the rules with Skolem symbols in body atoms capture the interme-
diate derivation steps. For example, rules (26) and (28) capture the
result of matching the first and the second body atom, respectively,
of rule (10) to facts produced by rules (22) and (27), respectively.
To complete the rewriting, SkDR combines (24) with (12) to obtain
(15), and it combines (22) with (13) to derive (16).

However, SkDR also combines (10) and (27) into (28), which with
(22) derives (14) the second time. These inferences are superfluous:
they just process the two body atoms of (10) in a different order.
Also, SkDR combines (12) and (25) into rule (29), which is a â€œdead-
endâ€ in that it does not further contribute to a Datalog rule.

ğ´(ğ‘¥1, ğ‘¥2) âˆ§ ğµ(ğ‘¥1, ğ‘“ (ğ‘¥1, ğ‘¥2)) â†’ ğ¸ (ğ‘¥1)
ğ´(ğ‘¥1, ğ‘¥2) âˆ§ ğ¸ (ğ‘¥1) âˆ§ ğ¸ (ğ‘”(ğ‘¥1, ğ‘¥2)) â†’ ğº (ğ‘”(ğ‘¥1, ğ‘¥2))
Our HypDR algorithm in Subsection 5.3 can avoid these overheads,
âŠ³
but at the expense of using more than two rules at a time.

(28)

(29)

Proposition 5.12 and Theorem 5.13 capture the relevant proper-

ties of the SkDR algorithm.

Proposition 5.12. Each application of the SkDR inference rule to

rules ğœ and ğœ â€² as in Definition 5.10 produces a guarded rule.

Theorem 5.13. Program SkDR(Î£) is a Datalog rewriting of a
finite set of GTGDs Î£. Moreover, the rewriting can be computed in
time ğ‘‚ (ğ‘ğ‘Ÿ ğ‘‘ Â· (ğ‘’+ğ‘¤ğ‘ +ğ‘ )ğ‘‘ğ‘
) for ğ‘Ÿ the number of relations in Î£, ğ‘ the
maximum relation arity in Î£, ğ‘’ the number of existential quantifiers
in Î£, ğ‘¤ğ‘ = bwidth(Î£), ğ‘ = |consts(Î£)|, and some ğ‘ and ğ‘‘.

It is natural to wonder whether SkDR is guaranteed to be more
efficient than ExbDR. We next show that neither algorithm is gener-
ally better: there exist families of inputs on which SkDR performs
exponentially more inferences than ExbDR, and vice versa.

Proposition 5.14. There exists a family {Î£ğ‘› }ğ‘›âˆˆN of finite sets of
GTGDs such that the number of GTGDs derived by ExbDR is ğ‘‚ (2ğ‘›)
times larger than the number of rules derived by SkDR on each Î£ğ‘›.

Proof. For each ğ‘› âˆˆ N, let Î£ğ‘› contain the following GTGDs.

ğ´(ğ‘¥) â†’ âˆƒ(cid:174)ğ‘¦ ğµ1 (ğ‘¥, ğ‘¦1) âˆ§ Â· Â· Â· âˆ§ ğµğ‘› (ğ‘¥, ğ‘¦ğ‘›)

(30)

ğµğ‘– (ğ‘¥1, ğ‘¥2) âˆ§ ğ¶ğ‘– (ğ‘¥1) â†’ ğ·ğ‘– (ğ‘¥1, ğ‘¥2) for 1 â‰¤ ğ‘– â‰¤ ğ‘›

(31)
On such Î£ğ‘›, ExbDR derives a GTGD of the form (32) for each subset
{ğ‘˜1, . . . , ğ‘˜ğ‘š } âŠ† {1, . . . , ğ‘›}, and there are 2ğ‘› such TGDs. In contrast,
the Skolemization of (30) consists of ğ‘› rules shown in equation (33),
so SkDR derives just ğ‘› rules shown in equation (34).

ğ´(ğ‘¥) âˆ§

ğ‘š
(cid:219)

ğ‘–=1

ğ¶ğ‘˜ğ‘– (ğ‘¥) â†’ âˆƒ(cid:174)ğ‘¦

ğ‘›
(cid:219)

ğ‘–=1

ğµğ‘– (ğ‘¥, ğ‘¦ğ‘– ) âˆ§

ğ‘š
(cid:219)

ğ‘–=1

ğ·ğ‘˜ğ‘– (ğ‘¥, ğ‘¦ğ‘˜ğ‘– )

(32)

ğ´(ğ‘¥) â†’ ğµğ‘– (ğ‘¥, ğ‘“ğ‘– (ğ‘¥)) for 1 â‰¤ ğ‘– â‰¤ ğ‘›
ğ´(ğ‘¥) âˆ§ ğ¶ğ‘– (ğ‘¥) â†’ ğ·ğ‘– (ğ‘¥, ğ‘“ğ‘– (ğ‘¥)) for 1 â‰¤ ğ‘– â‰¤ ğ‘›

(33)
â–¡(34)

Proposition 5.15. There exists a family {Î£ğ‘› }ğ‘›âˆˆN of finite sets
of GTGDs such that the number of rules derived by SkDR is ğ‘‚ (2ğ‘›)
times larger than the number of TGDs derived by ExbDR on each Î£ğ‘›.

Proof. For each ğ‘› âˆˆ N, let Î£ğ‘› contain the following GTGDs.
ğ´(ğ‘¥) â†’ âˆƒğ‘¦ ğµ1 (ğ‘¥, ğ‘¦) âˆ§ Â· Â· Â· âˆ§ ğµğ‘› (ğ‘¥, ğ‘¦)
ğµ1 (ğ‘¥1, ğ‘¥2) âˆ§ Â· Â· Â· âˆ§ ğµğ‘› (ğ‘¥1, ğ‘¥2) â†’ ğ¶ (ğ‘¥1)
(36)
On such Î£ğ‘›, ExbDR derives just GTGD (37) in one step. In contrast,
the Skolemization of (35) consists of ğ‘› rules of the form (38) for each
1 â‰¤ ğ‘– â‰¤ ğ‘›. Thus, SkDR combines these with (36) to derive 2ğ‘› âˆ’ 1
rules of the form (39), one for each subset {ğ‘˜1, . . . , ğ‘˜ğ‘š } âŠŠ {1, . . . , ğ‘›}.
(37)

(35)

ğ´(ğ‘¥) â†’ ğ¶ (ğ‘¥)
ğ´(ğ‘¥) â†’ ğµğ‘– (ğ‘¥, ğ‘“ (ğ‘¥))
ğ´(ğ‘¥) âˆ§ ğµğ‘˜1

(38)
(ğ‘¥, ğ‘“ (ğ‘¥)) âˆ§ Â· Â· Â· âˆ§ ğµğ‘˜ğ‘š (ğ‘¥, ğ‘“ (ğ‘¥)) â†’ ğ¶ (ğ‘¥) â–¡ (39)

5.3 Combining Several SkDR Steps into One
The SkDR algorithm can produce many rules with Skolem symbols
in the body, which is the main reason for Proposition 5.15. We
next present the HypDR algorithm, which uses the hyperresolution
inference rule as a kind of â€œmacroâ€ to combine several SkDR steps
into one. We show that this can be beneficial for several reasons.

Definition 5.16. The Hyperresolution Rewriting inference rule
HypDR takes guarded rules
ğœ1 = ğ›½1 â†’ ğ»1
ğœ â€² = ğ´â€²

. . .
1 âˆ§ Â· Â· Â· âˆ§ ğ´â€²
ğ‘› âˆ§ ğ›½â€² â†’ ğ» â€²

ğœğ‘› = ğ›½ğ‘› â†’ ğ»ğ‘› and

such that
â€¢ for each ğ‘– with 1 â‰¤ ğ‘– â‰¤ ğ‘›, conjunction ğ›½ğ‘– is Skolem-free and atom

ğ»ğ‘– contains a Skolem symbol, and

â€¢ rule ğœ â€² is Skolem-free,
and, for ğœƒ an MGU of ğ»1, . . . , ğ»ğ‘› and ğ´â€²
1
is Skolem-free, it derives

, . . . , ğ´â€²

ğ‘›, if conjunction ğœƒ (ğ›½â€²)

ğœƒ (ğ›½1) âˆ§ Â· Â· Â· âˆ§ ğœƒ (ğ›½ğ‘›) âˆ§ ğœƒ (ğ›½â€²) â†’ ğœƒ (ğ» â€²).

Example 5.17. The HypDR inference rule simulates chase steps
in the child vertex of a loop analogously to ExbDR: all body atoms
matching a fact introduced in the child vertex are resolved in one
step. We can see two benefits of this on our running example.

First, HypDR derives (27) from (23) and (9), and it derives (14)
from (10), (22), and (27). Rule (14) is derived just once, and with-
out intermediate rules (26) and (28). In other words, the HypDR
inference rule does not resolve the body atoms of a rule in every
possible order. As Proposition 5.20 below shows, this can reduce
the number of derived rules by an exponential factor.

Second, HypDR derives only rules with Skolem-free bodies, and
thus does not derive the â€œdead-endâ€ rule (29). In other words, all
consequences of HypDR derive in one step one fact in the child
vertex of a loop from the loopâ€™s input ğ‘‡ğ‘– (ğ‘£).

The downside of HypDR is that more than two rules can partici-
pate in an inference. This requires more complex unification and
âŠ³
selection of candidates that can participate in an inference.

Proposition 5.18 and Theorem 5.19 capture the properties of

HypDR, and Proposition 5.20 compares it to SkDR.

Proposition 5.18. Each application of the HypDR inference rule
to rules ğœ1, . . . , ğœğ‘› and ğœ â€² as in Definition 5.16 produces a guarded rule.

Theorem 5.19. Program HypDR(Î£) is a Datalog rewriting of a
finite set of GTGDs Î£. Moreover, the rewriting can be computed in
time time ğ‘‚ (ğ‘ğ‘Ÿ ğ‘‘ Â· (ğ‘’+ğ‘¤ğ‘ +ğ‘ )ğ‘‘ğ‘
) for ğ‘Ÿ the number of relations in Î£, ğ‘ the
maximum relation arity in Î£, ğ‘’ the number of existential quantifiers
in Î£, ğ‘¤ğ‘ = bwidth(Î£), ğ‘ = |consts(Î£)|, and some ğ‘ and ğ‘‘.

Proposition 5.20. There exists a family {Î£ğ‘› }ğ‘›âˆˆN of finite sets
of GTGDs such that SkDR derives ğ‘‚ (2ğ‘›) more rules than HypDR on
each Î£ğ‘›.

Proof. For each ğ‘› âˆˆ N, let Î£ğ‘› contain the following GTGDs.

ğ´(ğ‘¥) â†’ âˆƒğ‘¦ ğµ(ğ‘¥, ğ‘¦)
ğµ(ğ‘¥1, ğ‘¥2) âˆ§ ğ¶ğ‘– (ğ‘¥1) â†’ ğ·ğ‘– (ğ‘¥1, ğ‘¥2) for 1 â‰¤ ğ‘– â‰¤ ğ‘›
ğ·1 (ğ‘¥1, ğ‘¥2) âˆ§ Â· Â· Â· âˆ§ ğ·ğ‘› (ğ‘¥1, ğ‘¥2) â†’ ğ¸ (ğ‘¥1)

(40)

(41)

(42)

Skolemizing (40) produces (43). Thus, SkDR combines (43) with
each (41) to derive each (44), and it uses (44) and (42) to derive
2ğ‘› âˆ’ 1 rules of the form (45) for each set of indexes ğ¼ satisfying
âˆ… âŠŠ ğ¼ âŠ† {1, . . . , ğ‘›}; note that none of these rules are redundant.

ğ´(ğ‘¥) â†’ ğµ(ğ‘¥, ğ‘“ (ğ‘¥))
ğ´(ğ‘¥) âˆ§ ğ¶ğ‘– (ğ‘¥) â†’ ğ·ğ‘– (ğ‘¥, ğ‘“ (ğ‘¥)) for 1 â‰¤ ğ‘– â‰¤ ğ‘›
(cid:219)

(cid:219)

ğ· ğ‘— (ğ‘¥, ğ‘“ (ğ‘¥)) â†’ ğ¸ (ğ‘¥)

ğ¶ğ‘– (ğ‘¥) âˆ§

(43)

(44)

(45)

ğ´(ğ‘¥) âˆ§

ğ‘– âˆˆğ¼

ğ‘— âˆˆ {1,...,ğ‘›}\ğ¼

In contrast, HypDR derives each (44) just like SkDR, and it combines
â–¡
in one step (42) and all (44) to derive (45) for ğ¼ = {1, . . . , ğ‘›}.

6 IMPLEMENTATION AND OPTIMIZATIONS
In this section, we discuss numerous issues that have to be addressed
to make the computation of a rewriting practical.
Computing Inf(Î£) in Practice. Definition 5.3 does not specify
how to compute the set Î£â€², and redundancy elimination makes
this question nontrivial. When Inf derives a TGD/rule ğœ, we can
apply subsumption in two ways. First, we can discard ğœ if ğœ is sub-
sumed by a previously derived TGD/rule; this is known as forward
subsumption. Second, if ğœ is not discarded, we can discard each pre-
viously derived TGD/rule that is subsumed by ğœ; this is known as
backward subsumption. The set of derived TGD/rules can thus grow
and shrink, so the application of Inf has to be carefully structured
to ensure that all inferences are performed eventually.

We address this problem by a variant of the Otter loop [36] used
in first-order theorem provers. The pseudo-code is shown in Al-
gorithm 1. The algorithm maintains two sets of TGDs/rules: the
worked-off set W contain TGDs/rules that have been processed by
Inf, and the unprocessed set U contains TGDs/rules that are still to
be processed. Set W is initially empty (line 1), and set U is initial-
ized to the head-normal form of Î£ if Inf manipulates TGDs, or to
the Skolemization of Î£ if Inf manipulates rules. The algorithm then
processes each ğœ âˆˆ U until U becomes empty (lines 3â€“10). It is gen-
erally beneficial to process shorter TGDs/rules first as that improves
chances of redundancy elimination. After moving ğœ to W (line 5),

Algorithm 1 Computing Inf(Î£) for Î£ a finite set of GTGDs

1: W = âˆ…
2: U = the head-normal form or the Skolemization of Î£
3: while U â‰  âˆ… do
4:
5: W = W âˆª {ğœ }
6:

Choose some ğœ âˆˆ U and remove it from U

Let E be the result of applying Inf to ğœ and a subset of W
and transforming the result into head-normal form

for each ğœ â€² âˆˆ E do

7:

8:

9:

if ğœ â€² is not contained in W âˆª U up to redundancy then
Remove from W and U each ğœ â€²â€² subsumed by ğœ â€²
U = U âˆª {ğœ â€²}

10:
11: return {ğœ âˆˆ W | ğœ is a Skolem-free Datalog rule}

the algorithm applies Inf to ğœ and W and transforms the results
into head-normal form (line 6). The algorithm discards each result-
ing ğœ â€² âˆˆ E that is a syntactic tautology or is forward-subsumed by
an element of W âˆª U (line 8). If ğœ â€² is not discarded, the algorithm
applies backward subsumption to ğœ â€², W, and U (line 9) and adds
ğœ â€² to U (line 10). When all TGDs/rules are processed, the algorithm
returns all Skolem-free Datalog rules from W (line 11). The result
of applying Inf to TGDs/rules in W is thus contained in W âˆª U
up to redundancy at all times so, upon algorithmâ€™s termination, set
W satisfies the condition on Î£â€² from Definition 5.3.
Checking Subsumption. Checking whether TGD/rule ğœ1 sub-
sumes ğœ2 is NP-complete [32], and the main difficulty is in matching
the variables of ğœ1 to the variables of ğœ2. Thus, we use an approxi-
mate check in our implementation. First, we normalize each TGD
to use fixed variables ğ‘¥1, ğ‘¥2, . . . and ğ‘¦1, ğ‘¦2, . . .: we sort the body and
head atoms by their relations using an arbitrary, but fixed ordering
and breaking ties arbitrarily, and then we rename all variables so
that the ğ‘–ğ‘¡â„ distinct occurrence of a universally (respectively exis-
tentially) quantified variable from left to right is ğ‘¥ğ‘– (respectively
ğ‘¦ğ‘– ). To see whether ğœ1 = ğ›½1 â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚1 subsumes ğœ2 = ğ›½2 â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚2,
we determine whether ğ›½1 âŠ† ğ›½2 and ğœ‚1 âŠ‡ ğœ‚2 holds, which requires
only polynomial time. We use a similar approximation for rules.
Variable normalization ensures termination, and using a modified
subsumption check does not affect the correctness of the rewriting:
set W may contain more TGDs/rules than strictly necessary, but
these are all logical consequences of (the Skolemization of) Î£.
Subsumption Indexing. Sets W and U can be large, so we use
a variant of feature vector indexing [44] to retrieve subsumption
candidates in W âˆª U. For simplicity, we consider only TGDs in
the following discussion, but rules can be handled analogously.
Note that a TGD ğœ1 can subsume TGD ğœ2 only if the set of relations
occurring in the body of ğœ1 (respectively the head of ğœ2) is a subset of
the set of relations occurring in the body of ğœ2 (respectively the head
of ğœ1). Thus, we can reduce the problem of retrieving subsumption
candidates to the problem of, given a domain set ğ·, a set ğ‘ of
subsets of ğ·, a subset ğ‘† âŠ† ğ·, and âŠ²âŠ³ âˆˆ {âŠ†, âŠ‡}, retrieving each ğ‘† â€² âˆˆ ğ‘
satisfying ğ‘† â€² âŠ²âŠ³ ğ‘†. The set-trie data structure [43] can address this
problem. The idea is to order ğ· in an arbitrary, yet fixed way, so
that we can treat each subset of ğ‘ as a word over ğ·. We then index
ğ‘ by constructing a trie over the words representing the elements

of ğ‘ . Finally, we retrieve all ğ‘† â€² âˆˆ ğ‘ satisfying ğ‘† â€² âŠ²âŠ³ ğ‘† by traversing
the trie, where the ordering on ğ· allows us to considerably reduce
the number of vertices we visit during the traversal.

A minor issue is that retrieving TGDs that subsume a given
TGD requires both subset and superset testing for body and head
relations, respectively, and vice versa for retrieval of subsumed
TGDs. To address this, we introduce a distinct symbol ğ‘…ğ‘ and ğ‘…â„
for each relation ğ‘… occurring in Î£, and we represent each TGD ğœ as
a feature vector ğ¹ğœ of these symbols corresponding to the body and
head of ğœ. Moreover, we combine in the obvious way the subset and
superset retrieval algorithms. For example, when searching for a
TGD ğœ â€² âˆˆ W âˆª U that subsumes a given TGD ğœ, we use the subset
retrieval for the symbols ğ‘…ğ‘ and the superset retrieval for symbols
ğ‘…â„. Finally, we order these symbols by the decreasing frequency of
the order of the symbolsâ€™ occurrence in the set Î£ of input TGDs,
and moreover we order each ğ‘…ğ‘ before all ğ‘…â„.
Relation Clustering. We observed that the subsumption indexes
can easily get very large, so index traversal can become a consid-
erable source of overhead. To reduce the index size, we group the
symbols ğ‘…ğ‘ and ğ‘…â„ into clusters ğ¶ğ‘ and ğ¶â„, respectively. Then,
the feature vector ğ¹ğœ associated with each TGD ğœ consists of all
clusters ğ¶ğ‘ and ğ¶â„ that contain a relation occurring in the body
and head, respectively, of ğœ. We adapt the trie traversal algorithms
in the obvious way to take into account this change. The number
of clusters is computed using the average numbers of symbols and
atoms in the input TGDs, and clusters are computed with the aim
of balancing the number of TGDs stored in each leaf vertex.

Unification Indexing. We construct indexes over W that allow us
to quickly identify TGDs/rules that can participate in an inference
with some ğœ. For TGDs, we maintain a hash table that maps each
relation ğ‘… to a set of TGDs containing ğ‘… in the body, and another
hash table that does the same but for TGD heads. To index rules,
we use a variant of a path indexing [45]: each atom in a rule is rep-
resented as a sequence of relations and function symbols occurring
in the atom, and such sequences are entered into two tries (one for
body and one for head atoms). Then, given rule ğœ, we consider each
body and head atom ğ´ of ğœ, we convert ğ´ into the corresponding
sequence, and we use the sequence to query the relevant trie for
all candidates participating in an inference with ğœ on ğ´.

Cheap Lookahead Optimization. Consider an application of
the ExbDR inference rule to GTGDs ğœ and ğœ â€² as in Definition 5.5,
producing a GTGD ğœ â€²â€² where vars(ğœƒ (ğ» â€²)) âˆ© (cid:174)ğ‘¦ â‰  âˆ… and the relation
of ğ» â€² does not occur in the body of a GTGD in Î£. In each one-pass
chase sequence for some base instance and Î£, no GTGD of Î£ can
be applied to a fact obtained by instantiating ğœƒ (ğ» â€²), so deriving
this fact is redundant. Consequently, we can drop such ğœ â€²â€² as soon
as we derive it in line 6. Analogously, when the SkDR inference
rule is applied to rules ğœ and ğœ â€² as in Definition 5.10, we can drop
the resulting rule if ğœƒ (ğ» â€²) is not full and it contains a relation not
occurring in the body of a GTGD in Î£.

7 EXPERIMENTAL EVALUATION
We implemented a system that can produce a Datalog rewriting of a
set of GTGDs using our algorithms, and we conducted an empirical
evaluation using a comprehensive collection of 428 synthetic and

Table 1: Input GTGDs at a Glance

Inputs

# Full TGDs

# Non-Full TGDs

Min

Max
1 171,905 11,030

Avg Med Min
789

Max Avg Med
283

2 156,743 5,255

428

realistic inputs. Our objectives were to show that our algorithms
can indeed rewrite complex GTGDs, and that the rewriting can
be successfully processed by modern Datalog systems. In Subsec-
tion 7.1 we describe the test setting. Then, in Subsection 7.2 we
discuss the rewriting experiments with GTGDs obtained from on-
tologies, and in Subsection 7.3 we validate the usefulness of the
rewriting approach end-to-end. Finally, in Subsection 7.4 we discuss
rewriting GTGDs of higher arity. Due to the very large number of
inputs, we can only summarize our results in this paper; however,
our complete evaluation results are available online [13].

7.1 Input GTGDs, Competitors, & Test Setting
Before discussing our results, we next describe our test setting.

Input GTGDs. We are unaware of any publicly available sets of
GTGDs that we could readily use in our evaluation, so we derived
the input GTGDs for our evaluation from the ontologies in the
Oxford Ontology Library [40]. At the time of writing, this library
contained 787 ontologies, each assigned a unique five-digit identifier.
After removing closely-related ontology variants, we were left with
428 core ontologies. We loaded each ontology using the parser from
the Graal system [9], discarded axioms that cannot be translated
into GTGDs, and converted the remaining axioms into GTGDs. We
used the standard translation of description logics into first-order
logic [6], where each class corresponds to a unary relation, and
each property corresponds to a binary relation. We thus obtained
428 sets of input GTGDs with properties shown in Table 1.

To evaluate our algorithms on TGDs containing relations of ar-
ity higher than two, we devised a way to â€œblow upâ€ relation arity.
Given a set of GTGDs and a blowup factor ğ‘, our method proceeds
as follows. First, in each atom of each GTGD, it replaces each vari-
able argument with ğ‘ fresh variables uniquely associated with the
variable; for example, for ğ‘ = 2, atom ğ´(ğ‘¥, ğ‘¦) is transformed into
atom ğ´(ğ‘¥1, ğ‘¥2, ğ‘¦1, ğ‘¦2). Next, the method randomly introduces fresh
head and body atoms over the newly introduced variables; in doing
so, it ensures that the new atoms do not introduce patterns that
would prevent application of the ExbDR inference rule.

Competitors. We compared the ExbDR, SkDR, and HypDR algo-
rithms, implemented as described in Section 6. As noted in Section 2,
no existing system we are aware of implements a Datalog rewriting
algorithm for GTGDs. However, the KAON2 system [29, 38, 39]
can rewrite GTGDs obtained from OWL ontologies, so we used
KAON2 as a baseline in our experiments with OWL-based GTGDs.
We made sure that all inputs to KAON2 and our algorithms include
only GTGDs that all methods can process.

Test Setting. We conducted all experiments on a laptop with an
Intel Core i5-6500 CPU @ 3.20 GHz and 16 GB of RAM, running
Ubuntu 20.04.4 LTS and Java 11.0.15. In each test run, we loaded
a set of TGDs, measured the wall-clock time required to compute

Time (s)

ExbDR
SkDR
HypDR
KAON2

585

100

10

1

0.1

50 100 150 200 250 300 350
Nr. of Processed Sets of TGDs

# of Processed Inputs
Max. Processed Input Size
Max. Output Size
Max. Size Blowup
Max. Body Atoms in Output
# Blowup â‰¥ 1.5
) Min.
Max.
Avg.
Med.

e
m
T

s
(

i

ExbDR
367
185,515
196,594
8.95
7
26
0.05
582.18
23.23
0.82

SkDR HypDR KAON2
362
382
N/A
324,092
61,964
124,846
N/A
8.85
4
6
N/A
16
0.21
0.04
547.53
404.34
18.66
6.38
0.49
0.55

377
324,092
124,846
8.85
6
14
0.05
584.79
14.34
0.52

ğ‘Œ

ğ‘‹
ExbDR
SkDR
HypDR
KAON2

time (ğ‘Œ )/time (ğ‘‹ ) â‰¥ 10

ğ‘‹ and ğ‘Œ both fail

ExbDR SkDR HypDR KAON2

ExbDR SkDR HypDR KAON2

19

12
15

37
37
35

0
0

0

19
26
31

61
33
35
37

51
43
47

46
46

66

Figure 4: Results for TGDs Derived from Ontologies

the rewriting of a set of GTGDs, and saved the produced Datalog
rewriting. We used a timeout of ten minutes for each test run.

7.2 Experiments with GTGDs from Ontologies
We computed the Datalog rewriting of GTGDs obtained from OWL
ontologies using our three algorithms and KAON2. Figure 4 shows
the number of inputs that each algorithm processed in a given time,
provides information about the inputs and outputs of each system,
and compares the performance among systems. The input size for
ExbDR is the number of GTGDs after transforming the input into
head-normal form, and for SkDR and HypDR it is the number of
rules after Skolemization. Input size is not available for KAON2
since this system reads an OWL ontology and transforms it into
GTGDs internally. The output size is the number of Datalog rules
in the rewriting. Finally, the blowup is the ratio of the output and
the input sizes. Each input GTGD contained at most seven body
atoms. Out of 428 inputs, 349 were processed within the ten minute
limit by our three systems, and 334 inputs were processed by all
four systems. Moreover, 32 inputs, each containing between 20,270
and 221,648 GTGD, were not processed by any system.

Discussion. As one can see in Figure 4, all algorithms were able
to compute the rewriting of large inputs containing 100k+ GTGDs.
Moreover, for the vast majority of inputs that were successfully

processed, the size of the rewriting and the number of body atoms
in the rewriting are typically of the same order of magnitude as
the input. Hence, the worst-case exponential blowup from Theo-
rems 5.8, 5.13, and 5.19 does not appear in practice: the size of the
rewriting seems to be determined primarily by the input size.

Relative Performance. No system can be identified as the best in
general, but HypDR seems to offer the best performance on average.
The algorithm was able to process most inputs; it was at least 35%
faster than the other systems on the slowest input; it was never
slower by an order of magnitude; there were only 14 inputs that
could be processed by some other algorithm but not HypDR; and
the output of HypDR does not differ significantly from the output
of SkDR. This is in line with our motivation for HypDR outlined
in Example 5.17. Specifically, HypDR derives rules with just one
head atom, but it does not derive intermediate rules with functional
body atoms. The main source of overhead in HypDR seems to be
more complex selection of rules participating in an inference.

Impact of Subsumption. All algorithms spend a considerable por-
tion of their running time checking TGD/rule subsumption, so it is
natural to wonder whether this overhead is justified. To answer this
question, we ran our three approaches using a modification of Algo-
rithm 1: we replaced the check for containment up to redundancy
in line 8 with just checking ğœ â€² âˆ‰ W âˆª U, and we removed line 9.
Note that our normalization of variables described in Section 6
still guarantees termination. This change significantly increased
the number of derivations: the numbers of derived TGDs/rules
increased on average by a factor of 104, 185, and 103 on ExbDR,
SkDR, and HypDR, respectively. Interestingly, this increase did not
affect the performance uniformly. While SkDR was able to process
12 inputs an order of magnitude faster, ExbDR and HypDR timed
out on 72 and 17 additional inputs, respectively. This, we believe,
is due to how different inference rules select inference candidates.
The SkDR rule is applied to just pairs of rules, and candidate pairs
can be efficiently retrieved using unification indexes. In contrast,
ExbDR requires matching several head atoms with as many body
atoms, which makes developing a precise index for candidate pair
retrieval difficult; thus, as the number of derived TGDs increases,
the number of false candidates retrieved from the index increases as
well. Finally, HypDR can be applied to an arbitrary number of rules,
so selecting inference candidates clearly becomes more difficult as
the number of derived rules increases.

Impact of Structural Transformation. KAON2 uses structural
transformation [7] to simplify ontology axioms before translating
them into GTGDs. For example, axiom ğ´ âŠ‘ âˆƒğµ.âˆƒğ¶.ğ· is transformed
into ğ´ âŠ‘ âˆƒğµ.ğ‘‹ and ğ‘‹ âŠ‘ âˆƒğ¶.ğ· for ğ‘‹ a fresh class. The resulting
axioms have simpler structure, which is often beneficial to perfor-
mance. To see how this transformation affects our algorithms, we
reran our experiments while transforming the input axioms in the
same way as in KAON2. This indeed improved the performance of
SkDR by one order of magnitude on 22 ontologies, and it did not
hurt the performance of HypDR. The main challenge is to general-
ize this transformation to arbitrary GTGDs: whereas description
logic axioms exhibit syntactic nesting that lends itself naturally to
this transformation, it is less clear how to systematically apply this

Table 2: Computing the Fixpoint of the Rewriting

Ont. ID # Rules
63,422
00387
00448
67,986
75,146
00470
78,977
00471
75,146
00472
00473
78,977
113,959
00573
68,461
00682
81,553
00684
124,846
00686

# Input Facts
4,403,105
5,510,444
10,532,943
11,077,423
10,533,008
11,077,459
9,197,254
5,183,460
6,057,017
10,402,324

# Output Facts
51,439,424
107,235,697
141,396,446
128,954,126
141,396,576
128,954,198
155,118,592
105,431,952
66,981,628
166,366,039

Time (s)
53
110
242
253
279
291
206
101
109
238

transformation to TGDs, where heads and bodies consist of â€œflatâ€
conjunctions. We leave this question for future work.

7.3 End-to-End Experiments
To validate our approach end-to-end, we selected ten inputs where
ExbDR produced the largest rewritings. For each of these, we gen-
erated a large base instance using WatDiv [2], and we computed
the fixpoint of the rewriting and the instance using the RDFox [46]
Datalog system v5.4. Table 2 summarizes our results.

All programs used in this experiment are at least several orders
of magnitude larger than what is usually encountered in practical
applications of Datalog, but RDFox nevertheless computed the
fixpoint of all rewritings in a few minutes. Moreover, although the
fixpoints seem to be an order of magnitude larger than the base
instance, this is not a problem for highly optimized systems such
as RDFox. Hence, checking fact entailment via rewritings produced
by our algorithms is feasible in practice.

7.4 GTGDs With Relations of Higher Arity
Finally, we computed the rewriting of GTGDs obtained by blowing
up relation arity as described in Subsection 7.1 using a blowup
factor of five. We did not use KAON2 since this system supports
relations of arity at most two. Figure 5 summarizes our results. Out
of 428 inputs, 187 were processed within the ten minute limit by our
three systems, and 128 inputs were not processed by any system.
While HypDR performed best on GTGDs derived from ontolo-
gies, Figure 5 shows it to be worst-performing on higher-arity
GTGDs: it successfully processed only 199 inputs within the ten
minute timeout, whereas SkDR and ExbDR processed 238 and 274
inputs, respectively. This is mainly due to additional body atoms
introduced by our â€œblowupâ€ method: these increase the number of
rules participating in an application of the HypDR inference rule,
which makes selecting the participating rules harder.

This experiment proved to be more challenging, as most prob-
lems discussed in Section 6 became harder. For example, in ExbDR,
higher arity of atoms increases the likelihood that an atom re-
trieved through a unification index does not unify with a given
atom, and that the atoms of the selected GTGDs cannot be suc-
cessfully matched. Subsumption indexing is also more difficult for
similar reasons. However, the inputs used in this experiment consist
of a large numbers of GTGDs with relations of arity ten, so they
can be seen as a kind of a â€œstress testâ€. Our algorithms were able to

Time (s)

ExbDR
SkDR
HypDR

592

100

10

1

0.1

50

100

150

200

Nr. of Processed Sets of TGDs

250

# of Processed Inputs
Max. Processed Input Size
Max. Output Size
Max. Size Blowup
# Blowup â‰¥ 1.5
) Min.
Max.
Avg.
Med.

e
m
T

s
(

i

ExbDR
274
69,046
58,749
9.00
26
0.06
591.82
26.70
0.61

SkDR HypDR
199
38,362
38,335
5.84
3
0.04
557.75
17.05
1.72

238
182,569
171,832
5.84
5
0.05
504.49
38.39
1.65

ğ‘Œ

ğ‘‹
ExbDR
SkDR
HypDR

time (ğ‘Œ )/time (ğ‘‹ ) â‰¥ 10

ğ‘‹ and ğ‘Œ both fail

ExbDR SkDR HypDR

ExbDR SkDR HypDR

61

4

11
6

87
21

154
128
148

190
184

229

Figure 5: Results for TGDs with Higher-Arity Relations

process more than half of such inputs, which leads us to believe that
they can also handle more well-behaved GTGDs used in practice.

8 CONCLUSION
We presented several algorithms for rewriting a finite set of guarded
TGDs into a Datalog program that entails the same base facts on
each base instance. Our algorithms are based on a new framework
that establishes a close connection between Datalog rewritings
and a particular style of the chase. In future, we plan to generalize
our framework to wider classes of TGDs, such as frontier-guarded
TGDs, as well as provide rewritings for conjunctive queries under
certain answer semantics. Moreover, we shall investigate whether
the extension of our framework to disjunctive guarded TGDs [31]
can be used to obtain practical algorithms for rewriting disjunctive
guarded TGDs into disjunctive Datalog programs.

ACKNOWLEDGMENTS
This work was funded by the EPSRC grants OASIS (EP/S032347/1),
AnaLOG (EP/P025943/1), Concur (EP/V050869/1), and QUINTON
(EP/T022124/1). For the purpose of Open Access, the author has
applied a CC BY public copyright licence to any Author Accepted
Manuscript (AAM) version arising from this submission.

REFERENCES
[1] Shqiponja Ahmetaj, Magdalena Ortiz, and Mantas Simkus. 2018. Rewrit-
ing Guarded Existential Rules into Small Datalog Programs. In ICDT. Schloss
Dagstuhlâ€“Leibniz-Zentrum fuer Informatik, 4:1â€“4:24.

[2] GÃ¼nes AluÃ§, Olaf Hartig, M. Tamer Ã–zsu, and Khuzaima Daudjee. 2014. Di-
versified Stress Testing of RDF Data Management Systems. In ISWC. Springer,
197â€“212.

[3] Mario Alviano, Nicola Leone, Marco Manna, Giorgio Terracina, and Pierfrancesco
Veltri. 2012. Magic-Sets for Datalog with Existential Quantifiers. In Datalog 2.0.
Springer, 31â€“43.

[4] Antoine Amarilli and Michael Benedikt. 2022. When Can We Answer Queries
Using Result-Bounded Data Interfaces? Log. Methods Comput. Sci. 18, 2 (2022),
14:1â€”-14:81.

[5] Hajnal AndrÃ©ka, Johan van Benthem, and IstvÃ¡n NÃ©meti. 1998. Modal languages
and bounded fragments of predicate logic. Journal of Philosophical Logic 27
(1998), 217â€“274.

[6] F. Baader, D. Calvanese, D. McGuinness, D. Nardi, and P. F. Patel-Schneider (Eds.).
2007. The Description Logic Handbook: Theory, Implementation and Applications
(2nd ed.). Cambridge University Press, Cambridge, UK.

[7] M. Baaz, U. Egly, and A. Leitsch. 2001. Normal Form Transformations.

In
Handbook of Automated Reasoning, A. Robinson and A. Voronkov (Eds.). Vol. I.
Elsevier Science, Amsterdam, The Netherlands, Chapter 5, 273â€“333.

[8] Leo Bachmair and Harald Ganzinger. 2001. Resolution Theorem Proving. Hand-

[9]

[10]

book of automated reasoning 1 (2001), 19â€“99.
J.-F. Baget, M. LeclÃ¨re, M.-L. Mugnier, S. Rocher, and C. Sipieter. 2015. Graal:
A Toolkit for Query Answering with Existential Rules. In RuleML. Springer,
328â€“344.
Jean-FranÃ§ois Baget, Marie-Laure Mugnier, Sebastian Rudolph, and MichaÃ«l
Thomazo. 2011. Walking the complexity lines for generalized guarded existential
rules. In IJCAI. AAAI Press, 712â€“717.

[11] Vince BÃ¡rÃ¡ny, Michael Benedikt, and Balder Ten Cate. 2013. Rewriting Guarded

Negation Queries. In MFCS. Springer, 98â€“110.

[12] Luigi Bellomarini, Emanuel Sallinger, and Georg Gottlob. 2018. The Vadalog
System: Datalog-based Reasoning for Knowledge Graphs. Proc. VLDB Endow. 11,
9 (2018), 975â€“987.

[13] Michael Benedikt, Maxime Buron, Stefano Germano, Kevin Kappelmann, and
Boris Motik. 2021. Guarded Saturation. GitHub. Retrieved July 4, 2022 from
https://krr-oxford.github.io/Guarded-saturation/

[14] Michael Benedikt, George Konstantinidis, Giansalvatore Mecca, Boris Motik,
Paolo Papotti, Donatello Santoro, and Efthymia Tsamoura. 2017. Benchmarking
the Chase. In PODS. ACM, 37â€“52.

[15] Andrea CalÃ¬, Georg Gottlob, and Michael Kifer. 2013. Taming the Infinite Chase:
Query Answering under Expressive Relational Constraints. Journal of Artificial
Intelligence Research 48 (2013), 115â€“174.

[16] Andrea CalÃ¬, Domenico Lembo, and Riccardo Rosati. 2003. Query rewriting
and answering under constraints in data integration systems. In IJCAI. Morgan
Kaufmann, 16â€“21.

[17] Diego Calvanese, Benjamin Cogrel, Sarah Komla-Ebri, Roman Kontchakov, Da-
vide Lanti, Martin Rezk, Mariano Rodriguez-Muro, and Guohui Xiao. 2017. Ontop:
Answering SPARQL queries over relational databases. Semantic Web 8, 3 (2017),
471â€“487.

[18] Diego Calvanese, Giuseppe De Giacomo, Domenico Lembo, Maurizio Lenzerini,
and Riccardo Rosati. 2007. Tractable Reasoning and Efficient Query Answering in
Description Logics: The DL-Lite Family. J. Autom. Reason. 39, 3 (2007), 385â€“429.
[19] Hans de Nivelle. 1998. A Resolution Decision Procedure for the Guarded Frag-

ment. In CADE. Springer, 191â€“204.

[20] A. Deutsch, L. Popa, and V. Tannen. 2006. Query reformulation with constraints.

SIGMOD Record 35, 1 (2006), 65â€“73.

[21] R. Fagin, P. G. Kolaitis, R. J. Miller, and L. Popa. 2005. Data exchange: semantics
and query answering. Theoretical Computer Science 336, 1 (2005), 89â€“124.
[22] Mohamed Gaha, Arnaud Zinflou, Christian Langheit, Alexandre Bouffard, Math-
ieu Viau, and Luc Vouligny. 2013. An Ontology-Based Reasoning Approach for
Electric Power Utilities. In RR. Springer, 95â€“108.

[23] H. Ganzinger and H. de Nivelle. 1999. A Superposition Decision Procedure for
the Guarded Fragment with Equality. In Proc. of the 14th IEEE Symposium on

Logic in Computer Science (LICS â€™99). IEEE Computer Society, 295â€“305.

[24] Georg Gottlob, Sebastian Rudolph, and Mantas Simkus. 2014. Expressiveness of

Guarded Existential Rule Languages. In PODS. ACM, 27â€“38.

[25] Alon Halevy, Anand Rajaraman, and Joann Ordille. 2006. Data Integration: The

Teenage Years. In VLDB. ACM, 9â€“16.

[26] Alon Y. Halevy. 2001. Answering queries using views: A survey. VLDB Journal

10, 4 (2001), 270â€“294.

[27] Colin Hirsch. 2002. Guarded Logics: Algorithms and Bisimulation. Ph.D. Dis-
sertation. RWTH Aachen, Aachen, Germany. Retrieved July 4, 2022 from
http://www.umbrialogic.com/hirsch-thesis.pdf

[28] Ullrich Hustadt, Boris Motik, and Ulrike Sattler. 2004. Reducing S H I Q âˆ’
Description Logic to Disjunctive Datalog Programs. In KR. AAAI Press, 152â€“162.
[29] Ullrich Hustadt, Boris Motik, and Ulrike Sattler. 2007. Reasoning in description
logics by a reduction to disjunctive datalog. Journal of Automated Reasoning 39,
3 (2007), 351â€“384.

[30] David S. Johnson and Anthony C. Klug. 1984. Testing Containment of Conjunc-
tive Queries under Functional and Inclusion Dependencies. JCSS 28, 1 (1984),
167â€“189.

[31] Kevin Kappelmann. 2019. Decision Procedures for Guarded Logics. CoRR
abs/1911.03679 (2019), 92. Retrieved July 4, 2022 from http://arxiv.org/abs/
1911.03679

[32] Deepak Kapur and Paliath Narendran. 1986. NP-Completeness of the Set Unifi-

cation and Matching Problems. In CADE. Springer, 489â€“495.

[33] Alon Y. Levy. 2000. Logic-Based Techniques in Data Integration. Kluwer Academic

Publishers, Norwell, MA, USA, 575â€“595.

[34] Thomas Lukasiewicz, Andrea CalÃ¬, and Georg Gottlob. 2012. A General Datalog-
Based Framework for Tractable Query Answering over Ontologies. Journal of
Web Semantics 14, 0 (2012), 57â€“83.

[35] Bruno Marnette. 2012. Resolution and Datalog Rewriting Under Value Invention

and Equality Constraints. CoRR abs/1212.0254 (2012), 12.

[36] William McCune and Larry Wos. 1997. Otterâ€”The CADE-13 Competition Incar-

nations. Journal of Automated Reasoning 18, 2 (1997), 211â€“220.

[37] M. Meier. 2014. The backchase revisited. VLDB J. 23, 3 (2014), 495â€“516.
[38] Boris Motik. 2006. Reasoning in description logics using resolution and deductive
databases. Ph.D. Dissertation. Karlsruhe Institute of Technology, Karlsruhe,
Germany. Retrieved July 4, 2022 from http://digbib.ubka.uni-karlsruhe.de/
volltexte/1000003797

[39] Boris Motik. 2022. The KAON2 System. Karslruhe Institute of Technology.

Retrieved July 4, 2022 from http://kaon2.semanticweb.org/

[40] Oxford KR group. 2021. Oxford Ontology Library. Oxford University. Retrieved

July 4, 2022 from http://krr-nas.cs.ox.ac.uk/ontologies/

[41] Mike Paterson and Mark N. Wegman. 1978. Linear Unification. J. Comput. Syst.

[42]

[43]

Sci. 16, 2 (1978), 158â€“167.
John Alan Robinson. 1965. A machine-oriented logic based on the resolution
principle. JACM 12, 1 (1965), 23â€“41.
Iztok Savnik. 2013. Index Data Structure for Fast Subset and Superset Queries.
In CD-ARES. Springer, 134â€“148.

[44] Stephan Schulz. 2013. Simple and Efficient Clause Subsumption with Feature

Vector Indexing. In Automated Reasoning and Mathematics. Springer, 45â€“67.

[45] Mark E. Stickel. 1989. The Path-Indexing Method for Indexing Terms. Technical

Report. SRI.

[46] Oxford Semantic Technologies. 2022. The RDFox System. Oxford Semantic

Technologies. Retrieved July 4, 2022 from https://www.oxfordsemantic.tech/

[47] Moshe Y. Vardi. 1997. Why Is Modal Logic so Robustly Decidable?. In DIMACS
Series in Discrete Mathematics and Theoretical Computer Science, Vol. 31. American
Mathematical Society, 149â€“184.

[48] Roberto De Virgilio, Giorgio Orsi, Letizia Tanca, and Riccardo Torlone. 2012.
NYAYA: A System Supporting the Uniform Management of Large Sets of Seman-
tic Data. In ICDE. IEEE Computer Society, 1309â€“1312.

[49] Zhe Wang, Peng Xiao, Kewen Wang, Zhiqiang Zhuang, and Hai Wan. 2021.
Query Answering for Existential Rules via Efficient Datalog Rewriting. In IJCAI.
ijcai.org, 1933â€“1939.

[50] Sen Zheng and Renate A. Schmidt. 2020. Deciding the Loosely Guarded Fragment
and Querying Its Horn Fragment Using Resolution. In AAAI. AAAI Press, 3080â€“
3087.

A PROOFS FOR SECTION 4: ONE-PASS CHASE PROOFS
In Section 4 we introduced the notion of a one-pass chase proof, which allows us to establish a completeness criterion for saturations that is
tied to the chase. We provide details of the proofs in this appendix.

A.1 Proof of Theorem 4.2: Existence of One-Pass Chase Proofs

Theorem 4.2. For each base instance ğ¼ , each finite set of GTGDs Î£ in head-normal form, and each base fact ğ¹ such that ğ¼, Î£ |= ğ¹ , there exists a

one-pass tree-like chase proof of ğ¹ from ğ¼ and Î£.

Throughout this section, we fix an arbitrary base instance ğ¼ and a finite set of GTGDs Î£. It is known that ğ¼, Î£ |= ğ¹ if and only if there exists
a tree-like chase proof of ğ¹ from ğ¼ and Î£. We next prove Theorem 4.2 by showing that each such proof can be transformed to a one-pass
chase proof of ğ¹ from ğ¼ and Î£. This argument was developed jointly with Antoine Amarilli, and it is related to proofs by Amarilli and
Benedikt [4] and Kappelmann [31]; however, note that Definition 4.1 imposes slightly stronger conditions on one-pass chase sequences than
related definitions in those works.

Towards our goal, we first state two basic properties of tree-like chase sequences. The first claim is a variation of the well-known fact that
any chase tree produced for GTGDs represents a tree decomposition [15]. The second claim captures the idea that, as the chase progresses,
facts may be added within a vertex, but this will not produced new guarded sets of terms.

Lemma A.1. Let ğ‘‡0, . . . ,ğ‘‡ğ‘› be an arbitrary tree-like chase sequence for ğ¼ and Î£.

1. For each 0 â‰¤ ğ‘– â‰¤ ğ‘›, all vertices ğ‘£1 and ğ‘£2 in ğ‘‡ğ‘– , each set ğº of ground terms that is Î£-guarded by ğ‘‡ğ‘– (ğ‘£1) and by ğ‘‡ğ‘– (ğ‘£2), and each vertex ğ‘£3 on

the unique path in ğ‘‡ğ‘– between ğ‘£1 and ğ‘£2, set ğº is Î£-guarded by ğ‘‡ğ‘– (ğ‘£3).

2. For each 0 â‰¤ ğ‘– â‰¤ ğ‘›, each vertex ğ‘£ in ğ‘‡ğ‘– , each set ğº of ground terms that is Î£-guarded by ğ‘‡ğ‘– (ğ‘£), and each 0 â‰¤ ğ‘— â‰¤ ğ‘– such that ğ‘‡ğ‘— contains ğ‘£, set

ğº is Î£-guarded by ğ‘‡ğ‘— (ğ‘£).

Proof of Claim 1. The proof is by induction on ğ‘– with 0 â‰¤ ğ‘– â‰¤ ğ‘›. For ğ‘– = 0, chase tree ğ‘‡0 contains just one vertex so the claim holds
trivially. Now assume that the property holds for some 0 â‰¤ ğ‘– < ğ‘› and consider ways in which ğ‘‡ğ‘–+1 can be derived from ğ‘‡ğ‘– . First, ğ‘‡ğ‘–+1 can be
obtained by applying a chase step to ğ‘‡ğ‘– at vertex ğ‘£ with some GTGD ğœ âˆˆ Î£. Let ğ‘£1 be the recently updated vertex of ğ‘‡ğ‘–+1. Thus, ğ‘£1 is either ğ‘£
or a fresh child of ğ‘£. Moreover, consider each fact ğ‘…((cid:174)ğ‘¡) derived by the step, each set of ground terms ğº âŠ† (cid:174)ğ‘¡, each vertex ğ‘£2 such that ğº is
Î£-guarded by ğ‘‡ğ‘–+1 (ğ‘£2), and each vertex ğ‘£3 on the unique path in ğ‘‡ğ‘–+1 between ğ‘£1 and ğ‘£2. If ğº contains a labeled null that is freshly introduced
in ğ‘‡ğ‘–+1, the claim holds trivially because ğ‘£2 and ğ‘£3 are necessarily the same as ğ‘£1. Otherwise, ğœ is guarded, so ğ‘‡ğ‘– (ğ‘£) contains a fact ğ‘† ( (cid:174)ğ‘¢) such
that ğº âŠ† (cid:174)ğ‘¢. But then, ğº is Î£-guarded by ğ‘‡ğ‘– (ğ‘£3) by the induction assumption. Moreover, ğ‘‡ğ‘– (ğ‘£3) âŠ† ğ‘‡ğ‘–+1 (ğ‘£3) ensures that ğº is Î£-guarded by
â–¡
ğ‘‡ğ‘–+1 (ğ‘£3), as required. Second, ğ‘‡ğ‘–+1 can be obtained by applying a propagation step to ğ‘‡ğ‘– , but then the property clearly holds.

Proof of Claim 2. The proof is by induction on ğ‘– with 0 â‰¤ ğ‘– â‰¤ ğ‘›. The base case for ğ‘– = 0 is trivial. For the induction step, assume that the
property holds for some ğ‘–. If ğ‘‡ğ‘–+1 is obtained from ğ‘‡ğ‘– by a chase step with a non-full GTGD, then the claim clearly holds for ğ‘‡ğ‘–+1 because the
step introduces a fresh vertex that does not occur in any ğ‘‡ğ‘— with 0 â‰¤ ğ‘— â‰¤ ğ‘–. Otherwise, ğ‘‡ğ‘–+1 is obtained by extending some ğ‘‡ğ‘– (ğ‘£), so consider
an arbitrary fact ğ¹ âˆˆ ğ‘‡ğ‘–+1 (ğ‘£) \ ğ‘‡ğ‘– (ğ‘£). Clearly, ğ¹ is Î£-guarded by ğ‘‡ğ‘– (ğ‘£): if the step involves a full GTGD, then a body atom of the GTGD is
matched to a fact ğ¹ â€² âˆˆ ğ‘‡ğ‘– (ğ‘£) such that ğ¹ is Î£-guarded by ğ¹ â€²; moreover, if the step involves propagation, then by definition there exists a fact
ğ¹ â€² âˆˆ ğ‘‡ğ‘– (ğ‘£) such that ğ¹ is Î£-guarded by ğ¹ â€². Thus, each set of ground terms ğº that is Î£-guarded by ğ‘‡ğ‘–+1 (ğ‘£) is also Î£-guarded by ğ¹ â€² âˆˆ ğ‘‡ğ‘– (ğ‘£), so
â–¡
the claim holds.

In the rest of the proof, we show how to convert an arbitrary tree-like chase proof into a one-pass one through a series of transformations.

Before proceeding, we next describe formally the types of chase sequence that we consider in our transformations.

Definition A.2.
â€¢ A chase sequence is local if each propagation step in the sequence copies just one fact to either the parent or a child vertex.
â€¢ A chase sequence is rootward if each propagation step in the sequence copies just one fact from a child to its parent.
â€¢ A chase sequence is almost one-pass if it is rootward and each chase or propagation step is applied to the recently updated vertex or an
ancestor thereof, and a chase step is applied only if a propagation step is not applicable to the recently updated vertex or an ancestor thereof.

Note that facts can still be copied from a parent to a child in a rootward chase sequence, but this can be done only in chase steps with
non-full GTGDs that introduce a child. Furthermore, the use of â€œalmostâ€ in the â€œalmost one-passâ€ reflects the caveat that, in an almost
one-pass chase sequence, a step can be applied to an ancestor of the recently updated vertex, thus â€œjumping rootwardâ€ in the tree, whereas
such steps are forbidden in a one-pass chase sequence.

We capture formally the relationship between the chase sequences produced by our transformations using the notion introduced in

Definition A.3.
Definition A.3. A chase tree ğ‘‡ is a subset of a chase tree ğ‘‡ â€², written ğ‘‡ âŠ† ğ‘‡ â€², if the tree of ğ‘‡ is a subtree of ğ‘‡ â€² (i.e., the root of ğ‘‡ is the root of ğ‘‡ â€²,
and whenever vertex ğ‘£ is a parent of vertex ğ‘£ â€² in ğ‘‡ , then ğ‘£ is a parent of ğ‘£ â€² in ğ‘‡ â€²), and ğ‘‡ (ğ‘£) âŠ† ğ‘‡ â€² (ğ‘£) holds for each vertex ğ‘£ of ğ‘‡ .

We are now ready to present our transformations, which we capture in a series of lemmas. We next summarize the main intuitions.

â€¢ In Lemma A.4, we show that an arbitrary chase sequence can be transformed into a local chase sequence by â€œslowing downâ€ propagation

steps so that facts are copied only between vertices that are adjacent in a chase tree.

â€¢ In Lemma A.5, we show that each local chase sequence can be transformed into a rootward chase sequence. Intuitively, instead of
propagating a fact from a parent to a child, we â€œregrowâ€ a clone of the relevant child and the entire subtree underneath. The relevant fact
is then copied as part of the chase step with the non-full GTGD that â€œregrowsâ€ the childâ€™s clone.

â€¢ In Lemma A.6, we show that each rootward chase sequence can be transformed to an almost one-pass chase sequence. The main difficulty
arises due to the fact that steps in a rootward chase sequence can be applied to arbitrary vertices. We address this problem by shuffling
and regrowing parts of the chase trees.

â€¢ Finally, in Lemma A.7, we show that each almost one-pass chase proof can be transformed to a one-pass chase proof by pruning irrelevant

parts of the chase sequence.
Lemma A.4. For each tree-like chase sequence ğ‘‡0, . . . ,ğ‘‡ğ‘› for ğ¼ and Î£, there exists a local tree-like chase sequence ğ‘‡ 0, . . . ,ğ‘‡ ğ‘š for ğ¼ and Î£ such

that ğ‘‡ğ‘› âŠ† ğ‘‡ ğ‘š.

Proof. Each propagation step in ğ‘‡0, . . . ,ğ‘‡ğ‘› that copies more than one fact can clearly be â€œexpandedâ€ into several steps, each copying just
one fact. Moreover, due to Claim 1 of Lemma A.1, each propagation step that copies a fact ğ¹ between vertices ğ‘£ and ğ‘£ â€² that are further apart
can be â€œexpandedâ€ into several steps that propagate ğ¹ to all vertices on the unique path between ğ‘£ and ğ‘£ â€².
â–¡

Lemma A.5. For each local tree-like chase sequence ğ‘‡0, . . . ,ğ‘‡ğ‘› for ğ¼ and Î£, there exists a rootward tree-like chase sequence ğ‘‡ 0, . . . ,ğ‘‡ ğ‘š for ğ¼

and Î£ such that

(S1) ğ‘‡ğ‘› âŠ† ğ‘‡ ğ‘š, and
(S2) for each vertex ğ‘£ in ğ‘‡ğ‘› that is introduced by a chase step with a non-full GTGD ğœ âˆˆ Î£ and substitutions ğœ and ğœ â€², vertex ğ‘£ is introduced
into some ğ‘‡ ğ‘˜ with 0 â‰¤ ğ‘˜ â‰¤ ğ‘š by a chase step with the same ğœ, ğœ, and ğœ â€².

Proof. Let ğ‘‡0, . . . ,ğ‘‡ğ‘› be an arbitrary local tree-like chase sequence for ğ¼ and Î£. We prove the claim by induction on 0 â‰¤ ğ‘– â‰¤ ğ‘›. The
induction base ğ‘– = 0 holds trivially. For the induction step, we assume that the claim holds for some ğ‘– with 0 â‰¤ ğ‘– < ğ‘›. By the inductive
assumption, there exists a rootward chase sequence ğ‘‡ 0, . . . ,ğ‘‡ ğ‘— for ğ¼ such that ğ‘‡ğ‘– âŠ† ğ‘‡ ğ‘— and property (S2) holds. Let ğ‘£ be the vertex of ğ‘‡ğ‘– to
which a chase or propagation step is applied to derive ğ‘‡ğ‘–+1. By Definition A.3, chase tree ğ‘‡ ğ‘— contains vertex ğ‘£ and ğ‘‡ğ‘– (ğ‘£) âŠ† ğ‘‡ ğ‘— (ğ‘£) holds. We
now consider ways in which ğ‘‡ğ‘–+1 can be derived from ğ‘‡ğ‘– .

Assume that ğ‘‡ğ‘–+1 is obtained from ğ‘‡ğ‘– by a chase step with non-full TGD ğœ âˆˆ Î£, and let ğ‘£ â€² be the child of ğ‘£ introduced by the step. Without
loss of generality, we can choose ğ‘£ â€² and the fresh labeled nulls such that they do not occur in ğ‘‡ ğ‘— . Now let ğ‘‡ ğ‘—+1 be obtained from ğ‘‡ ğ‘— by
adding ğ‘£ â€² as a child of ğ‘£ and setting ğ‘‡ ğ‘—+1 (ğ‘£ â€²) = ğ‘‡ğ‘–+1 (ğ‘£ â€²). Clearly, ğ‘‡ 0, . . . ,ğ‘‡ ğ‘— ,ğ‘‡ ğ‘—+1 is a rootward chase sequence such that ğ‘‡ğ‘–+1 âŠ† ğ‘‡ ğ‘—+1 and
property (S2) hold, as required.

Assume that ğ‘‡ğ‘–+1 is obtained from ğ‘‡ğ‘– by a chase step with a full TGD ğœ âˆˆ Î£ deriving a fact ğ¹ , or by a rootward propagation step that copies
a fact ğ¹ from ğ‘‡ğ‘– (ğ‘£) to the parent of ğ‘£. Let ğ‘£ â€² be the recently updated vertex of ğ‘‡ğ‘–+1. Chase tree ğ‘‡ ğ‘— clearly contains ğ‘£ â€². If ğ¹ âˆˆ ğ‘‡ ğ‘— (ğ‘£ â€²), then
sequence ğ‘‡ 0, . . . ,ğ‘‡ ğ‘— satisfies the inductive property. If ğ‘‡ğ‘–+1 is obtained from ğ‘‡ğ‘– by a propagation step, then ğ¹ is Î£-guarded by ğ‘‡ğ‘– (ğ‘£ â€²). But
then, ğ‘‡ğ‘– (ğ‘£ â€²) âŠ† ğ‘‡ ğ‘— (ğ‘£ â€²) ensures that ğ¹ is also Î£-guarded by ğ‘‡ ğ‘— (ğ‘£ â€²) and thus the propagation step is applicable to vertices ğ‘£ and ğ‘£ â€² in ğ‘‡ ğ‘— . Now
let ğ‘‡ ğ‘—+1 to be the same as ğ‘‡ ğ‘— but with ğ‘‡ ğ‘—+1 (ğ‘£ â€²) = ğ‘‡ ğ‘— (ğ‘£ â€²) âˆª {ğ¹ } and with ğ‘£ â€² being the recently updated vertex. Clearly, ğ‘‡ 0, . . . ,ğ‘‡ ğ‘— ,ğ‘‡ ğ‘—+1 is a
rootward chase sequence satisfying ğ‘‡ğ‘–+1 âŠ† ğ‘‡ ğ‘—+1, as required. Moreover, property (S2) holds by the induction hypothesis.

The only remaining case is when ğ‘‡ğ‘–+1 is obtained from ğ‘‡ğ‘– by applying a propagation step that copies one fact ğ¹ to a child ğ‘£ â€² of ğ‘£. By
Definition A.3, chase tree ğ‘‡ ğ‘— contains vertex ğ‘£ â€² and ğ‘‡ğ‘– (ğ‘£ â€²) âŠ† ğ‘‡ ğ‘— (ğ‘£ â€²) holds. Sequence ğ‘‡ 0, . . . ,ğ‘‡ ğ‘— satisfies the inductive property if ğ¹ âˆˆ ğ‘‡ ğ‘— (ğ‘£ â€²)
holds, so we next assume ğ¹ âˆ‰ ğ‘‡ ğ‘— (ğ‘£ â€²). We next show that we can simulate propagation by â€œreplayingâ€ the chase steps that generate ğ‘£ â€² and all
of its descendants. Towards this goal, let ğ‘‡ğ‘˜ be the chase tree in the original sequence where ğ‘£ â€² is first introduced by applying a chase step
with the non-full GTGD ğœ = ğ›½ â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚ âˆˆ Î£, and let ğœ and ğœ â€² be substitutions used in the step. By the inductive property (S2), there exists â„“0
with 0 < â„“0 â‰¤ ğ‘— such that ğ‘£ â€² is introduced in ğ‘‡ â„“0 as the result of applying a chase step with the same non-full TGD ğœ and substitutions ğœ and
ğœ â€². Finally, let ğ‘‡ â„“0
, . . . ,ğ‘‡ â„“ğ‘š be the subsequence of ğ‘‡ 0, . . . ,ğ‘‡ ğ‘— consisting of precisely those chase trees that were obtained by applying a chase
or a propagation step to ğ‘£ â€² or a descendant of ğ‘£ â€². In other words, the chase steps producing ğ‘‡ â„“0
, . . . ,ğ‘‡ â„“ğ‘š are exactly the steps that we need to
â€œreplayâ€ to simulate the propagation of ğ¹ from ğ‘£ to ğ‘£ â€².
Our objective is to â€œreplayâ€ the steps producing ğ‘‡ â„“0

, . . . ,ğ‘‡ â„“ğ‘š so that they introduce exactly the same vertices and labeled nulls, which is
needed because property (S1) talks about exact containment of the final chase trees of the two sequences (rather than containment up to
isomorphism). A technical issue is that these vertices and labeled nulls already occur in the sequence ğ‘‡ 0, . . . ,ğ‘‡ ğ‘— ; thus, if we extended this
sequence directly, we could not â€œreapplyâ€ the chase steps with non-full GTGDs, which by definition introduce fresh vertices and labeled
nulls. To get around this, we first perform the following renaming step. Let ğ‘ be the set of labeled nulls introduced by the chase steps
, . . . ,ğ‘‡ â„“ğ‘š , and let ğ‘Š be the set of introduced vertices (thus, ğ‘Š contains ğ‘£ â€² and all of its descendants).
with non-full TGDs in subsequence ğ‘‡ â„“0
Moreover, let ğ‘ˆ 0, . . . , ğ‘ˆ ğ‘— be the chase sequence obtained by uniformly replacing in ğ‘‡ 0, . . . ,ğ‘‡ ğ‘— each labeled null in ğ‘ with a distinct, fresh
labeled null, and by uniformly replacing each vertex ğ‘¤ âˆˆ ğ‘Š by a fresh vertex.

We next describe the chase trees that will be produced by â€œreplayingâ€ the steps producing the subsequence ğ‘‡ â„“0

, . . . ,ğ‘‡ â„“ğ‘š . Intuitively, we
must â€œgraftâ€ the results of these steps onto ğ‘ˆ ğ‘— : for ğ‘£ â€² or a descendant of ğ‘£ â€² we take the results of the chase steps in the subsequence, and for
each other vertex we copy the content from ğ‘ˆ ğ‘— . Formally, let ğ‘‰ 0, . . . , ğ‘‰ ğ‘š be the sequence obtained from the subsequence ğ‘‡ â„“0
, . . . ,ğ‘‡ â„“ğ‘š using
the following steps.
(R1) For each 0 â‰¤ ğ‘ â‰¤ ğ‘š and each vertex ğ‘¤ in ğ‘ˆ ğ‘— such that ğ‘¤ is neither ğ‘£ â€² nor a descendant of ğ‘£ â€² in ğ‘ˆ ğ‘— , we set ğ‘‰ ğ‘ (ğ‘¤) = ğ‘ˆ ğ‘— (ğ‘¤).
(R2) For each 0 â‰¤ ğ‘ â‰¤ ğ‘š and each vertex ğ‘¤ that occurs in ğ‘‡ â„“ğ‘ such that ğ‘¤ is ğ‘£ â€² or a descendant of ğ‘£ â€² in ğ‘‡ â„“ğ‘ , we set ğ‘‰ ğ‘ (ğ‘¤) = ğ‘‡ â„“ğ‘ (ğ‘¤).
(R3) We add to ğ‘‰ 0 (ğ‘£ â€²) each fact ğº âˆˆ ğ‘ˆ ğ‘— (ğ‘£) that is Î£-guarded by ğœ â€² (ğœ‚).
(R4) We analogously extend each ğ‘‰ ğ‘ with 1 â‰¤ ğ‘ â‰¤ ğ‘š to ensure that each chase step with a non-full GTGD correctly propagates all relevant

facts to a child.

We now argue that ğ‘ˆ 0, . . . , ğ‘ˆ ğ‘— , ğ‘‰ 0, . . . , ğ‘‰ ğ‘š is a rootward chase sequence that satisfies properties (S1) and (S2). Towards this goal, we make

the following observations.
â€¢ Sequence ğ‘ˆ 0, . . . , ğ‘ˆ ğ‘— is a rootward chase sequence produced by the same steps as ğ‘‡ 0, . . . ,ğ‘‡ ğ‘— , but with the vertices in ğ‘Š and labeled nulls

in ğ‘ uniformly renamed. Also, due to step (R4), ğ‘‰ 0, . . . , ğ‘‰ ğ‘š is a rootward chase sequence produced by the same steps as ğ‘‡ â„“0

, . . . ,ğ‘‡ â„“ğ‘š .

â€¢ Chase tree ğ‘‰ 0 coincides with ğ‘ˆ ğ‘— on each vertex that is not ğ‘£ â€² or a descendant of ğ‘£ â€². Moreover, ğ‘ˆ ğ‘— does not contain a labeled null in ğ‘ ,
and it does not contain ğ‘£ â€² or a descendant of ğ‘£ â€²; thus, ğ‘‰ 0 can be seen as the result of applying to ğ‘ˆ ğ‘— a chase step with the non-full GTGD
ğœ and substitutions ğœ and ğœ â€² that introduces vertex ğ‘£ â€² as a child of ğ‘£.

â€¢ We now show that property (S2) is satisfiedâ€”that is, that ğ‘‡ğ‘–+1 âŠ† ğ‘‰ ğ‘š holds. Towards this goal, consider an arbitrary vertex ğ‘¤ occurring
in ğ‘‡ğ‘–+1; by the induction assumption, we have ğ‘‡ğ‘– (ğ‘¤) âŠ† ğ‘‡ ğ‘— (ğ‘¤). If ğ‘¤ is neither ğ‘£ â€² nor a descendant thereof, then neither ğ‘¤ nor a labeled
null occurring in ğ‘‡ğ‘– (ğ‘¤) was renamed in ğ‘ˆ ğ‘— , so we have ğ‘‡ ğ‘— (ğ‘¤) = ğ‘ˆ ğ‘— (ğ‘¤) = ğ‘‰ ğ‘š (ğ‘¤), where the last equality is ensured by step (R1); thus,
ğ‘‡ğ‘–+1 (ğ‘¤) = ğ‘‡ğ‘– (ğ‘¤) âŠ† ğ‘‰ ğ‘š (ğ‘¤) holds, as required. Now assume that ğ‘¤ is ğ‘£ â€² or a descendant thereof. Then, ğ‘‡ ğ‘— (ğ‘¤) = ğ‘‡ â„“ğ‘š (ğ‘¤) holds by the fact
that ğ‘‡ â„“ğ‘š is the last place in ğ‘‡ 0, . . . ,ğ‘‡ ğ‘— where ğ‘£ â€² or a descendant of ğ‘£ â€² was modified, and ğ‘‡ â„“ğ‘š (ğ‘¤) = ğ‘‰ ğ‘š (ğ‘¤) holds by step (R2); putting it
all together, we have ğ‘‡ğ‘– (ğ‘¤) âŠ† ğ‘‰ ğ‘š (ğ‘¤). Now if ğ‘¤ is not ğ‘£ â€² (i.e., ğ‘¤ is a descendant of ğ‘£ â€²), then ğ‘‡ğ‘–+ğ‘– (ğ‘¤) = ğ‘‡ğ‘– (ğ‘¤) âŠ† ğ‘‰ ğ‘š (ğ‘¤) holds, as required.
We finally consider the case when ğ‘¤ is ğ‘£ â€², so ğ‘‡ğ‘–+1 (ğ‘£ â€²) = ğ‘‡ğ‘– (ğ‘£ â€²) âˆª {ğ¹ }. Since the propagation step is applicable to ğ‘‡ğ‘– , fact ğ¹ is Î£-guarded by
ğ‘‡ğ‘– (ğ‘£ â€²). By Claim 2 of Lemma A.1, fact ğ¹ is also Î£-guarded by ğ‘‡ğ‘˜ (ğ‘£ â€²). Finally, by the definition of a chase step with a non-full TGD, fact ğ¹
is Î£-guarded by ğœ â€² (ğœ‚). But then, step (R3) ensures ğ¹ âˆˆ ğ‘‰ 0 (ğ‘£ â€²) âŠ† ğ‘‰ ğ‘š (ğ‘£ â€²). Consequently, ğ‘‡ğ‘–+ğ‘– (ğ‘£ â€²) âŠ† ğ‘‰ ğ‘š (ğ‘£ â€²) holds, as required.

â€¢ We now show that property (S2) is satisfied. To this end, consider an arbitrary vertex ğ‘¤ in ğ‘‡ğ‘–+1 introduced by a chase step with a non-full
GTGD ğœ and substitutions ğœ and ğœ â€². If ğ‘¤ is not ğ‘£ â€² or a descendant thereof, then the labeled nulls introduced by the chase step are not
renamed in ğ‘ˆ 0, . . . , ğ‘ˆ ğ‘— , so the claim holds by the induction assumption. Otherwise, the chase steps producing ğ‘‰ 0, . . . , ğ‘‰ ğ‘š are exactly the
â–¡
, . . . ,ğ‘‡ â„“ğ‘š , so the claim holds by the induction assumption too.
same as the chase steps producing ğ‘‡ â„“0

Lemma A.6. For each rootward tree-like chase sequence ğ‘‡0, . . . ,ğ‘‡ğ‘› for ğ¼ and Î£, there exists an almost one-pass chase sequence ğ‘‡ 0, . . . ,ğ‘‡ ğ‘š for ğ¼

and Î£ such that ğ‘‡ğ‘› âŠ† ğ‘‡ ğ‘š.

Proof. Let ğ‘‡0, . . . ,ğ‘‡ğ‘› be an arbitrary rootward tree-like chase sequence for ğ¼ and Î£. The induction base ğ‘– = 0 holds trivially. For the
induction step, we assume that the claim holds for some ğ‘– with 0 â‰¤ ğ‘– < ğ‘›. By the inductive assumption, there exists an almost one-pass chase
sequence ğ‘‡ 0, . . . ,ğ‘‡ ğ‘— for ğ¼ and Î£ such that ğ‘‡ğ‘– âŠ† ğ‘‡ ğ‘— holds. Now assume that ğ‘‡ğ‘–+1 is obtained by applying a chase or a propagation step to some
vertex ğ‘£ of ğ‘‡ğ‘– , and let ğ‘˜ be the maximal number such that 0 â‰¤ ğ‘˜ â‰¤ ğ‘— and ğ‘£ is recently updated in ğ‘‡ ğ‘˜ . Such ğ‘˜ clearly exists since ğ‘£ occurs in
ğ‘‡ ğ‘— , and ğ‘‡ğ‘– (ğ‘£) âŠ† ğ‘‡ ğ‘˜ (ğ‘£) holds because ğ‘˜ is maximal. We now consider ways in which ğ‘‡ğ‘–+1 can be derived from ğ‘‡ğ‘– .

Assume that ğ‘‡ğ‘–+1 is obtained from ğ‘‡ğ‘– by a chase step with non-full GTGD ğœ âˆˆ Î£ and substitutions ğœ and ğœ â€², and let ğ‘£ â€² be the child of ğ‘£
introduced by the step. Without loss of generality, we can choose ğ‘£ â€² and the fresh labeled nulls such that they do not occur in ğ‘‡ ğ‘— . We shall
now â€œmoveâ€ this chase step so that it is performed immediately after ğ‘‡ ğ‘˜ . Towards this goal, we describe the chase trees that are obtained by
this move. For each ğ‘ with ğ‘˜ â‰¤ ğ‘ â‰¤ ğ‘—, let ğ‘ˆ ğ‘ be the chase tree obtained from ğ‘‡ ğ‘ by adding vertex ğ‘£ â€² and letting ğ‘ˆ ğ‘ (ğ‘£ â€²) = ğ‘‡ğ‘–+1 (ğ‘£ â€²). We now
argue that ğ‘‡ 0, . . . ,ğ‘‡ ğ‘˜, ğ‘ˆ ğ‘˜, . . . , ğ‘ˆ ğ‘— is an almost one-pass chase sequence satisfying the conditions of the lemma.
â€¢ Chase tree ğ‘ˆ ğ‘˜ can be seen as obtained from ğ‘‡ ğ‘˜ by a chase step with ğœ and substitutions ğœ and ğœ â€². Moreover, for each ğ‘ with ğ‘˜ â‰¤ ğ‘ < ğ‘—,
chase tree ğ‘ˆ ğ‘+1 is obtained from ğ‘ˆ ğ‘ in the same way as ğ‘‡ ğ‘+1 is obtained from ğ‘‡ ğ‘ . Thus, all preconditions of all chase steps are satisfied.
â€¢ Chase tree ğ‘ˆ ğ‘˜ is obtained from ğ‘‡ ğ‘˜ by applying the chase step to the recently updated vertex ğ‘£ of ğ‘‡ ğ‘˜ . Moreover, if ğ‘˜ < ğ‘—, then ğ‘‡ ğ‘˜+1 is
obtained from ğ‘‡ ğ‘˜ by applying a step to ğ‘£ or an ancestor of ğ‘£, and so ğ‘ˆ ğ‘˜+1 is obtained from ğ‘ˆ ğ‘˜ by applying a step to an ancestor of the
recently updated vertex of ğ‘ˆ ğ‘˜ . Thus, the sequence is almost one-pass.

â€¢ The construction clearly satisfies ğ‘‡ğ‘–+1 âŠ† ğ‘ˆ ğ‘— .

In the rest of this proof we consider the case when ğ‘‡ğ‘–+1 is obtained from ğ‘‡ğ‘– by a chase step with a full GTGD ğœ âˆˆ Î£ deriving a fact ğ¹ , or
by a propagation step that copies a fact ğ¹ from ğ‘‡ğ‘– (ğ‘£) to the parent of ğ‘£. Let ğ‘£ â€² be the recently updated vertex of ğ‘‡ğ‘–+1. Chase tree ğ‘‡ ğ‘— clearly

contains ğ‘£ â€². If ğ¹ âˆˆ ğ‘‡ ğ‘˜ (ğ‘£ â€²), then sequence ğ‘‡ 0, . . . ,ğ‘‡ ğ‘— satisfies the inductive property, so we next assume that ğ¹ âˆ‰ ğ‘‡ ğ‘˜ (ğ‘£ â€²) holds. We shall now
transform ğ‘‡ 0, . . . ,ğ‘‡ ğ‘— so that this step is applied immediately after ğ‘‡ ğ‘˜ , and fact ğ¹ is propagated towards the root as far as possible. Since this
will move the recently updated vertex towards the root, we will then â€œreapplyâ€ all relevant steps from ğ‘‡ 0, . . . ,ğ‘‡ ğ‘— to â€œregrowâ€ the relevant
part of the sequence. In each case, we specify the structure of the chase trees and discuss the steps that produce these trees.

Let ğ‘ˆ 0 be obtained from ğ‘‡ ğ‘˜ by adding ğ¹ to ğ‘‡ ğ‘˜ (ğ‘£). We argue that ğ‘ˆ 0 can be seen as being obtained from ğ‘‡ ğ‘˜ by the same step that produces

ğ‘‡ğ‘–+1 from ğ‘‡ğ‘– .
â€¢ If ğ‘‡ğ‘–+1 is obtained from ğ‘‡ğ‘– by a chase step with a full GTGD, then ğ¹ âˆ‰ ğ‘‡ ğ‘˜ (ğ‘£ â€²) holds ensures that the same step is applicable to ğ‘‡ ğ‘˜ (ğ‘£ â€²)

(where ğ‘£ â€² = ğ‘£).

â€¢ If ğ‘‡ğ‘–+1 is obtained from ğ‘‡ğ‘– by a propagation step, then ğ¹ is Î£-guarded by ğ‘‡ğ‘– (ğ‘£ â€²). But then, ğ‘‡ğ‘– (ğ‘£ â€²) âŠ† ğ‘‡ ğ‘— (ğ‘£ â€²) ensures that ğ¹ is also Î£-guarded
by ğ‘‡ ğ‘— (ğ‘£ â€²), and Claim 2 of Lemma A.1 ensures that ğ¹ is Î£-guarded by ğ‘‡ ğ‘˜ (ğ‘£ â€²). Thus, the propagation step is applicable to vertices ğ‘£ and ğ‘£ â€²
in ğ‘‡ ğ‘˜ .

Moreover, let ğ‘ˆ 1, . . . , ğ‘ˆ ğ‘  be the chase trees obtained by propagating ğ¹ starting from ğ‘ˆ 0 towards the root using local steps as long as possible.
Clearly, ğ‘‡ 0, . . . ,ğ‘‡ ğ‘˜, ğ‘ˆ 0, ğ‘ˆ 1, . . . , ğ‘ˆ ğ‘  is a correctly formed almost one-pass chase sequence. Let ğ‘£ â€²â€² be the recently updated vertex of ğ‘ˆ ğ‘  ,

We cannot simply append the step producing ğ‘‡ğ‘˜+1 after ğ‘ˆ ğ‘  because this step might not be applicable to ğ‘£ â€²â€² or an ancestor thereof. Thus,
to obtain the chase sequence satisfying the claim of the lemma, we shall find a place in sequence ğ‘‡ 0, . . . ,ğ‘‡ ğ‘— where vertex ğ‘£ â€²â€² is introduced,
and we shall â€œreplayâ€ all steps from that point onwards. In doing so, we shall use chase steps that introduce the same vertices and labeled
nulls, so we will first need to rename these in the sequence ğ‘‡ 0, . . . ,ğ‘‡ ğ‘˜, ğ‘ˆ 0, ğ‘ˆ 1, . . . , ğ‘ˆ ğ‘  .

Let â„“ be the smallest integer such that ğ‘‡ â„“ contains ğ‘£ â€²â€². Clearly, â„“ â‰¤ ğ‘˜ holds. Now let ğ‘ be the set of labeled nulls introduced by
applying a chase step to ğ‘£ â€²â€² or a descendant thereof, and let ğ‘Š the the set of descendants of ğ‘£ â€²â€² in the sequence ğ‘‡ 0, . . . ,ğ‘‡ ğ‘— . Moreover, let
ğ‘‡ â€²
ğ‘  be the chase sequence obtained by uniformly replacing in ğ‘‡ 0, . . . ,ğ‘‡ ğ‘˜, ğ‘ˆ 0, ğ‘ˆ 1, . . . , ğ‘ˆ ğ‘  each labeled null in ğ‘ with a
0
distinct, fresh labeled null, and by uniformly replacing each vertex ğ‘¤ âˆˆ ğ‘Š by a fresh vertex.

, . . . , ğ‘ˆ â€²

, . . . ,ğ‘‡ â€²

ğ‘˜, ğ‘ˆ â€²
0

, ğ‘ˆ â€²
1

We now transform chase trees ğ‘‡ â„“+1, . . . ,ğ‘‡ ğ‘— into chase tress ğ‘‰ â„“+1, . . . , ğ‘‰ ğ‘— that reflect the result of â€œreplayingâ€ after ğ‘ˆ â€²

ğ‘  the steps producing

the former sequence. Intuitively, each ğ‘‰ ğ‘ is a â€œunionâ€ of ğ‘ˆ ğ‘  and ğ‘‡ ğ‘ . Formally, for each ğ‘ with â„“ < ğ‘ â‰¤ ğ‘—, we define ğ‘‰ ğ‘ as follows.
(S1) The chase tree ğ‘‰ ğ‘ contains the union of the vertices of ğ‘ˆ â€²
(S2) For each vertex ğ‘¤ occurring only in ğ‘ˆ â€²
(S3) For each vertex ğ‘¤ occurring in both ğ‘ˆ â€²
(S4) If ğ‘‡ ğ‘ is obtained by applying to a vertex ğ‘¤ of ğ‘‡ ğ‘ âˆ’1 a chase step with a non-full GTGD ğœ = âˆ€(cid:174)ğ‘¥ [ğ›½ â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚] and substitutions ğœ and ğœ â€²,
then, for ğ‘¤ â€² the child of ğ‘¤ introduced by the step, we extend ğ‘‰ ğ‘ (ğ‘¤ â€²) with each fact ğº âˆˆ ğ‘‰ ğ‘ âˆ’1 (ğ‘¤) that is Î£-guarded by ğœ â€² (ğœ‚).

ğ‘  (resp. ğ‘‡ ğ‘ ), we define ğ‘‰ ğ‘ (ğ‘¤) = ğ‘ˆ â€²
ğ‘  and ğ‘‡ ğ‘ , we define ğ‘‰ ğ‘ (ğ‘¤) = ğ‘ˆ â€²

ğ‘  (ğ‘¤) (resp. ğ‘‰ ğ‘ (ğ‘¤) = ğ‘‡ ğ‘ (ğ‘¤)).

ğ‘  (ğ‘¤) âˆª ğ‘‡ ğ‘ (ğ‘¤).

ğ‘  and ğ‘‡ ğ‘ .

ğ‘ , ğ‘‰ â„“+1, . . . , ğ‘‰ ğ‘— contains an almost one-pass chase sequence for Î£ and ğ¼ that satisfies the

, . . . ,ğ‘‡ â€²

We now argue that ğ‘‡ â€²
0
conditions of this lemma.
â€¢ Sequence ğ‘‡ â€²
, ğ‘ˆ â€²
ğ‘˜, ğ‘ˆ â€²
1
0
0
â€¢ For â„“ â‰¤ ğ‘ < ğ‘—, either ğ‘‰ ğ‘+1 is obtained from ğ‘‰ ğ‘ (or ğ‘ˆ â€²

, . . . , ğ‘ˆ â€²

, . . . , ğ‘ˆ â€²

, . . . ,ğ‘‡ â€²

ğ‘˜, ğ‘ˆ â€²
0

, ğ‘ˆ â€²
1

ğ‘  is clearly a valid almost one-pass chase sequence.

ğ‘  in case ğ‘ = â„“) by the same step that produces ğ‘‡ ğ‘+1 from ğ‘‡ ğ‘ , or the step is not
applicable. In the latter case, we can simply drop such ğ‘‰ ğ‘+1 from the sequence. By dropping all such ğ‘‰ ğ‘+1, we clearly obtain a valid
almost one-pass chase sequence.

â€¢ We have ğ‘‡ğ‘– âŠ† ğ‘‡ ğ‘— by the induction assumption, and steps (S1)â€“(S3) clearly ensure ğ‘‡ğ‘– âŠ† ğ‘‰ ğ‘— . Moreover, ğ‘‡ğ‘–+1 differs from ğ‘‡ğ‘– only in vertex ğ‘£ â€²,
ğ‘  (ğ‘£ â€²â€²), and step (S4) ensures that ğ¹ is propagated in
â–¡

where ğ‘‡ğ‘–+1 (ğ‘£ â€²) = ğ‘‡ (ğ‘£ â€²) âˆª {ğ¹ } holds. Our construction, however, clearly ensures ğ¹ âˆˆ ğ‘ˆ â€²
each chase step with a non-full GTGD introducing a vertex on the unique path from ğ‘£ â€²â€² to ğ‘£ â€². Thus, ğ‘‡ğ‘–+1 âŠ† ğ‘‰ ğ‘— holds.
Lemma A.7. For each base fact ğ¹ and each almost one-pass tree-like chase proof of ğ¹ from ğ¼ and Î£, there exists a one-pass tree-like chase proof

of ğ¹ from ğ¼ and Î£.

Proof. Consider an arbitrary base fact ğ¹ and an arbitrary almost one-pass tree-like chase proof ğ‘‡0, . . . ,ğ‘‡ğ‘› of ğ¹ from ğ¼ and Î£. Since ğ¹ is
a base fact, without loss of generality we can assume that ğ¹ occurs in the facts of the root vertex. Now let ğ‘‡ğ‘– be the first chase tree that
contains ğ¹ in the root, and let ğ‘Š be the set containing each non-root vertex ğ‘£ occurring in any of the chase trees such that no propagation
step is applied to ğ‘£. We transform this proof to a one-pass proof as follows. First, we delete each ğ‘‡ğ‘— with ğ‘– < ğ‘— â‰¤ ğ‘›. Next, we delete in each
remaining ğ‘‡ğ‘— each vertex ğ‘£ âˆˆ ğ‘Š and each descendant of ğ‘£. Finally, we delete each remaining ğ‘‡ğ‘— that is equal to ğ‘‡ğ‘—+1. After this transformation,
every vertex has a propagation step applied to it. It is straightforward to see that the result is a one-pass tree-like chase sequence. Moreover,
â–¡
since ğ¹ occurs in the root, the sequence is a tree-like chase proof of ğ¹ from ğ¼ and Î£.

A.2 Proof of Proposition 4.7: Rewriting Criterion Using One-pass Chase Proofs
Proposition 4.7. A Datalog program Î£â€² is a rewriting of a finite set of GTGDs Î£ in head-normal form if

â€¢ Î£â€² is a logical consequence of Î£,

â€¢ each Datalog rule of Î£ is a logical consequence of Î£â€², and
â€¢ for each base instance ğ¼ , each one-pass tree-like chase sequence ğ‘‡0, . . . ,ğ‘‡ğ‘› for ğ¼ and Î£, and each loop ğ‘‡ğ‘–, . . . ,ğ‘‡ğ‘— at the root vertex ğ‘Ÿ with output

fact ğ¹ , there exist a Datalog rule ğ›½ â†’ ğ» âˆˆ Î£â€² and a substitution ğœ such that ğœ (ğ›½) âŠ† ğ‘‡ğ‘– (ğ‘Ÿ ) and ğœ (ğ» ) = ğ¹ .

Proof. Let Î£ and Î£â€² be as specified in the proposition, let ğ¼ be an arbitrary base instance, and let ğ¹ be an arbitrary base fact. Since Î£â€² is a
logical consequence of Î£, it is clear that ğ¼, Î£â€² |= ğ¹ implies ğ¼, Î£ |= ğ¹ . Thus, we assume that ğ¼, Î£ |= ğ¹ holds, and we prove that ğ¼, Î£â€² |= ğ¹ holds as
well. By Theorem 4.2, there exists a one-pass tree-like chase proof ğ‘‡0, . . . ,ğ‘‡ğ‘› of ğ¹ from ğ¼ and Î£. Without loss of generality, we can assume
that ğ¹ is produced in the last step of the proof, and so the recently updated vertex of ğ‘‡ğ‘› is root vertex ğ‘Ÿ . Let ğ‘–0 < Â· Â· Â· < ğ‘–ğ‘š be exactly the
indexes between 0 and ğ‘› such that the recently updated vertex of ğ‘‡ğ‘– ğ‘— is ğ‘Ÿ . We next construct a tree-like chase sequence ğ‘‡ 0, . . . ,ğ‘‡ ğ‘˜ for ğ¼ and
Î£â€² such that ğ‘‡ğ‘› (ğ‘Ÿ ) âŠ† ğ‘‡ ğ‘˜ (ğ‘Ÿ ). To formalize our inductive construction of this chase sequence, we shall also construct a sequence of indexes
â„“0, . . . , â„“ğ‘š such that â„“ğ‘š = ğ‘˜ and, for each ğ‘— with 0 â‰¤ ğ‘— â‰¤ ğ‘š, we have ğ‘‡ğ‘– ğ‘— (ğ‘Ÿ ) âŠ† ğ‘‡ â„“ğ‘— (ğ‘Ÿ ); in other words, each index â„“ğ‘— helps us establish the
inductive property by relating ğ‘‡ğ‘– ğ‘— and ğ‘‡ â„“ğ‘— . For the base case, ğ‘–0 = 0 holds by the definition of a tree-like chase proof; thus, we set ğ‘‡ 0 = ğ‘‡0 and
â„“0 = 0, and the required property clearly holds. For the inductive step, we consider arbitrary 0 < ğ‘— â‰¤ ğ‘š such that the claim holds for ğ‘— âˆ’ 1,
and assume that the sequence constructed thus far is ğ‘‡ â„“0
â€¢ The recently updated vertex of ğ‘‡ğ‘– ğ‘— âˆ’1 is ğ‘Ÿ . Thus, ğ‘– ğ‘— âˆ’ 1 = ğ‘– ğ‘— âˆ’1, and ğ‘‡ğ‘– ğ‘— is obtained from ğ‘‡ğ‘– ğ‘— âˆ’1 by a chase step with a full GTGD ğ›½ â†’ ğ» âˆˆ Î£
producing a fact ğº âˆˆ ğ‘‡ğ‘– ğ‘— (ğ‘Ÿ ). The second condition of the proposition ensures that ğ›½ â†’ ğ» is a logical consequence of Î£â€², so ğº can be
derived from ğ‘‡ â„“1 (ğ‘Ÿ ) and the Datalog rules of Î£â€² using â„˜ steps. We then define â„“ğ‘— = â„“ğ‘— âˆ’1 + â„˜, and we append the corresponding steps to
obtain the sequence ğ‘‡ 0, . . . ,ğ‘‡ â„“ğ‘— âˆ’1

, . . . ,ğ‘‡ â„“ğ‘— âˆ’1 . We have the following two cases.

, . . . ,ğ‘‡ â„“ğ‘— .

â€¢ Otherwise, ğ‘‡ğ‘– ğ‘— âˆ’1

, . . . ,ğ‘‡ğ‘– ğ‘— is a loop at the root vertex ğ‘Ÿ with some output fact ğº âˆˆ ğ‘‡ğ‘– ğ‘— (ğ‘Ÿ ). The third condition of the proposition ensures
that there exists a Datalog rule ğ›½ â†’ ğ» âˆˆ Î£â€² and a substitution ğœ such that ğœ (ğ›½) âŠ† ğ‘‡ğ‘– (ğ‘Ÿ ) and ğœ (ğ» ) = ğº. We define â„“ğ‘— = â„“ğ‘— âˆ’1 + 1, and we
define ğ‘‡ â„“ğ‘— as the the chase tree containing just the root vertex ğ‘Ÿ such that ğ‘‡ â„“ğ‘— (ğ‘Ÿ ) = ğ‘‡ â„“ğ‘— âˆ’1 (ğ‘Ÿ ) âˆª {ğº }; thus, ğ‘‡ â„“ğ‘— is obtained from ğ‘‡ â„“ğ‘— âˆ’1 by
applying the Datalog rule ğ›½ â†’ ğ» âˆˆ Î£â€² to the root vertex ğ‘Ÿ . Moreover, ğ‘‡ğ‘– ğ‘— (ğ‘Ÿ ) âŠ† ğ‘‡ â„“ğ‘— (ğ‘Ÿ ) clearly holds, as required.
â–¡

A.3 Proof of Proposition A.8: Properties of One-Pass Chase Proofs
We finally prove a property that will be needed in the proofs in Appendices Bâ€“E. This property intuitively ensures that, as soon as a fact ğ¹ is
derived in the child vertex of a loop such that ğ¹ does not contain any null values introduced by the child, the loop is completed and ğ¹ is
propagated to the parent vertex.

Proposition A.8. For each loop ğ‘‡ğ‘–, . . . ,ğ‘‡ğ‘— at a vertex ğ‘£ in a one-pass tree-like chase proof for some ğ¼ and Î£, for ğ‘– < ğ‘˜ â‰¤ ğ‘—, and for ğ‘£ â€² the vertex

introduced in ğ‘‡ğ‘–+1, set terms(cid:0)ğ‘‡ğ‘˜ (ğ‘£ â€²)(cid:1) \ nulls(cid:0)ğ‘‡ğ‘–+1 (ğ‘£ â€²)(cid:1) is Î£-guarded by ğ‘‡ğ‘– (ğ‘£).

Proof. Consider an arbitrary loop ğ‘‡ğ‘–, . . . ,ğ‘‡ğ‘— at a vertex ğ‘£ in a one-pass tree-like chase proof for some ğ¼ and Î£, and let ğ‘£ â€² be the child of
ğ‘£ introduced by the chase step producing ğ‘‡ğ‘–+1. We prove the claim by induction on ğ‘˜ with ğ‘– < ğ‘˜ â‰¤ ğ‘—. For the induction base ğ‘˜ = ğ‘– + 1, the
definition of a chase step with a non-full GTGD clearly ensures this claim for ğ‘‡ğ‘–+1 (ğ‘£ â€²). For the induction step, consider an arbitrary ğ‘˜ such
that the claim holds. Our claim holds trivially if ğ‘‡ğ‘˜+1 (ğ‘£ â€²) = ğ‘‡ğ‘˜ (ğ‘£ â€²), so we assume that ğ‘‡ğ‘˜+1 (ğ‘£ â€²) \ ğ‘‡ğ‘˜ (ğ‘£ â€²) contains exactly one fact ğ¹ , which
can be derived in one of the following two ways.
â€¢ Assume ğ¹ is obtained by a propagation step to vertex ğ‘£ â€². Then, ğ¹ is Î£-guarded by ğ‘‡ğ‘˜ (ğ‘£ â€²), so terms(ğ¹ ) âŠ† terms(cid:0)ğ‘‡ğ‘˜ (ğ‘£ â€²)(cid:1) âˆª consts(Î£) holds.
â€¢ Assume ğ¹ is obtained by applying a full GTGD ğœ âˆˆ Î£ to ğ‘‡ğ‘˜ (ğ‘£ â€²) using a substitution ğœ. Then, ğœ contains a guard atom ğ´ in the body such

that ğœ (ğ´) âŠ† ğ‘‡ğ‘˜ (ğ‘£ â€²); moreover, the head ğœ contains all variables of ğ´, and so we have terms(ğ¹ ) âŠ† terms(cid:0)ğ‘‡ğ‘˜ (ğ‘£ â€²)(cid:1) âˆª consts(Î£).

Either way, we have terms(cid:0)ğ‘‡ğ‘˜+1 (ğ‘£ â€²)(cid:1) âŠ† terms(cid:0)ğ‘‡ğ‘˜ (ğ‘£ â€²)(cid:1) âˆª consts(Î£). By the induction assumption, set terms(cid:0)ğ‘‡ğ‘˜ (ğ‘£ â€²)(cid:1) \ nulls(ğ‘‡ğ‘–+1 (ğ‘£ â€²)) is
Î£-guarded by ğ‘‡ğ‘– (ğ‘£), and so set terms(cid:0)ğ‘‡ğ‘˜1
â–¡

(ğ‘£ â€²)(cid:1) \ nulls(ğ‘‡ğ‘–+1 (ğ‘£ â€²)) is also Î£-guarded by ğ‘‡ğ‘– (ğ‘£), as required.

B PROOFS FOR ExbDR
B.1 Proof of Proposition 5.7: Properties of ExbDR

Proposition 5.7. Each application of the ExbDR inference rule to ğœ, ğœ â€², and ğœƒ as in Definition 5.5 satisfies the following properties.

1. Some atom ğ´â€²
2. For each 1 â‰¤ ğ‘– â‰¤ ğ‘› such that ğ´â€²

ğ‘– with 1 â‰¤ ğ‘– â‰¤ ğ‘› is a guard in ğœ â€².

case that vars(cid:0)ğœ (ğ´â€²

ğ‘— )(cid:1) âˆ© (cid:174)ğ‘¦ â‰  âˆ… for each 1 â‰¤ ğ‘— â‰¤ ğ‘›.

ğ‘– is a guard of ğœ â€², and for ğœ the (cid:174)ğ‘¦-MGU of ğ´â€²

ğ‘– and the corresponding atom ğ´ğ‘– such that ğœ ( (cid:174)ğ‘¥) âˆ© (cid:174)ğ‘¦ = âˆ…, it is the

3. The result is a GTGD whose body and head width are at most bwidth(Î£) and hwidth(Î£), respectively.

Proof of Claim 1. Let ğº be a guard for ğœ â€². For the sake of a contradiction, assume that ğº is not one of the atoms ğ´â€²
1

ğº âˆˆ ğ›½â€². Since ğ‘› â‰¥ 1, atom ğ´â€²
variable ğ‘¦ âˆˆ (cid:174)ğ‘¦. Moreover, the conditions of the ExbDR inference rule ensure ğœƒ (ğ‘¦) = ğ‘¦. Since ğ‘¦ does not occur in ğ´â€²

ğ‘›â€”that is,
1 in the body of ğœ â€² is matched to ğ´1 in the head of ğœ. Since ğœ is in head-normal form, ğ´1 contains at least one
1 and

1 and ğœƒ unifies ğ´â€²

, . . . , ğ´â€²

ğ´1, atom ğ´â€²
vars(ğœƒ (ğº)) âˆ© (cid:174)ğ‘¦ â‰  âˆ…, which contradicts the requirement vars(ğœƒ (ğ›½â€²)) âˆ© (cid:174)ğ‘¦ = âˆ… of the ExbDR inference rule.

1 contains at some position a variable ğ‘§ such that ğœƒ (ğ‘§) = ğ‘¦. Since ğº is a guard for ğœ â€², variable ğ‘§ occurs in ğº. Therefore, we have
â–¡

Proof of Claim 2. Consider arbitrary ğ‘– such that 1 â‰¤ ğ‘– â‰¤ ğ‘› and ğ´â€²

ğ‘– and the corresponding
atom ğ´ğ‘– of ğœ. Since ğœƒ is a unifier of ğ´â€²
ğ‘– and ğ´ğ‘– as well as of other pairs of atoms, there clearly exists a substitution ğœŒ such that ğœƒ = ğœŒ â—¦ ğœ.
Now consider an arbitrary ğ´â€²
ğ‘— to the corresponding atom ğ´ğ‘— in the head of ğœ. Since TGD ğœ
is in head-normal form, atom ğ´ğ‘— contains at least one variable ğ‘¦ âˆˆ (cid:174)ğ‘¦. Since ğœƒ (ğ‘¦) = ğ‘¦, we necessarily have ğ‘¦ âˆˆ vars(ğœƒ (ğ´â€²
ğ‘— )). Consequently,
atom ğ´â€²
ğ‘– . Now assume for the sake of a
contradiction that ğœ (ğ‘§) â‰  ğ‘¦. Then ğœ (ğ‘§) = ğœ (ğ‘¥) for some ğ‘¥ âˆˆ vars(ğ´ğ‘– ) and ğ‘¦ = ğœƒ (ğ‘§) = ğœŒ (ğœ (ğ‘§)) = ğœŒ (ğœ (ğ‘¥)) = ğœƒ (ğ‘¥). However, this contradicts
â–¡
the requirement ğœƒ ( (cid:174)ğ‘¥) âˆ© (cid:174)ğ‘¦ = âˆ… of the ExbDR inference rule.

ğ‘— contains some variable ğ‘§ such that ğœƒ (ğ‘§) = ğ‘¦. Since ğ´â€²

ğ‘— with 1 â‰¤ ğ‘— â‰¤ ğ‘› in ğœ â€². Substitution ğœƒ matches ğ´â€²

ğ‘– is a guard for ğœ â€², variable ğ‘§ occurs in ğ´â€²

ğ‘– is a guard of ğœ â€², and let ğœ be an MGU of ğ´â€²

Proof of Claim 3. By Claim 1, there exists ğ‘– with 1 â‰¤ ğ‘– â‰¤ ğ‘› such that atom ğ´â€²

ğ‘– is a guard for ğœ â€². Thus, vars(ğ›½â€²) âˆª vars(ğ» â€²) âŠ† vars(ğ´â€²
ğ‘– ).
The ExbDR inference rule ensures vars(ğœƒ (ğ›½â€²)) âˆ© (cid:174)ğ‘¦ = âˆ…, which in turn ensures vars(ğœƒ (ğ›½â€²)) âŠ† vars(ğœƒ (ğ´â€²
ğ‘– )) \ (cid:174)ğ‘¦. Now let ğº be a guard for ğœ.
We clearly have vars(ğœƒ (ğ›½)) âŠ† vars(ğœƒ (ğº)). Moreover, ğœƒ (ğ‘¦ğ‘– ) = ğ‘¦ğ‘– and ğœƒ (ğ‘¥) âˆ© (cid:174)ğ‘¦ = âˆ… ensure vars(ğœƒ (ğœ‚)) âˆª vars(ğœƒ (ğ´ğ‘– )) âŠ† vars(ğœƒ (ğº)) âˆª (cid:174)ğ‘¦. Thus,
ğœƒ (ğº) is a guard for the TGD produced by the ExbDR inference rule. Finally, since ğº contains all variables of ğœ, the widths of the resulting
â–¡
TGD and ğœ are equal.

B.2 Proof of Theorem 5.8: Correctness and Complexity of ExbDR

Theorem 5.8. Program ExbDR(Î£) is a Datalog rewriting of a finite set of GTGDs Î£. Moreover, the rewriting can be computed in time
) for ğ‘Ÿ the number of relations in Î£, ğ‘ the maximum relation arity in Î£, ğ‘¤ğ‘ = bwidth(Î£), ğ‘¤â„ = hwidth(Î£),

ğ‘‚ (ğ‘ğ‘Ÿ ğ‘‘ Â· (ğ‘¤ğ‘ +ğ‘ )ğ‘‘ğ‘ Â·ğ‘Ÿ ğ‘‘ Â· (ğ‘¤â„+ğ‘ )ğ‘‘ğ‘
ğ‘ = |consts(Î£)|, and some ğ‘ and ğ‘‘.

Proof of Correctness. Let Î£â€² be the set Î£ closed under the ExbDR inferences rule as specified in Definition 5.3. It is straightforward to
see that Î£â€² is a logical consequence of Î£, so ExbDR(Î£) is also a logical consequence of Î£. Moreover, ExbDR(Î£) contains each full GTGD of Î£
up to redundancy, so each full GTGD of Î£ is logically entailed by ExbDR(Î£). We next consider an arbitrary base instance ğ¼ and a one-pass
tree-like chase sequence for ğ¼ and Î£, and we show the following property:

(â™¦) for each loop ğ‘‡ğ‘–, . . . ,ğ‘‡ğ‘— in the sequence at some vertex ğ‘£ with output fact ğ¹ , there exist a full GTGD ğ›½ â†’ ğ» âˆˆ Î£â€² and a
substitution ğœ such that ğœ (ğ›½) âŠ† ğ‘‡ğ‘– (ğ‘£) and ğ¹ = ğœ (ğ» ).

Since ExbDR(Î£) contains all full TGDs of Î£â€² and this property holds for the root vertex ğ‘Ÿ , Proposition 4.7 ensures that ExbDR(Î£) is a
rewriting of Î£.

Our proof is by induction on the length of the loop. The base case and the inductive step have the same structure, so we consider them
jointly. Thus, consider an arbitrary loop ğ‘‡ğ‘–,ğ‘‡ğ‘–+1, . . . ,ğ‘‡ğ‘— âˆ’1,ğ‘‡ğ‘— at vertex ğ‘£ in the sequence, and assume that the claim holds for all shorter
loops in the sequence. By the definition of the loop, chase tree ğ‘‡ğ‘–+1 is obtained from ğ‘‡ğ‘– by applying a chase step to some non-full TGD
0)) \ nulls(rng(ğœ0)), let ğ‘£ â€² be the child
âˆ€(cid:174)ğ‘¥ [ğ›½0 â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚0] âˆˆ Î£. Let ğœ0 and ğœ â€²
0 be the substitutions used in this chase step, let ğ‘ = nulls(rng(ğœ â€²
of ğ‘£ introduced in ğ‘‡ğ‘–+1, and let ğ‘† âŠ† ğ‘‡ğ‘– (ğ‘£) be the facts that are copied to ğ‘‡ğ‘–+1 (ğ‘£ â€²) because they are Î£-guarded by ğœ â€²
0 (ğœ‚0). Thus, we have
ğ‘‡ğ‘–+1 (ğ‘£ â€²) = ğ‘† âˆª ğœ â€²
0 (ğœ‚0). By Proposition A.8 and the fact that a chase step is applied only if propagation to the parent is not applicable, the
output fact of the loop is added to ğ‘‡ğ‘— âˆ’1 (ğ‘£ â€²) in step ğ‘— âˆ’ 1, and in ğ‘‡ğ‘— this fact is propagated back to ğ‘‡ğ‘— (ğ‘£). In other words, for each ğ‘˜ with
ğ‘– < ğ‘˜ < ğ‘— âˆ’ 1, each fact in ğ‘‡ğ‘˜ (ğ‘£ â€²) \ ğ‘† contains at least one labeled null from ğ‘ , or the fact would be Î£-guarded by ğ‘‡ğ‘– (ğ‘£) and thus propagated
back to vertex ğ‘£. We show that, in the loop ğ‘‡ğ‘–,ğ‘‡ğ‘–+1, . . . ,ğ‘‡ğ‘— âˆ’1,ğ‘‡ğ‘— fixed above, the following property holds for each ğ‘˜ with ğ‘– < ğ‘˜ < ğ‘— âˆ’ 1:

(â™¢) there exist a GTGD âˆ€(cid:174)ğ‘¥ [ğ›½ â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚] âˆˆ Î£â€², a substitution ğœ such that ğœ (ğ›½) âŠ† ğ‘‡ğ‘– (ğ‘£), and a substitution ğœ â€² that extends ğœ by
mapping (cid:174)ğ‘¦ to fresh labeled nulls such that ğ‘‡ğ‘˜ (ğ‘£ â€²) âŠ† ğ‘† âˆª ğœ â€² (ğœ‚).

We prove (â™¢) by induction on ğ‘˜. We have already proved the base case ğ‘˜ = ğ‘– + 1 above. For the inductive step, assume that (â™¢) holds for
some ğ‘˜, so there exists a GTGD âˆ€(cid:174)ğ‘¥ [ğ›½ â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚] âˆˆ Î£â€² and substitutions ğœ and ğœ â€² satisfying (â™¢) for ğ‘˜. Now consider ğ‘‡ğ‘˜+1. Property (â™¢) holds by
the inductive hypothesis if ğ‘‡ğ‘˜+1 (ğ‘£ â€²) = ğ‘‡ğ‘˜ (ğ‘£ â€²)â€”that is, if the step involves a descendant of ğ‘£ â€². Otherwise, ğ‘‡ğ‘˜+1 (ğ‘£ â€²) = ğ‘‡ğ‘˜ (ğ‘£ â€²) âˆª {ğº } where fact
ğº is obtained in one of the following two ways.
â€¢ A full GTGD in Î£ derives ğº from ğ‘‡ğ‘˜ (ğ‘£ â€²). Set Î£â€² contains this GTGD up to redundancy, so by Definition 5.1 there exist a full GTGD

ğ›½â€²â€² â†’ ğ» â€² âˆˆ Î£â€² and a substitution ğœŒ such that ğœŒ (ğ›½â€²â€²) âŠ† ğ‘‡ğ‘˜ (ğ‘£ â€²) and ğœŒ (ğ» â€²) = ğº.

â€¢ Fact ğº is the output of a loop at vertex ğ‘£ â€². But then, this loop is shorter than ğ‘‡ğ‘–, . . . ,ğ‘‡ğ‘— so, by property (â™¦), there exists a full GTGD

ğ›½â€²â€² â†’ ğ» â€² âˆˆ Î£â€² and a substitution ğœŒ such that ğœŒ (ğ›½â€²â€²) âŠ† ğ‘‡ğ‘˜ (ğ‘£ â€²) and ğœŒ (ğ» â€²) = ğº.

1 âˆ§ Â· Â· Â· âˆ§ ğ´â€²

Since ğœ‚ is in head-normal form, each atom in ğœ â€² (ğœ‚) contains at least one labeled null of ğ‘ . Now let ğ´â€²
ğ‘› be the atoms of ğ›½â€²â€² that
1
are matched to the atoms in ğœ â€² (ğœ‚). Atom ğœŒ (ğ» â€²) contains at least one labeled null of ğ‘ , so ğ‘› â‰¥ 1. Thus, we can assume that ğ›½â€²â€² â†’ ğ» â€² is of
ğ‘›)} âŠ† ğœ â€² (ğœ‚) and ğœŒ (ğ›½â€²) âŠ† ğ‘†. Also, since ğ›½â€²â€² â†’ ğ» â€² is guarded, at least one of ğ´â€²
the form ğ´â€²
ğ‘–
is a guard for ğ›½â€²â€² â†’ ğ» â€². Let ğ´1, . . . , ğ´ğ‘› be the atoms of ğœ‚ such that ğœ â€² (ğ´ğ‘– ) = ğœŒ (ğ´â€²
ğ‘– ) for 1 â‰¤ ğ‘– â‰¤ ğ‘›. Since ğœ â€² maps each ğ‘¦ âˆˆ (cid:174)ğ‘¦ to a distinct
labeled null that does not occur in ğ‘‡ğ‘– , we have ğœ â€² ( (cid:174)ğ‘¥) âˆ© ğœ â€² ( (cid:174)ğ‘¦) = âˆ…. Thus, there exists a (cid:174)ğ‘¦-MGU ğœƒ of ğ´1, . . . , ğ´ğ‘› and ğ´â€²
ğ‘› satisfying
1
ğœƒ ( (cid:174)ğ‘¥) âˆ© (cid:174)ğ‘¦ = âˆ…. Conjunction ğœŒ (ğ›½â€²) does not contain a labeled null of ğ‘ , so vars(ğœƒ (ğ›½â€²)) âˆ© (cid:174)ğ‘¦ = âˆ… holds. Thus, the preconditions of the ExbDR
ğ‘› âˆ§ ğ›½â€² â†’ ğ» â€², so the ExbDR rule derives ğœ = ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½â€²) â†’ âˆƒ(cid:174)ğ‘¦ ğœƒ (ğœ‚) âˆ§ ğœƒ (ğ» â€²).
inference rule are satisfied for âˆ€(cid:174)ğ‘¥ [ğ›½ â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚] and ğ´â€²

ğ‘› âˆ§ ğ›½â€² â†’ ğ» â€² where {ğœŒ (ğ´â€²

1), . . . , ğœŒ (ğ´â€²

, . . . , ğ´â€²

, . . . , ğ´â€²

1 âˆ§ Â· Â· Â· âˆ§ ğ´â€²

1 âˆ§ Â· Â· Â· âˆ§ ğ´â€²

ğ‘– is a guard so all variables of ğ´â€²

Moreover, some ğ´â€²
ğ‘› âˆ§ ğ›½â€² â†’ ğ» â€² participate in unification, and thus we can extend ğœ and ğœ â€² to
substitutions ğœ and ğœ â€², respectively, covering these variables such that ğœ (ğœƒ (ğ›½)) âˆª ğœ (ğœƒ (ğ›½â€²)) âŠ† ğ‘‡ğ‘– (ğ‘£) and ğ‘‡ğ‘˜+1 (ğ‘£ â€²) âŠ† ğ‘† âˆª ğœ â€² (ğœƒ (ğœ‚)) âˆª ğœ â€² (ğœƒ (ğ» â€²)).
Set Î£â€² contains ğœ up to redundancy. Since ğº âˆ‰ ğ‘‡ğ‘˜ (ğ‘£ â€²), GTGD ğœ is not a syntactic tautology, so there exists a GTGD âˆ€(cid:174)ğ‘¥1 [ğ›½1 â†’ âˆƒ(cid:174)ğ‘¦1 ğœ‚1] âˆˆ Î£â€² and
substitution ğœ‡ such that dom(ğœ‡) = (cid:174)ğ‘¥1 âˆª (cid:174)ğ‘¦1, ğœ‡ ( (cid:174)ğ‘¥1) âŠ† (cid:174)ğ‘¥2, ğœ‡ ( (cid:174)ğ‘¦1) âŠ† (cid:174)ğ‘¦1 âˆª (cid:174)ğ‘¦2 and ğœ‡ (ğ‘¦) â‰  ğœ‡ (ğ‘¦â€²) for distinct ğ‘¦ and ğ‘¦â€² in (cid:174)ğ‘¦1, and ğœ‡ (ğ›½1) âŠ† ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½â€²)
and ğœ‡ (ğœ‚1) âŠ‡ ğœƒ (ğœ‚) âˆ§ ğœƒ (ğ» â€²). Now let ğœ1 be the substitution defined as ğœ1 (ğ‘¥) = ğœ (ğœ‡ (ğ‘¥)) on each ğ‘¥ âˆˆ (cid:174)ğ‘¥, and let ğœ â€²
1 be the extension of ğœ1 to (cid:174)ğ‘¦1
such that ğœ â€²

1 (ğ‘¦) = ğœ â€² (ğœ‡ (ğ‘¦)) for each ğ‘¦ âˆˆ (cid:174)ğ‘¦. Clearly, ğœ1 (ğ›½1) âŠ† ğ‘‡ğ‘˜ (ğ‘£ â€²) and ğ‘‡ğ‘˜+1 (ğ‘£ â€²) âŠ† ğ‘† âˆª ğœ â€²

1 (ğœ‚1) hold, so property (â™¢) is satisfied.

To complete the proof, consider now the derivation of ğ‘‡ğ‘— âˆ’1. By property (â™¢), there exists a GTGD âˆ€(cid:174)ğ‘¥ [ğ›½ â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚] âˆˆ Î£â€² and substitutions ğœ
ğ‘› âˆ§ ğ›½â€² â†’ ğ» â€² that
and ğœ â€² such that ğœ (ğ›½) âŠ† ğ‘‡ğ‘– (ğ‘£) and ğ‘‡ğ‘— âˆ’2 (ğ‘£ â€²) = ğ‘† âˆª ğœ â€² (ğœ‚). Then, as above, Î£â€² contains a full TGD of the form ğ´â€²
ğ‘›) âŠ† ğœ â€² (ğœ‚) and ğœŒ (ğ›½â€²) âŠ† ğ‘† for some substitution ğœŒ. A minor difference is that ğœŒ (ğ» â€²) does not contain a labeled
satisfies ğœŒ (ğ´â€²
null introduced by ğœ â€² (ğœ‚0), so ğ‘› = 0 is possible; however, in such a case, this TGD immediately satisfies property (â™¦). Moreover, if ğ‘› > 0, then
ğ›½ â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚ can again be resolved with ğ´â€²

ğ‘› âˆ§ ğ›½â€² â†’ ğ» â€² to produce
ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½â€²) â†’ âˆƒ(cid:174)ğ‘¦ ğœƒ (ğœ‚) âˆ§ ğœƒ (ğ» â€²) âˆˆ Î£â€²
satisfying vars(ğœƒ (ğ» â€²)) âˆ© (cid:174)ğ‘¦ = âˆ…. This TGD is transformed into head-normal form by Definition 5.3, so âˆ€(cid:174)ğ‘¥ [ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½â€²) â†’ ğœƒ (ğ» â€²)] is contained
in Î£â€² up to redundancy. But then, Î£â€² contains a full GTGD that satisfies property (â™¦) by the same argument as above.
â–¡

1) âˆª Â· Â· Â· âˆª ğœŒ (ğ´â€²

1 âˆ§ Â· Â· Â· âˆ§ ğ´â€²

1 âˆ§ Â· Â· Â· âˆ§ ğ´â€²

Proof of Complexity. Fix Î£, ğ‘Ÿ , ğ‘¤ğ‘ , ğ‘¤â„, ğ‘, and ğ‘ as stated in the theorem. The number of different body atoms of arity ğ‘ constructed using
ğ‘Ÿ relations, ğ‘¤ğ‘ variables, and ğ‘ constants is clearly bounded by â„“ğ‘ = ğ‘Ÿ Â· (ğ‘¤ğ‘ + ğ‘)ğ‘. Moreover, by the third claim of Proposition 5.7, the number
of variables in the head of each TGD is bounded by ğ‘¤â„, so the number of head atoms is bounded by â„“â„ = ğ‘Ÿ Â· (ğ‘¤â„ + ğ‘)ğ‘. The body (resp. head)
of each GTGD corresponds to a subset of these atoms, so number of different GTGDs up to variable renaming is bounded by â„˜ = 2â„“ğ‘ Â· 2â„“â„ .
Thus, the ExbDR inference rule needs to be applied to at most â„˜2 = 22(â„“ğ‘ +â„“â„ ) pairs of GTGDs. For each such pair, one might need to consider
each possible way to match the â„“ğ‘ body atoms of ğœ â€² to â„“â„ head atoms of ğœ, and there are at most (â„“â„)â„“ğ‘ â‰¤ 2â„“ğ‘ Â·â„“â„ of these. Consequently, unifier
ğœƒ may need to be computed at most 22(â„“ğ‘ +â„“â„ ) Â· 2â„“ğ‘ Â·â„“â„ â‰¤ 25Â·â„“ğ‘ Â·â„“â„ = 32â„“ğ‘ Â·â„“â„ times. To check whether TGD ğœ1 = âˆ€(cid:174)ğ‘¥1 [ğ›½1 â†’ (cid:174)ğ‘¦1 ğœ‚1] is subsumed
by ğœ2 = âˆ€(cid:174)ğ‘¥2 [ğ›½2 â†’ (cid:174)ğ‘¦2 ğœ‚2], we can proceed as follows. First, we consider all possible ways to match an atom of ğ›½1 to an atom of ğ›½2; since both
such matchings. Second, we analogously consider each of at most 2(â„“â„ ) 2
conjunctions contain at most â„“ğ‘ atoms, there are at most â„“ğ‘
ways to match an atom of ğœ‚2 to an atom of ğœ‚1. Once all atoms have been matched, we try to find a substitution ğœ‡ satisfying Definition 5.1 in
linear time. Thus, a subsumption check for pairs of TGDs takes at most 2â„“ğ‘ 2 Â· 2â„“â„ 2
steps. Finally, unification of atoms requires time that is
â–¡
linear in ğ‘, and all other steps require linear time too.

â„“ğ‘ â‰¤ 2â„“ğ‘ 2

C PROOFS FOR SkDR
C.1 Proof of Proposition 5.12: Properties of SkDR
We reuse results by de Nivelle [19] about unification of atoms in guarded rules. The variable depth [19, Definition 3] of an atom is defined as
âˆ’1 if the atom is ground, or as the maximum number of nested function symbols that contain a variable of the atom. Moreover, an atom is
weakly covering [19, Definition 6] if each nonground functional subterm of the atom contains all variables of the atom. Finally, de Nivelle [19,
Theorem 1] says that, for ğœƒ an MGU of weakly covering atoms ğ´ and ğµ, atom ğ¶ = ğœƒ (ğ´) = ğœƒ (ğµ) is also weakly covering, the variable depth of
ğ¶ is bounded by the variable depth of ğ´ and ğµ, and the number of variables of ğ¶ is bounded by the number of variables of ğ´ and ğµ too.

Proposition 5.12. Each application of the SkDR inference rule to rules ğœ and ğœ â€² as in Definition 5.10 produces a guarded rule.
Proof. Consider arbitrary rules ğœ = ğ›½ â†’ ğ» and ğœ â€² = ğ´â€² âˆ§ ğ›½â€² â†’ ğ» â€² and an MGU ğœƒ of ğ» and ğ´â€² satisfying the preconditions of the SkDR
inference rule. Atom ğ» thus contains a Skolem symbol, and rule ğœ is guarded; consequently, atom ğ» is weakly covering, it contains a term of
the form ğ‘“ ((cid:174)ğ‘¡) where (cid:174)ğ‘¡ consists of constants and all variables of the rule, and the variable depth of ğ» is at most one. The corresponding atom
ğ´â€² can be of the following two forms.
â€¢ Atom ğ´â€² is Skolem-free. But then, ğ´â€² contains all variables of ğœ â€², and it is clearly weakly covering. By de Nivelle [19, Theorem 1], atom
ğœƒ (ğ´â€²) is weakly covering and has variable depth at most one; consequently, each atom in rule ğœƒ (ğ´â€²) âˆ§ ğœƒ (ğ›½â€²) â†’ ğœƒ (ğ» â€²) is weakly covering
and has variable depth at most one. Moreover, the variable depth of ğœƒ (ğ» ) is also at most one, which can be only if ğœƒ maps each variable
in ğ» to another variable or a constant. Thus, each atom in rule ğœƒ (ğ›½) â†’ ğœƒ (ğ» ) is weakly covering and has variable depth at most one;
moreover, ğœƒ (ğ›½) contains an atom that contains all variables of the rule. But then, rule ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½â€²) â†’ ğœƒ (ğ» â€²) is guarded, as required.
â€¢ Atom ğ´â€² contains a Skolem symbol. But then, ğ´â€² is weakly covering by the definition of guarded rules, and its variable depth is at most
one. By de Nivelle [19, Theorem 1], atom ğœƒ (ğ» ) = ğœƒ (ğ´â€²) is weakly covering and has variable depth at most one, which can be the case only
if ğœƒ maps all variables to other variables or constants. Consequently, rules ğœƒ (ğ›½) â†’ ğœƒ (ğ» ) and ğœƒ (ğ´â€²) âˆ§ ğœƒ (ğ›½â€²) â†’ ğœƒ (ğ» â€²) are both guarded.
But then, rule ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½â€²) â†’ ğœƒ (ğ» â€²) is guarded, as required.
â–¡

C.2 Proof of Theorem 5.13: Correctness and Complexity of SkDR

Theorem 5.13. Program SkDR(Î£) is a Datalog rewriting of a finite set of GTGDs Î£. Moreover, the rewriting can be computed in time
) for ğ‘Ÿ the number of relations in Î£, ğ‘ the maximum relation arity in Î£, ğ‘’ the number of existential quantifiers in Î£,

ğ‘‚ (ğ‘ğ‘Ÿ ğ‘‘ Â· (ğ‘’+ğ‘¤ğ‘ +ğ‘ )ğ‘‘ğ‘
ğ‘¤ğ‘ = bwidth(Î£), ğ‘ = |consts(Î£)|, and some ğ‘ and ğ‘‘.

Proof of Correctness. Let Î£ be an arbitrary finite set of GTGDs, and let Î£â€² be the set of rules obtained from Î£ as specified in
Definition 5.3. It is straightforward to see that Î£â€² is a logical consequence of the Skolemization of Î£, so SkDR(Î£) is also a logical consequence
of Î£. Moreover, SkDR(Î£) contains each full TGD of Î£ up to redundancy, so each full TGD of Î£ is logically entailed by SkDR(Î£). We next
consider an arbitrary base instance ğ¼ and a one-pass tree-like chase sequence for ğ¼ and Î£, and we show the following property:

(â™¦) for each loop ğ‘‡ğ‘–, . . . ,ğ‘‡ğ‘— in the sequence at some vertex ğ‘£ with output fact ğ¹ , there exist a Skolem-free rule ğ›½ â†’ ğ» âˆˆ Î£â€²
and a substitution ğœ such that ğœ (ğ›½) âŠ† ğ‘‡ğ‘– (ğ‘£) and ğ¹ = ğœ (ğ» ).

Since SkDR(Î£) contains all Skolem-free rules of Î£â€² and this property holds for the root vertex ğ‘Ÿ , Proposition 4.7 ensures that SkDR(Î£) is a
rewriting of Î£.

Our proof is by induction in the length of the loop. The base case and the inductive step have the same structure, so we consider them
jointly. Thus, consider an arbitrary loop ğ‘‡ğ‘–,ğ‘‡ğ‘–+1, . . . ,ğ‘‡ğ‘— âˆ’1,ğ‘‡ğ‘— at vertex ğ‘£ in the sequence, and assume that the claim holds for all shorter loops
in the sequence. By the definition of a loop, chase tree ğ‘‡ğ‘–+1 is obtained from ğ‘‡ğ‘– by applying a chase step to some non-full GTGD ğœ âˆˆ Î£ and
substitution ğ›¾. Let ğ‘£ â€² be the child of ğ‘£ introduced in ğ‘‡ğ‘–+1, let ğ‘† âŠ† ğ‘‡ğ‘– (ğ‘£) be the facts that are copied to ğ‘‡ğ‘–+1 (ğ‘£ â€²) because they are Î£-guarded
by the instantiated head of ğœ, let ğ‘ = {ğ‘›1, . . . , ğ‘›ğ‘š } be the set of labeled nulls introduced in the chase step for the existentially quantified
variables ğ‘¦1, . . . , ğ‘¦ğ‘š of ğœ, let ğœˆ be a function that maps each labeled null ğ‘›ğ‘– to the ground term ğ‘“ğ‘– (ğ›¾ ( (cid:174)ğ‘¥)) where ğ‘“ğ‘– is the symbol used in the
Skolemization of ğ‘¦ğ‘– . For ğ‘ˆ a set of facts, let ğœˆ (ğ‘ˆ ) be the result of replacing each occurrence of a labeled null ğ‘› âˆˆ dom(ğœˆ) in ğ‘ˆ with ğœˆ (ğ‘›) and
eliminating any duplicate facts in the result. Clearly, the inverse function ğœˆ âˆ’ is well-defined, and we define ğœˆ âˆ’ (ğ‘ˆ ) for ğ‘ˆ a set of facts in the
obvious way. By Proposition A.8 and the fact that propagation is applied eagerly, the output fact of the loop is added to ğ‘‡ğ‘— âˆ’1 (ğ‘£ â€²) in step
ğ‘— âˆ’ 1, and in ğ‘‡ğ‘— this fact is propagated back to ğ‘‡ğ‘— (ğ‘£). In other words, for each ğ‘˜ with ğ‘– < ğ‘˜ < ğ‘— âˆ’ 1, each fact in ğ‘‡ğ‘˜ (ğ‘£ â€²) \ ğ‘† contains at least
one labeled null from ğ‘ , or the fact would be Î£-guarded by ğ‘‡ğ‘– (ğ‘£) and would thus be propagated back to vertex ğ‘£. We now show that the
following property holds for each ğ‘˜ with ğ‘– < ğ‘˜ â‰¤ ğ‘— âˆ’ 1:

(â™¢) for each fact ğº âˆˆ ğ‘‡ğ‘˜ (ğ‘£ â€²) \ ğ‘†, there exist a rule ğ›½ â†’ ğ» âˆˆ Î£â€² and a substitution ğœ such that ğ›½ is Skolem-free, ğœ (ğ›½) âŠ† ğœˆ (ğ‘‡ğ‘– (ğ‘£)),
and ğœ (ğ» ) = ğœˆ (ğº).

Property (â™¢) implies (â™¦): fact ğ¹ does not contain a labeled null from ğ‘ , so the rule ğ›½ â†’ ğ» âˆˆ Î£â€² whose existence is implied by (â™¢) for ğ‘˜ = ğ‘— âˆ’ 1
is actually a Skolem-free rule that satisfies (â™¦).

We next prove property (â™¢) by a nested induction on ğ‘˜. For the base case ğ‘˜ = ğ‘– + 1, property (â™¢) holds due to the fact that Î£â€² contains the
rules obtained by Skolemizing GTGD ğœ. For the inductive step, assume that (â™¢) holds for some ğ‘˜ and consider the possible ways to obtain
ğ‘‡ğ‘˜+1 from ğ‘‡ğ‘˜ . Property (â™¢) holds by the inductive hypothesis if ğ‘‡ğ‘˜+1 (ğ‘£ â€²) = ğ‘‡ğ‘˜ (ğ‘£ â€²)â€”that is, if the step involves a descendant of ğ‘£ â€². Otherwise,
ğ‘‡ğ‘˜+1 (ğ‘£ â€²) = ğ‘‡ğ‘˜ (ğ‘£ â€²) âˆª {ğº } where fact ğº is obtained in one of the following two ways.
â€¢ A full TGD in Î£ derives ğº from ğ‘‡ğ‘˜ (ğ‘£ â€²). Set Î£â€² contains this TGD up to redundancy, so by Definition 5.1 there exist a Skolem-free rule

ğ›½â€²â€² â†’ ğ» â€² âˆˆ Î£â€² and a substitution ğœ â€² such that ğœ â€² (ğ›½â€²â€²) âŠ† ğœˆ (ğ‘‡ğ‘˜ (ğ‘£ â€²)) and ğœ â€² (ğ» â€²) = ğœˆ (ğº).

â€¢ Fact ğº is the output of a loop at vertex ğ‘£ â€². But then, this loop is shorter than ğ‘‡ğ‘–, . . . ,ğ‘‡ğ‘— so, by property (â™¦), there exist a Skolem-free rule

ğ›½â€²â€² â†’ ğ» â€² âˆˆ Î£â€² and a substitution ğœ â€² such that ğœ â€² (ğ›½â€²â€²) âŠ† ğœˆ (ğ‘‡ğ‘˜ (ğ‘£ â€²)) and ğœ â€² (ğ» â€²) = ğœˆ (ğº).

Now let ğ‘Š = {ğµâ€² âˆˆ ğ›½â€²â€² | ğœ â€² (ğµâ€²) âˆ‰ ğ‘† }. We next show that set Î£â€² contains up to redundancy the result of â€œresolving awayâ€ each atom ğµâ€² âˆˆ ğ‘Š .
A slight complication arises due to the fact that the SkDR inference rule considers only two rules at a time, and that the result of each
inference is contained in Î£â€² up to redundancy. Thus, we will achieve our goal by showing that the SkDR inference rule can be applied up to
ğ‘› = |ğ‘Š | times. Our proof is by induction on 1 â‰¤ â„“ â‰¤ ğ‘›. Towards this goal, we shall define ğ‘› rules ğ›½â€²â€²
â„“ , and sets of
atoms ğ‘Š = ğ‘Š0 âŠ‹ Â· Â· Â· âŠ‹ ğ‘Šğ‘› for â„“ with 0 â‰¤ â„“ â‰¤ ğ‘› satisfying the following invariant:

â„“ , substitutions ğœ â€²

â„“ â†’ ğ» â€²

(âˆ—) ğœ â€²

â„“ ) = ğœ â€² (ğ» â€²).
For â„“ = ğ‘›, we have ğ‘Šğ‘› = âˆ…, and so property (âˆ—) implies property (â™¢), as required. Our construction proceeds as follows.

â„“ ) âŠ† ğ‘† âˆª {ğœ â€² (ğµâ€²) | ğµâ€² âˆˆ ğ‘Šâ„“ } and ğœ â€²

â„“ (ğ›½â€²â€²

â„“ (ğ» â€²

For the base case â„“ = 0, property (âˆ—) clearly holds for ğ›½â€²â€²
â„“ , ğœ â€²

â„“ â†’ ğ» â€²

0 = ğ›½â€²â€², ğœ â€²

â„“ , and ğ‘Šâ„“ satisfying (âˆ—) have been defined. First, assume that there exists ğµâ€² âˆˆ ğ‘Šâ„“ such that ğœ â€² (ğµâ€²) âˆ‰ ğœ â€²

0 = ğœ â€², and let ğ‘Š0 = ğ‘Š . For the induction step, assume that (âˆ—) holds for
â„“ (ğ›½â€²
â„“ ).
â„“ , and ğ‘Šâ„“+1 = ğ‘Šâ„“ \ {ğµâ€²}. Otherwise, we consider the following possibilities.
â„“ â†’ ğ» â€²

â„“ contains all variables of the rule.

â„“ where ğ´â€²

â„“ , ğœ â€²
â„“+1 = ğ›½â€²â€²
â„“ is Skolem-free, the rule is of the form ğ´â€²

â„“+1 = ğ» â€²

â„“ , ğ» â€²

â„“+1 = ğœ â€²
â„“ âˆ§ ğ›½â€²

â„“ is of the form ğ´â€²

â„“ âˆ§ ğ›½â€²

â„“ â†’ ğ» â€²

â„“ where atom ğ´â€²

â„“ contains a Skolem symbol, in which case this atom contains all

some 0 â‰¤ â„“ < ğ‘›, so ğ›½â€²â€²
Then, property (âˆ—) clearly holds for ğ›½â€²â€²
â€¢ If rule ğ›½â€²â€²
â€¢ Otherwise, rule ğ›½â€²â€²
variables of the rule.

â„“ â†’ ğ» â€²

â„“ â†’ ğ» â€²

â„“ (ğ´â€²

Either way, there exists ğµâ€² âˆˆ ğ‘Šâ„“ such that ğœ â€²
â„“ ) = ğœ â€² (ğµâ€²) where ğœ â€² (ğµâ€²) âˆˆ ğ‘‡ğ‘˜ (ğ‘£ â€²) \ ğ‘†. Thus, by property (â™¢), these exist a rule ğ›½â„“ â†’ ğ»â„“ âˆˆ Î£â€²
and a substitution ğœâ„“ such that ğ›½â„“ is Skolem-free, ğœâ„“ (ğ›½â„“ ) âŠ† ğœˆ (ğ‘‡ğ‘– (ğ‘£)), and ğœâ„“ (ğ»â„“ ) = ğœ â€² (ğµâ€²); the last observation ensures that ğ»â„“ contains a
Skolem symbol. Moreover, there exists an MGU ğœƒâ„“ of ğ»â„“ and ğ´â€²
â„“ , and Î£â€²
â„“ â†’ ğ» â€²
contains rule ğœƒâ„“ (ğ›½â„“ ) âˆ§ ğœƒâ„“ (ğ›½â€²
â„“ and ğœƒ ; note that substitu-
â„“ do not share variables. Moreover, let ğ‘Šâ„“+1 = ğ‘Šâ„“ \ {ğµâ€²}. We clearly
tion ğœâ„“ âˆª ğœ â€²
have ğœâ„“ (ğœƒâ„“ (ğ›½â„“ )) âŠ† ğ‘†, ğœâ„“ (ğœƒâ„“ (ğ›½â€²
â„“ ) â†’ ğœƒâ„“ (ğ»â„“ ) is not
â„“+1) âŠ† ğœƒâ„“ (ğ›½â„“ ) âˆª ğœƒâ„“ (ğ›½â€²
a syntactic tautology. Thus, by Definition 5.1, there exist a rule ğ›½â€²â€²
â„“ )
and ğœ‡â„“+1 (ğ» â€²
â„“+1) = ğœƒâ„“ (ğ» â€²
â„“+1 (ğ‘¥) = ğœâ„“ (ğœ‡â„“+1 (ğ‘¥)). Then,
property (âˆ—) clearly holds for ğ›½â€²â€²
â–¡

â„“+1 âˆˆ Î£â€² and substitution ğœ‡â„“+1 such that ğœ‡â„“+1 (ğ›½â€²â€²
â„“+1 â†’ ğ» â€²

â„“ )) âŠ† ğ‘† âˆª {ğœ â€² (ğ¶â€²) | ğ¶â€² âˆˆ ğ‘Šâ„“+1}, and ğœâ„“ (ğœƒâ„“ (ğ» )) = ğœ â€² (ğ» â€²). Since ğº âˆ‰ ğ‘‡ğ‘˜ (ğ‘£ â€²), rule ğœƒâ„“ (ğ›½â„“ ) âˆ§ ğœƒâ„“ (ğ›½â€²

â„“+1 be the substitution defined on each variable ğ‘¥ in ğ›½â€²â€²

â„“ , so the SkDR inference rule is applicable to ğ›½â„“ â†’ ğ»â„“ and ğ´â€²

â„“ ) â†’ ğœƒâ„“ (ğ»â„“ ) up to redundancy. Now let ğœâ„“ = (ğœâ„“ âˆª ğœ â€²

â„“ is correctly defined because rules ğ›½â„“ â†’ ğ»â„“ and ğ´â€²

â„“ ) â—¦ ğœƒ be the composition of ğœâ„“ âˆª ğœ â€²

â„“+1 such that ğœ â€²

â„“ ). Now let ğœ â€²

â„“+1 â†’ ğ» â€²

â„“ â†’ ğ» â€²

â„“ âˆ§ ğ›½â€²

â„“ âˆ§ ğ›½â€²

â„“+1 â†’ ğ» â€²

â„“+1, ğœ â€²

â„“+1, and ğ‘Šâ„“+1, as required.

Proof of Complexity. Fix Î£, ğ‘Ÿ , ğ‘¤ğ‘ , ğ‘’, ğ‘, and ğ‘ as stated in the theorem. Skolemizing a GTGD âˆ€(cid:174)ğ‘¥ [ğ›½ â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚] produces guarded rules
in which each atom is of the form ğ‘…(ğ‘¡1, . . . , ğ‘¡ğ‘›) such that each ğ‘¡ğ‘– is a constant, a variable from (cid:174)ğ‘¥, or a term of the form ğ‘“ ( (cid:174)ğ‘¥) where ğ‘“ is a
Skolem symbol. Moreover, each atom obtained from ğ‘…(ğ‘¡1, . . . , ğ‘¡ğ‘›) by the SkDR inference rule is obtained by replacing a variable in (cid:174)ğ‘¥ with
another variable or a constant. Thus, atom ğ‘…(ğ‘¡1, . . . , ğ‘¡ğ‘›) cannot contain more than | (cid:174)ğ‘¥ | variables. Since the number of different symbols
obtained by Skolemization is clearly bounded by ğ‘’, the number of different atoms of such form is bounded by â„“ = ğ‘Ÿ Â· (ğ‘¤ğ‘ + ğ‘’ + ğ‘)ğ‘. The
body of each guarded rule corresponds to a subset of these atoms, so the number of different rules up to variable remaining is bounded
by 2â„“ Â· â„“ â‰¤ 2â„“ Â· 2â„“ = 22â„“ = â„˜. By Definition 5.3, the result of applying the SkDR inference rule is retained in set Î£â€² only if the set does not
contain a variable renaming of the result. Thus, the SkDR inference rule needs to be applied to at most â„˜2 = 24â„“ pairs of rules. For each pair,
one might need to unify at most â„“ body atoms of one rule with the head atom of the other rule, so the unifier ğœƒ may need to be computed at
most â„˜2 Â· â„“ â‰¤ â„˜2 Â· 2â„“ = 25â„“ = 32â„“ times. We can check subsumption between a pair of rules analogously to Theorem 5.8: for each of at most
2â„“ 2
ways to match the body atoms of one rule to the body atoms of another rule, we try to find a substitution ğœ‡ satisfying Definition 5.1.
â–¡
Finally, unification of atoms requires time that is linear in ğ‘, and all other steps require linear time too.

D PROOFS FOR HypDR
D.1 Proof of Proposition 5.18: Properties of HypDR

Proposition 5.18. Each application of the HypDR inference rule to rules ğœ1, . . . , ğœğ‘› and ğœ â€² as in Definition 5.16 produces a guarded rule.

1 âˆ§ Â· Â· Â· âˆ§ ğ´â€²

ğ‘› âˆ§ ğ›½â€² â†’ ğ» â€², and an MGU ğœƒ of ğ»1, . . . , ğ»ğ‘› and ğ´â€²
1

Proof. Consider arbitrary rules ğœğ‘– = ğ›½ğ‘– â†’ ğ»ğ‘– with 1 â‰¤ ğ‘– â‰¤ ğ‘› such that ğ›½ğ‘– is Skolem-free and ğ»ğ‘– contains a Skolem symbol, a Skolem-free
rule ğœ â€² = ğ´â€²
ğ‘› satisfying the preconditions of the HypDR inference rule.
Rule ğœ1 contains a term with a Skolem symbol in the head, and this term is unified with a variable, say ğ‘¥, occurring in a Skolem-free body
atom ğ´â€²
1 of rule ğœ â€². Moreover, rule ğœ â€² is guarded, so the body of the rule contains a Skolem-free atom ğº that contains all variables of the rule;
thus, ğº also contains ğ‘¥. Since ğœƒ (ğ‘¥) contains a Skolem symbol, ğœƒ (ğº) contains a Skolem symbol too. However, ğœƒ (ğ›½â€²) is Skolem-free, so ğº must
ğ‘› from the body of rule ğœ â€² that are participating in the HypDR inference rule. But then, we can show that the
be one of the atoms ğ´â€²
1
â–¡
result of the inference is guarded analogously to the proof of Proposition 5.12.

, Â· Â· Â· ğ´â€²

, . . . , ğ´â€²

D.2 Proof of Theorem 5.19: Correctness and Complexity of HypDR

Theorem 5.19. Program HypDR(Î£) is a Datalog rewriting of a finite set of GTGDs Î£. Moreover, the rewriting can be computed in time
) for ğ‘Ÿ the number of relations in Î£, ğ‘ the maximum relation arity in Î£, ğ‘’ the number of existential quantifiers in Î£,

time ğ‘‚ (ğ‘ğ‘Ÿ ğ‘‘ Â· (ğ‘’+ğ‘¤ğ‘ +ğ‘ )ğ‘‘ğ‘
ğ‘¤ğ‘ = bwidth(Î£), ğ‘ = |consts(Î£)|, and some ğ‘ and ğ‘‘.

, . . . , ğ´â€²

ğ‘› be precisely the atoms of ğ›½â€²â€² such that ğœ â€² (ğ´â€²

Proof of Correctness. The correctness proof for HypDR is almost identical to the correctness proof in Theorem 5.13, so we outline
just the difference. In particular, we wish to prove properties (â™¦) and (â™¢) exactly as stated in Theorem 5.13 using the same proof structure. In
the proof of property (â™¢), we establish existence of a Skolem-free rule ğ›½â€²â€² â†’ ğ» â€² âˆˆ Î£â€² and a substitution ğœ â€² such that ğœ â€² (ğ›½â€²â€²) âŠ† ğœˆ (ğ‘‡ğ‘˜ (ğ‘£ â€²)) and
ğœ â€² (ğ» â€²) = ğœˆ (ğº) in exactly the same way. The difference to the proof of Theorem 5.13 is that we â€œresolve awayâ€ all relevant body atoms of ğ›½â€²â€²
in one step. To this end, let ğ´â€²
ğ‘– ) âˆ‰ ğ‘† for each 1 â‰¤ ğ‘– â‰¤ ğ‘›. Thus, we can assume that the rule
1
ğ‘› âˆ§ ğ›½â€² â†’ ğ» â€², and ğœ â€² (ğ›½â€²) âŠ† ğ‘† clearly holds. By property (â™¢), for each 1 â‰¤ â„“ â‰¤ ğ‘›, there exist a rule ğ›½â„“ â†’ ğ»â„“ âˆˆ Î£â€²
1 âˆ§ Â· Â· Â· âˆ§ ğ´â€²
is of the form ğ´â€²
and substitution ğœâ„“ such that ğ›½â„“ is Skolem-free and ğœâ„“ (ğ»â„“ ) = ğœ â€² (ğ´â€²
â„“ ); the last observation ensures that ğ»â„“ contains a Skolem symbol.
ğ‘›. Since ğœ â€² (ğ›½â€²) âŠ† ğ‘†, conjunction ğœƒ (ğ›½â€²) is Skolem-free. Thus, the HypDR inference
Finally, there exists an MGU ğœƒ of ğ»1, . . . , ğ»ğ‘› and ğ´â€²
1
ğ‘› âˆ§ ğ›½â€² â†’ ğ» â€², so set Î£â€² contains rule ğœƒ (ğ›½1) âˆ§ Â· Â· Â· âˆ§ ğœƒ (ğ›½ğ‘›) âˆ§ ğœƒ (ğ›½â€²) â†’ ğœƒ (ğ» â€²)
rule is applicable to ğ›½1 â†’ ğ»1, . . . , ğ›½ğ‘› â†’ ğ»ğ‘› and ğ´â€²
up to redundancy. Since no premises share variables, substitution ğœ1 âˆª Â· Â· Â· âˆª ğœğ‘› âˆª ğœ â€² is correctly defined, so let ğœ be the composition of
ğœ1 âˆª Â· Â· Â· âˆª ğœğ‘› âˆª ğœ â€² and ğœƒ . Clearly, we have ğœ (ğœƒ (ğ›½1)) âˆª Â· Â· Â· âˆª ğœ (ğœƒ (ğ›½ğ‘›)) âˆª ğœ (ğœƒ (ğ›½â€²)) âŠ† ğ‘† and ğœ (ğœƒ (ğ» â€²)) = ğœ â€² (ğ» â€²) = ğœˆ (ğº). Since ğº âˆ‰ ğ‘‡ğ‘˜ (ğ‘£ â€²), rule
ğœƒ (ğ›½1) âˆ§ Â· Â· Â· âˆ§ ğœƒ (ğ›½ğ‘›) âˆ§ ğœƒ (ğ›½â€²) â†’ ğœƒ (ğ» â€²) is not a syntactic tautology so, by Definition 5.1, there exist a rule ğ›½ â†’ ğ» âˆˆ Î£â€² and substitution ğœ‡
such that ğœ‡ (ğ›½) âŠ† ğœƒ (ğ›½1) âˆª Â· Â· Â· âˆª ğœƒ (ğ›½ğ‘›) âˆª ğœƒ (ğ›½â€²) and ğœ‡ (ğ» ) = ğœƒ (ğ» â€²). Let ğœ be the substitution defined on each variable ğ‘¥ in ğ›½ â†’ ğ» such that
ğœ (ğ‘¥) = ğœ (ğœ‡ (ğ‘¥)). Then, ğœ (ğ›½) âŠ† ğ‘† and ğœ (ğ» ) = ğœ â€² (ğ» â€²) = ğœˆ (ğº), as required for property (â™¢).
â–¡

, . . . , ğ´â€²
1 âˆ§ Â· Â· Â· âˆ§ ğ´â€²

Proof of Complexity. Fix Î£, ğ‘Ÿ , ğ‘¤ğ‘ , ğ‘’, ğ‘, and ğ‘ as stated in the theorem. In the same way as in the complexity proof of Theorem 5.13, the
number of different atoms can be bounded by â„“ = ğ‘Ÿ Â· (ğ‘¤ğ‘ + ğ‘’ + ğ‘)ğ‘, and the number of different rules can be bounded by â„˜ = 22â„“ . Now we
can apply the HypDR inference rule as follows: we choose one of the â„˜ rules that plays the role of ğœ â€² and then, for each of the at most â„“ body
atoms in ğœ â€², we select one of the â„˜ rules that play the role of rules ğœğ‘– . Hence, there are at most â„˜ Â· â„˜â„“ = â„˜â„“+1 different applications of the
HypDR inference rule. Thus, we may need to compute the unifier ğœƒ at most (22â„“ )â„“+1 = 22â„“ 2+2â„“ â‰¤ 23â„“ 2
times. Finally, the times needed for
â–¡
subsumption checking, unification, and all other steps can be bounded analogously as in the complexity proof of Theorem 5.13.

E THE FullDR ALGORITHM: CREATING DATALOG RULES DIRECTLY
The algorithms presented in the body of the paper all create the Datalog rules needed for the final rewriting as well as intermediate non-full
TGDs or rules that are discarded after all inferences are performed. We now present an algorithm that produces only Datalog rules. Similar
algorithms have appeared in the prior literature [4]. After presenting such an algorithm, we explain the shortcomings of this approach.

Definition E.1. The Full Datalog Rewriting inference rule FullDR can be applied in two ways, depending on the types of TGDs it takes.
â€¢ The (COMPOSE) variant of the FullDR inference rule takes full TGDs

ğœ = âˆ€(cid:174)ğ‘¥ [ğ›½ â†’ ğ´]

and

ğœ â€² = âˆ€(cid:174)ğ‘§ [ğ´â€² âˆ§ ğ›½â€² â†’ ğ» â€²]

and a substitution ğœƒ such that
â€“ ğœƒ (ğ´) = ğœƒ (ğ´â€²),
â€“ dom(ğœƒ ) = (cid:174)ğ‘¥ âˆª (cid:174)ğ‘§, and
â€“ rng(ğœƒ ) âŠ† (cid:174)ğ‘¤ âˆª consts(ğœ) âˆª consts(ğœ â€²) where (cid:174)ğ‘¤ is a vector of hwidth(Î£) + |consts(Î£)| variables different from (cid:174)ğ‘¥ âˆª (cid:174)ğ‘¦ âˆª (cid:174)ğ‘§,
and it derives

ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½â€²) â†’ ğœƒ (ğ» â€²).

â€¢ The (PROPAGATE) variant of the FullDR inference rule takes TGDs

ğœ = âˆ€(cid:174)ğ‘¥ [ğ›½ â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚ âˆ§ ğ´1 âˆ§ Â· Â· Â· âˆ§ ğ´ğ‘›]

and

ğœ â€² = âˆ€(cid:174)ğ‘§ [ğ´â€²

1 âˆ§ Â· Â· Â· âˆ§ ğ´â€²

ğ‘› âˆ§ ğ›½â€² â†’ ğ» â€²]

ğ‘– ) for each ğ‘– with 1 â‰¤ ğ‘– â‰¤ ğ‘›,

and a substitution ğœƒ such that
â€“ ğœƒ (ğ´ğ‘– ) = ğœƒ (ğ´â€²
â€“ dom(ğœƒ ) = (cid:174)ğ‘¥ âˆª (cid:174)ğ‘§,
â€“ rng(ğœƒ ) âŠ† (cid:174)ğ‘¤ âˆª (cid:174)ğ‘¦ âˆª consts(ğœ) âˆª consts(ğœ â€²) where (cid:174)ğ‘¤ is a vector of hwidth(Î£) + |consts(Î£)| variables different from (cid:174)ğ‘¥ âˆª (cid:174)ğ‘¦ âˆª (cid:174)ğ‘§,
â€“ ğœƒ ( (cid:174)ğ‘¥) âˆ© (cid:174)ğ‘¦ = âˆ…, and
â€“ vars(ğœƒ (ğ›½â€²)) âˆ© (cid:174)ğ‘¦ = âˆ… and vars(ğœƒ (ğ» â€²)) âˆ© (cid:174)ğ‘¦ = âˆ…,
and it derives

ğœƒ (ğ›½) âˆ§ ğœƒ (ğ›½â€²) â†’ ğœƒ (ğ» â€²).

Theorem E.2. Program FullDR(Î£) is a Datalog rewriting of a finite set of GTGDs Î£. Moreover, the rewriting can be computed in time

ğ‘‚ (ğ‘ğ‘Ÿ ğ‘‘ Â· (ğ‘¤+ğ‘ )ğ‘‘ğ‘

) for ğ‘Ÿ the number of relations in Î£, ğ‘ the maximum relation arity in Î£, ğ‘¤ = width(Î£), ğ‘ = |consts(Î£)|, and some ğ‘ and ğ‘‘.

Proof of Correctness. The proof follows the same structure as the correctness proof of Theorem 5.8: we show that property (â™¦) holds
for each loop on a one-pass tree-like chase sequence for ğ¼ and Î£; a minor difference is that the TGD whose existence is implied by (â™¦) is not
necessarily guarded, but has width bounded by hwidth(ğœ). To this end, we consider an arbitrary loop ğ‘‡ğ‘–,ğ‘‡ğ‘–+1, . . . ,ğ‘‡ğ‘— âˆ’1,ğ‘‡ğ‘— at vertex ğ‘£ in the
sequence, and assume that the claim holds for all shorter loops in the sequence. By the definition of the loop, chase tree ğ‘‡ğ‘–+1 is obtained
from ğ‘‡ğ‘– by applying a chase step to some non-full TGD âˆ€(cid:174)ğ‘¥ [ğ›½0 â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚0] âˆˆ Î£. Let ğœ0 and ğœ â€²
0 be the substitutions used in this chase step, and
let ğ‘£ â€² be the child of ğ‘£ introduced in ğ‘‡ğ‘–+1. Note that ğ‘‡ğ‘–+1 (ğ‘£ â€²) contains at most hwidth(Î£) + |consts(Î£)| distinct terms. We show by another
induction on ğ‘˜ that the following property holds for each ğ‘˜ with ğ‘– < ğ‘˜ â‰¤ ğ‘— âˆ’ 1:

(â™¢) for each fact ğº âˆˆ ğ‘‡ğ‘˜ (ğ‘£ â€²) \ ğ‘‡ğ‘–+1 (ğ‘£ â€²), there exist a full TGD âˆ€(cid:174)ğ‘¥ [ğ›½ â†’ ğ» ] âˆˆ Î£â€² of width at most width(Î£) and a substitution
ğœ such that ğœ (ğ›½) âŠ† ğ‘‡ğ‘–+1 (ğ‘£ â€²) and ğœ (ğ» ) = ğº.

For the base case ğ‘˜ = ğ‘– + 1, property (â™¢) holds vacuously because ğ‘‡ğ‘˜ (ğ‘£ â€²) \ ğ‘‡ğ‘–+1 (ğ‘£ â€²) = âˆ…. For the inductive step, assume that (â™¢) holds for
some ğ‘˜ and consider the possible ways to obtain ğ‘‡ğ‘˜+1 from ğ‘‡ğ‘˜ . Property (â™¢) holds by the inductive hypothesis if ğ‘‡ğ‘˜+1 (ğ‘£ â€²) = ğ‘‡ğ‘˜ (ğ‘£ â€²)â€”that is, if
the step involves a descendant of ğ‘£ â€². Otherwise, ğ‘‡ğ‘˜+1 (ğ‘£ â€²) = ğ‘‡ğ‘˜ (ğ‘£ â€²) âˆª {ğº } where fact ğº is obtained in one of the following two ways.
â€¢ A full TGD in Î£ derives ğº from ğ‘‡ğ‘˜ (ğ‘£ â€²). Set Î£â€² contains this TGD up to redundancy, so by Definition 5.1 there exist a full TGD ğ›½â€²â€² â†’ ğ» â€² âˆˆ Î£â€²

and a substitution ğœ such that ğœ (ğ›½â€²â€²) âŠ† ğ‘‡ğ‘˜ (ğ‘£ â€²) and ğœ (ğ» â€²) = ğº.

â€¢ Fact ğº is the output of a loop at vertex ğ‘£ â€². But then, this loop is shorter than ğ‘‡ğ‘–, . . . ,ğ‘‡ğ‘— so, by property (â™¦), there exists a full TGD

ğ›½â€²â€² â†’ ğ» â€² âˆˆ Î£â€² and a substitution ğœ such that ğœ (ğ›½â€²â€²) âŠ† ğ‘‡ğ‘˜ (ğ‘£ â€²) and ğœ (ğ» â€²) = ğº.

Either way, the width of rule ğ›½â€²â€² â†’ ğ» â€² is bounded by width(Î£), and we can assume that ğ›½â€²â€² â†’ ğ» â€² is of the form ğ´â€²
ğ‘› âˆ§ ğ›½â€² â†’ ğ» â€²
â„“ ) âˆˆ ğ‘‡ğ‘˜ (ğ‘£ â€²) \ ğ‘‡ğ‘–+1 (ğ‘£ â€²) for each 1 â‰¤ â„“ â‰¤ ğ‘›, and ğœ (ğ›½â€²) âŠ† ğ‘‡ğ‘–+1 (ğ‘£ â€²). By property (â™¢), for each 1 â‰¤ â„“ â‰¤ ğ‘› there exist a full TGD
where ğœ (ğ´â€²
ğ›½â„“ â†’ ğ»â„“ âˆˆ Î£â€² and a substitution ğœâ„“ such that ğœâ„“ (ğ›½â„“ ) âŠ† ğ‘‡ğ‘–+1 (ğ‘£ â€²) and ğœâ„“ (ğ»â„“ ) = ğ›¾ (ğ´â€²
â„“ ). Moreover, set rng(ğœâ„“ ) clearly contains at most
hwidth(Î£) + |consts(Î£)| distinct terms. But then, there exist substitutions ğœƒ1, . . . , ğœƒğ‘› that allow us to iteratively compose each ğ›½â„“ â†’ ğ»â„“ with
ğ´â€²
1 âˆ§ Â· Â· Â· âˆ§ ğ´â€²
ğ‘› âˆ§ ğ›½â€² â†’ ğ» â€² to obtain a full TGD subsumed by some ğœ âˆˆ Î£â€² and substitution ğœ1 such that ğœ and ğœ1 satisfy property (â™¢).
To complete the proof, consider an arbitrary fact ğ¹ âˆˆ ğ‘‡ğ‘— âˆ’1 (ğ‘£ â€²) \ ğ‘‡ğ‘–+1 (ğ‘£ â€²) that is propagated from ğ‘£ â€² to ğ‘£ in ğ‘‡ğ‘— , and let ğ›½â€²â€² â†’ ğ» â€² âˆˆ Î£â€² and ğœ
0 (ğœ‚0), then TGD ğ›½â€²â€² â†’ ğ» â€² satisfies
0 (ğœ‚0) for each 1 â‰¤ ğ‘– â‰¤ ğ‘›,
0 (ğœ‚0). Moreover, rng(ğœ) clearly contains at most hwidth(Î£) + |consts(Î£)| distinct terms. But then, there exists a
ğ‘› âˆ§ ğ›½â€² â†’ ğ» â€²
â–¡

be the TGD and substitution whose existence is guaranteed by property (â™¢). Now if ğœ (ğ›½â€²â€²) âŠ† ğ‘‡ğ‘–+1 (ğ‘£ â€²) \ ğœ â€²
property (â™¦). Otherwise, we can assume that the rule is of the form ğ´â€²
and ğœ (ğ›½â€²) âŠ† ğ‘‡ğ‘–+1 (ğ‘£ â€²) \ ğœ â€²
substitution ğœƒ that allows us to apply the (PROPAGATE) variant of the FullDR inference rule to ğ›½0 â†’ âˆƒ(cid:174)ğ‘¦ ğœ‚0 and ğ´â€²
to obtain a full TGD subsumed by some TGD ğœ âˆˆ Î£â€² and substitution ğœ1 such that ğœ and ğœ1 satisfy property (â™¦).

ğ‘› âˆ§ ğ›½â€² â†’ ğ» â€² where ğœ (ğ´â€²

1 âˆ§ Â· Â· Â· âˆ§ ğ´â€²

1 âˆ§ Â· Â· Â· âˆ§ ğ´â€²

1 âˆ§ Â· Â· Â· âˆ§ ğ´â€²

ğ‘– ) âˆˆ ğœ â€²

Proof of Complexity. The proof is analogous to the proof of complexity of Theorem 5.8. In particular, the (PROPAGATE) variant of the
FullDR inference rule is analogous to the ExbDR inference rule, so we can bound in the same way the number of candidate rule pairs and
possible ways to match body atoms of ğœ â€² to head atoms of ğœ by 32â„“ 2
, where â„“ = ğ‘Ÿ Â· (ğ‘¤ + ğ‘)ğ‘. Once a candidate pair of ğœ and ğœ â€² has been selected,
we need to consider all possible substitutions ğœƒ . Each such ğœƒ is defined on at most 2ğ‘¤ variables (cid:174)ğ‘¥ âˆª (cid:174)ğ‘§. Moreover, each variable is mapped to
one of the ğ‘¤ + ğ‘ variables or to one of the ğ‘ constants in consts(Î£). Hence, there are at most (ğ‘¤ + 2ğ‘)2ğ‘¤ â‰¤ 4(ğ‘¤+2ğ‘ ) Â·ğ‘¤ â‰¤ 4(ğ‘¤+ğ‘ ) 2
different
substitutions ğœƒ . Consequently, the (PROPAGATE) variant of the FullDR inference rule can be applied at most 32â„“ 2 Â· 4(ğ‘¤+ğ‘ ) 2 < 32ğ‘›Â· (ğ‘¤+ğ‘ ) 2ğ‘+1
times. Applications of the (COMPOSE) variant can be bounded analogously. Finally, the times needed for subsumption checking, unification,
and all other steps can be bounded analogously as in the complexity proof of Theorem 5.8, with a minor difference that only body atoms
â–¡
need to be matched in the subsumption checks.

The FullDR algorithm has several obvious weak points. First, it considers all possible ways to compose Datalog rules as long as this
produces a rule with at most hwidth(Î£) + |consts(Î£)| variables. This may seem unnecessary, but the (COMPOSE) variant of the FullDR
inference rule cannot be simply dropped while retaining completeness. To understand why, consider an arbitrary loop ğ‘‡ğ‘–, . . . ,ğ‘‡ğ‘— at vertex ğ‘£
with output fact ğ¹ in a one-pass chase proof: the (PROPAGATE) variant of the FullDR inference reflects only the chase step that derives
the loopâ€™s output ğ¹ , so the (COMPOSE) variant is needed to reflects the chase steps that produce facts derived in the child of ğ‘£ that are
not propagated back to ğ‘£. Second, it is not clear how one efficiently obtains the atoms ğ´1, . . . , ğ´ğ‘› and ğ´â€²
ğ‘› participating in the
1
(PROPAGATE) variant. Third, the number of substitutions ğœƒ in the (COMPOSE) and (PROPAGATE) variants of the FullDR inference rule
can be very large. Example E.3 illustrates this problem for the (COMPOSE) variant, but one can show analogously that the (PROPAGATE)
variant suffers from the same issues.

, . . . , ğ´â€²

(46)

(47)

Example E.3. Consider the steps of the FullDR algorithm on GTGDs (46)â€“(48).

ğ‘…(ğ‘¥1, ğ‘¥2) â†’ âˆƒğ‘¦1, ğ‘¦2 ğ‘† (ğ‘¥1, ğ‘¥2, ğ‘¦1, ğ‘¦2) âˆ§ ğ‘‡ (ğ‘¥1, ğ‘¥2, ğ‘¦2)

ğ‘† (ğ‘¥1, ğ‘¥2, ğ‘¥3, ğ‘¥4) â†’ ğ‘ˆ (ğ‘¥4)
ğ‘‡ (ğ‘§1, ğ‘§2, ğ‘§3) âˆ§ ğ‘ˆ (ğ‘§3) â†’ ğ‘ƒ (ğ‘§1)

(48)
The (COMPOSE) variant of the FullDR inference rule should be applied to GTGDs (47) and (48), but it is not clear which unifier ğœƒ , identifying
variables ğ‘§ğ‘– in the latter with variables ğ‘¥ğ‘– in the former, one should use. The standard resolution inference rule from first-order theorem
proving would consider only the MGU ğœƒ that maps ğ‘§3 to ğ‘¥4; however, this would produce the resolvent ğ‘† (ğ‘¥1, ğ‘¥2, ğ‘¥3, ğ‘¥4) âˆ§ ğ‘‡ (ğ‘§1, ğ‘§2, ğ‘¥4) â†’ ğ‘ƒ (ğ‘§1)
containing more than hwidth(Î£) = 4 variables, so this rule is not derived by the (COMPOSE) variant. Eliminating the upper bound on the
number of variables is not a solution: doing so would allow the derivation of full TGDs with an unbounded number of variables, which
would prevent termination. Instead, the (COMPOSE) variant requires us to consider every possible substitution ğœƒ that maps variables
ğ‘¥1, . . . , ğ‘¥4, ğ‘§1, . . . , ğ‘§3 to at most hwidth(Î£) variables. Consequently, 74 = 2401 substitutions deriving rules such as

ğ‘† (ğ‘¥1, ğ‘¥2, ğ‘¥3, ğ‘¥4) âˆ§ ğ‘‡ (ğ‘¥1, ğ‘¥2, ğ‘¥4) â†’ ğ‘ƒ (ğ‘¥1),
ğ‘† (ğ‘¥1, ğ‘¥2, ğ‘¥3, ğ‘¥4) âˆ§ ğ‘‡ (ğ‘¥2, ğ‘¥1, ğ‘¥4) â†’ ğ‘ƒ (ğ‘¥2),
ğ‘† (ğ‘¥1, ğ‘¥2, ğ‘¥3, ğ‘¥4) âˆ§ ğ‘‡ (ğ‘¥1, ğ‘¥3, ğ‘¥4) â†’ ğ‘ƒ (ğ‘¥1),
ğ‘† (ğ‘¥1, ğ‘¥2, ğ‘¥3, ğ‘¥4) âˆ§ ğ‘‡ (ğ‘¥3, ğ‘¥1, ğ‘¥4) â†’ ğ‘ƒ (ğ‘¥3),

need to be considered, which is clearly infeasible in practice.

(49)

(50)

(51)

(52)
âŠ³

Nevertheless, we implemented FullDR using the subsumption and indexing techniques described in Section 6. Unsurprisingly, we did not
find FullDR competitive in our experiments. In fact, FullDR timed out on 173 ontologies, and there are only three ontologies where another
algorithm reached the timeout but FullDR did not. For this reason, we do not discuss the results with FullDR in Section 7.

